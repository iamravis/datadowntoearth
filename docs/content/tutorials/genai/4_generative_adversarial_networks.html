<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.47">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ravi Shankar">

<title>generative_adversarial_networks – Data Down To Earth</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../logo.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
<link rel="stylesheet" href="../../content.css">
<meta property="og:title" content="– Data Down To Earth">
<meta property="og:site_name" content="Data Down To Earth">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Data Down To Earth</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projects" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Projects</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-projects">    
        <li>
    <a class="dropdown-item" href="../../../projects/dsml_projects.html">
 <span class="dropdown-text">Data Science and ML Projects</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../projects/genai_projects.html">
 <span class="dropdown-text">Generative AI Projects</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-tutorials" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Tutorials</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-tutorials">    
        <li>
    <a class="dropdown-item" href="../../../topics/statistics.html">
 <span class="dropdown-text">Statistics &amp; Probability</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/machine_learning.html">
 <span class="dropdown-text">Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/de.html">
 <span class="dropdown-text">Data Engineering</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/generative_ai.html">
 <span class="dropdown-text">Generative AI</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/public_health.html">
 <span class="dropdown-text">Public Health</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/product_sense.html">
 <span class="dropdown-text">Product Sense</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../notes/notes.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/iamrsps"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/iamravishankar/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content column-page" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
</div>



<div class="quarto-title-meta column-page">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ravi Shankar </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="chapter-4-generative-adversarial-networks" class="level1 text-content">
<h1>Chapter 4: Generative Adversarial Networks</h1>
<section id="architecture-and-training-process" class="level2">
<h2 class="anchored" data-anchor-id="architecture-and-training-process">Architecture and Training Process</h2>
<p>Generative Adversarial Networks (GANs) consist of two neural networks that engage in a competitive, zero-sum game framework. The core components are:</p>
<ol type="1">
<li><strong>Generator (G)</strong>: A neural network that learns to create data resembling the training distribution.</li>
<li><strong>Discriminator (D)</strong>: A neural network that learns to distinguish between real and generated data.</li>
</ol>
<section id="formulation-of-the-gan-framework" class="level3">
<h3 class="anchored" data-anchor-id="formulation-of-the-gan-framework">Formulation of the GAN Framework</h3>
<p>The training process is formalized as a minimax game:</p>
<p><span class="math display">\[
\min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(p_{data}(x)\)</span> is the true data distribution.</li>
<li><span class="math inline">\(p_z(z)\)</span> is the prior distribution of the input noise.</li>
<li><span class="math inline">\(G(z)\)</span> is the generator function.</li>
<li><span class="math inline">\(D(x)\)</span> is the discriminator function.</li>
</ul>
</section>
<section id="training-process" class="level3">
<h3 class="anchored" data-anchor-id="training-process">Training Process</h3>
<p>The training process alternates between updating <span class="math inline">\(D\)</span> and <span class="math inline">\(G\)</span>:</p>
<ol type="1">
<li><p><strong>Train the discriminator</strong>: Maximize the probability of correctly classifying real and fake samples by minimizing the following loss: <span class="math display">\[
L_D = -\mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] - \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
\]</span></p></li>
<li><p><strong>Train the generator</strong>: Minimize the probability of the discriminator correctly classifying fake samples by minimizing the following loss: <span class="math display">\[
L_G = -\mathbb{E}_{z \sim p_z(z)}[\log D(G(z))]
\]</span></p></li>
</ol>
<p>This process continues until the generator produces samples that the discriminator cannot distinguish from real data.</p>
</section>
<section id="mathematical-explanation" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-explanation">Mathematical Explanation</h3>
<p>The minimax game between the generator and the discriminator can be understood through the concept of game theory, where two players (G and D) are trying to optimize their own objectives.</p>
<ol type="1">
<li><p><strong>Discriminator Objective</strong>: The discriminator aims to maximize the probability of assigning the correct label to both real and generated data. This is achieved by adjusting its parameters to maximize the following value: <span class="math display">\[
\mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
\]</span></p></li>
<li><p><strong>Generator Objective</strong>: The generator aims to minimize the probability of the discriminator correctly identifying generated data as fake. This is achieved by adjusting its parameters to minimize the following value: <span class="math display">\[
\mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
\]</span></p></li>
</ol>
</section>
<section id="detailed-mathematical-explanation" class="level3">
<h3 class="anchored" data-anchor-id="detailed-mathematical-explanation">Detailed Mathematical Explanation</h3>
<section id="discriminator-objective" class="level4">
<h4 class="anchored" data-anchor-id="discriminator-objective">Discriminator Objective</h4>
<p>The discriminator’s task is to distinguish real data from fake data generated by <span class="math inline">\(G\)</span>. The discriminator’s objective function can be written as:</p>
<p><span class="math display">\[
\max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
\]</span></p>
<ul>
<li>The term <span class="math inline">\(\mathbb{E}_{x \sim p_{data}(x)}[\log D(x)]\)</span> represents the expected value of the logarithm of the discriminator’s probability of classifying real data <span class="math inline">\(x\)</span> correctly.</li>
<li>The term <span class="math inline">\(\mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]\)</span> represents the expected value of the logarithm of the discriminator’s probability of classifying generated data <span class="math inline">\(G(z)\)</span> as fake.</li>
</ul>
</section>
<section id="generator-objective" class="level4">
<h4 class="anchored" data-anchor-id="generator-objective">Generator Objective</h4>
<p>The generator’s task is to produce data that is indistinguishable from real data. The generator’s objective function can be written as:</p>
<p><span class="math display">\[
\min_G V(D, G) = \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
\]</span></p>
<ul>
<li>The generator aims to minimize <span class="math inline">\(\mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]\)</span>, which is the expected value of the logarithm of the discriminator’s probability of classifying generated data <span class="math inline">\(G(z)\)</span> as fake. This incentivizes the generator to produce data that the discriminator classifies as real.</li>
</ul>
</section>
<section id="minimax-game" class="level4">
<h4 class="anchored" data-anchor-id="minimax-game">Minimax Game</h4>
<p>The overall training objective can be seen as a two-player minimax game, where the discriminator <span class="math inline">\(D\)</span> tries to maximize the objective while the generator <span class="math inline">\(G\)</span> tries to minimize it:</p>
<p><span class="math display">\[
\min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
\]</span></p>
<p>This formulation can be thought of as a saddle point problem where one player (the discriminator) tries to maximize the value while the other player (the generator) tries to minimize it.</p>
</section>
<section id="optimal-discriminator" class="level4">
<h4 class="anchored" data-anchor-id="optimal-discriminator">Optimal Discriminator</h4>
<p>Given a fixed generator <span class="math inline">\(G\)</span>, the optimal discriminator <span class="math inline">\(D\)</span> can be derived by taking the derivative of the discriminator’s objective with respect to <span class="math inline">\(D\)</span> and setting it to zero:</p>
<p><span class="math display">\[
D^*(x) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}
\]</span></p>
<p>Where <span class="math inline">\(p_g(x)\)</span> is the distribution of the generated data. This means that the optimal discriminator outputs the probability that a sample <span class="math inline">\(x\)</span> is real rather than generated by the generator.</p>
</section>
<section id="simplified-generator-objective" class="level4">
<h4 class="anchored" data-anchor-id="simplified-generator-objective">Simplified Generator Objective</h4>
<p>Substituting the optimal discriminator <span class="math inline">\(D^*(x)\)</span> back into the generator’s objective gives us a new objective for the generator:</p>
<p><span class="math display">\[
\min_G V(G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D^*(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D^*(G(z)))]
\]</span></p>
<p>Using the optimal discriminator <span class="math inline">\(D^*(x)\)</span>, we have:</p>
<p><span class="math display">\[
\mathbb{E}_{x \sim p_{data}(x)}[\log D^*(x)] = \mathbb{E}_{x \sim p_{data}(x)} \left[\log \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}\right]
\]</span></p>
<p>And:</p>
<p><span class="math display">\[
\mathbb{E}_{z \sim p_z(z)}[\log(1 - D^*(G(z)))] = \mathbb{E}_{z \sim p_z(z)} \left[\log \left(1 - \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}\right)\right]
\]</span></p>
<p>Simplifying the second term:</p>
<p><span class="math display">\[
\mathbb{E}_{z \sim p_z(z)} \left[\log \left(1 - \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}\right)\right] = \mathbb{E}_{z \sim p_z(z)} \left[\log \left(\frac{p_g(x)}{p_{data}(x) + p_g(x)}\right)\right]
\]</span></p>
<p>So the generator’s objective becomes:</p>
<p><span class="math display">\[
\min_G V(G) = \mathbb{E}_{x \sim p_{data}(x)} \left[\log \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}\right] + \mathbb{E}_{z \sim p_z(z)} \left[\log \frac{p_g(x)}{p_{data}(x) + p_g(x)}\right]
\]</span></p>
<p>This can be rewritten as:</p>
<p><span class="math display">\[
\min_G V(G) = -\log 4 + 2 \cdot \text{JSD}(p_{data} \| p_g)
\]</span></p>
<p>Where <span class="math inline">\(\text{JSD}\)</span> is the Jensen-Shannon divergence, which measures the similarity between two probability distributions. The generator thus aims to minimize the Jensen-Shannon divergence between the real data distribution <span class="math inline">\(p_{data}\)</span> and the generated data distribution <span class="math inline">\(p_g\)</span>.</p>
</section>
</section>
</section>
<section id="vanilla-gan-and-its-variants" class="level2">
<h2 class="anchored" data-anchor-id="vanilla-gan-and-its-variants">Vanilla GAN and Its Variants</h2>
<section id="vanilla-gan" class="level3">
<h3 class="anchored" data-anchor-id="vanilla-gan">Vanilla GAN</h3>
<p>The original GAN proposed by Goodfellow et al.&nbsp;uses fully connected layers for both the generator and discriminator. It suffers from training instability and mode collapse issues.</p>
<section id="training-instability" class="level4">
<h4 class="anchored" data-anchor-id="training-instability"><strong>Training Instability</strong></h4>
<p>Training instability arises due to the nature of the minimax game. If the discriminator becomes too good, the generator receives vanishing gradients and struggles to learn. Conversely, if the generator produces realistic data early on, the discriminator fails to improve.</p>
</section>
<section id="mode-collapse" class="level4">
<h4 class="anchored" data-anchor-id="mode-collapse"><strong>Mode Collapse</strong></h4>
<p>Mode collapse occurs when the generator produces a limited variety of outputs, failing to capture the diversity of the real data distribution. This happens when the generator finds a few modes that consistently fool the discriminator, ignoring other modes.</p>
</section>
</section>
<section id="dcgan-deep-convolutional-gan" class="level3">
<h3 class="anchored" data-anchor-id="dcgan-deep-convolutional-gan">DCGAN (Deep Convolutional GAN)</h3>
<p>DCGANs introduce convolutional and transposed convolutional layers in the discriminator and generator, respectively. Key improvements include:</p>
<ul>
<li><strong>Strided convolutions</strong>: Used instead of pooling layers to downsample images in the discriminator and upsample images in the generator.</li>
<li><strong>Batch normalization</strong>: Applied in both networks to stabilize training and accelerate convergence.</li>
<li><strong>ReLU activation</strong>: Used in the generator (except for the output layer, which uses tanh).</li>
<li><strong>LeakyReLU activation</strong>: Used in the discriminator to allow a small gradient when the unit is not active.</li>
</ul>
<section id="dcgan-architecture" class="level4">
<h4 class="anchored" data-anchor-id="dcgan-architecture"><strong>DCGAN Architecture</strong></h4>
<p><strong>Discriminator</strong>:</p>
<ul>
<li><strong>Input</strong>: Image of size (64, 64, 3)</li>
<li><strong>Convolutional layers</strong>: Feature extraction using strided convolutions</li>
<li><strong>LeakyReLU activation</strong>: Introduces non-linearity</li>
<li><strong>Batch normalization</strong>: Stabilizes training</li>
<li><strong>Fully connected layer</strong>: Outputs a single probability value</li>
</ul>
<p><strong>Generator</strong>:</p>
<ul>
<li><strong>Input</strong>: Random noise vector (e.g., 100-dimensional)</li>
<li><strong>Fully connected layer</strong>: Transforms noise vector to a suitable shape for convolutional operations</li>
<li><strong>Transposed convolutional layers</strong>: Upsample to the desired image size</li>
<li><strong>ReLU activation</strong>: Used in all layers except the output</li>
<li><strong>Output layer</strong>: Uses tanh activation to produce the final image</li>
</ul>
</section>
</section>
<section id="wgan-wasserstein-gan" class="level3">
<h3 class="anchored" data-anchor-id="wgan-wasserstein-gan">WGAN (Wasserstein GAN)</h3>
<p>WGANs address the issue of vanishing gradients and mode collapse by using the Wasserstein distance instead of the Jensen-Shannon divergence. The objective function becomes:</p>
<p><span class="math display">\[
\min_G \max_{D \in \mathcal{D}} \mathbb{E}_{x \sim p_{data}(x)}[D(x)] - \mathbb{E}_{z \sim p_z(z)}[D(G(z))]
\]</span></p>
<p>Where <span class="math inline">\(\mathcal{D}\)</span> is the set of 1-Lipschitz functions. WGANs use weight clipping or gradient penalty to enforce the Lipschitz constraint.</p>
<section id="wasserstein-distance" class="level4">
<h4 class="anchored" data-anchor-id="wasserstein-distance"><strong>Wasserstein Distance</strong></h4>
<p>The Wasserstein distance (or Earth Mover’s distance) measures the cost of transforming one distribution into another. It provides meaningful gradients even when the distributions do not overlap, leading to more stable training.</p>
<p>Mathematically, the Wasserstein distance <span class="math inline">\(W(p_{data}, p_g)\)</span> between two distributions <span class="math inline">\(p_{data}\)</span> and <span class="math inline">\(p_g\)</span> is defined as:</p>
<p><span class="math display">\[
W(p_{data}, p_g) = \inf_{\gamma \in \Pi(p_{data}, p_g)} \mathbb{E}_{(x, y) \sim \gamma} [\| x - y \|]
\]</span></p>
<p>Where <span class="math inline">\(\Pi(p_{data}, p_g)\)</span> denotes the set of all joint distributions <span class="math inline">\(\gamma(x, y)\)</span> whose marginals are <span class="math inline">\(p_{data}\)</span> and <span class="math inline">\(p_g\)</span>, respectively.</p>
</section>
<section id="gradient-penalty" class="level4">
<h4 class="anchored" data-anchor-id="gradient-penalty"><strong>Gradient Penalty</strong></h4>
<p>To enforce the Lipschitz constraint, WGAN-GP (WGAN with Gradient Penalty) adds a penalty term to the discriminator loss:</p>
<p><span class="math display">\[
L_D = \mathbb{E}_{\tilde{x} \sim p_g}[D(\tilde{x})] - \mathbb{E}_{x \sim p_r}[D(x)] + \lambda \mathbb{E}_{\hat{x} \sim p_{\hat{x}}}[(\|\nabla_{\hat{x}}D(\hat{x})\|_2 - 1)^2]
\]</span></p>
<p>Where <span class="math inline">\(\hat{x}\)</span> is sampled uniformly along straight lines between pairs of real and generated samples. This term penalizes the gradient norm <span class="math inline">\(\|\nabla_{\hat{x}}D(\hat{x})\|_2\)</span> when it deviates from 1, enforcing the Lipschitz constraint more effectively than weight clipping.</p>
</section>
</section>
<section id="lsgan-least-squares-gan" class="level3">
<h3 class="anchored" data-anchor-id="lsgan-least-squares-gan">LSGAN (Least Squares GAN)</h3>
<p>LSGANs replace the binary cross-entropy loss with a least squares loss function:</p>
<p><span class="math display">\[
\min_D V_{LSGAN}(D) = \frac{1}{2}\mathbb{E}_{x \sim p_{data}(x)}[(D(x) - b)^2] + \frac{1}{2}\mathbb{E}_{z \sim p_z(z)}[(D(G(z)) - a)^2]
\]</span></p>
<p><span class="math display">\[
\min_G V_{LSGAN}(G) = \frac{1}{2}\mathbb{E}_{z \sim p_z(z)}[(D(G(z)) - c)^2]
\]</span></p>
<p>Where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are the labels for fake and real data, respectively, and <span class="math inline">\(c\)</span> is the value that <span class="math inline">\(G\)</span> wants <span class="math inline">\(D\)</span> to believe for fake data. This approach provides more stable gradients during training.</p>
<section id="least-squares-loss" class="level4">
<h4 class="anchored" data-anchor-id="least-squares-loss"><strong>Least Squares Loss</strong></h4>
<p>The least squares loss penalizes samples that are classified with high confidence but are incorrect. This results in smoother gradients and more stable training.</p>
</section>
</section>
<section id="cgan-conditional-gan" class="level3">
<h3 class="anchored" data-anchor-id="cgan-conditional-gan">CGAN (Conditional GAN)</h3>
<p>CGANs introduce conditional information to both the generator and discriminator, allowing for controlled generation. The objective function becomes:</p>
<p><span class="math display">\[
\min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x|y)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z|y)))]
\]</span></p>
<p>Where <span class="math inline">\(y\)</span> is the conditional information (e.g., class labels). This enables the generation of samples with specific attributes or characteristics.</p>
<section id="conditional-information" class="level4">
<h4 class="anchored" data-anchor-id="conditional-information"><strong>Conditional Information</strong></h4>
<p>Conditional information can be class labels, attributes, or any other data that the model should condition on. This allows for more controlled and targeted data generation.</p>
</section>
</section>
<section id="acgan-auxiliary-classifier-gan" class="level3">
<h3 class="anchored" data-anchor-id="acgan-auxiliary-classifier-gan">ACGAN (Auxiliary Classifier GAN)</h3>
<p>ACGANs extend CGANs by adding an auxiliary classifier to the discriminator, which predicts the class label of the input data. This modification improves the quality of the generated samples and allows for better interpretation of the conditional information.</p>
<p><span class="math display">\[
\min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x|y) + \log P(C = y|x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z|y))) + \log P(C = y|G(z|y))]
\]</span></p>
<p>Where <span class="math inline">\(P(C = y|x)\)</span> is the probability that the input <span class="math inline">\(x\)</span> belongs to class <span class="math inline">\(y\)</span>. The generator aims to produce samples that are both realistic and classified correctly by the auxiliary classifier.</p>
</section>
</section>
<section id="discriminator-and-generator-networks" class="level2">
<h2 class="anchored" data-anchor-id="discriminator-and-generator-networks">Discriminator and Generator Networks</h2>
<p>The discriminator and generator networks in GANs are typically implemented as deep neural networks:</p>
<section id="discriminator" class="level3">
<h3 class="anchored" data-anchor-id="discriminator">Discriminator</h3>
<p>The discriminator network is designed to classify inputs as real or fake. Its architecture typically includes:</p>
<ul>
<li><strong>Input layer</strong>: Takes real or generated samples.</li>
<li><strong>Convolutional layers</strong>: For images, these layers extract hierarchical features.</li>
<li><strong>Fully connected layers</strong>: Map the extracted features to a single output.</li>
<li><strong>Output layer</strong>: Produces a probability score indicating the likelihood that the input is real.</li>
</ul>
</section>
<section id="generator" class="level3">
<h3 class="anchored" data-anchor-id="generator">Generator</h3>
<p>The generator network is designed to produce samples that resemble the training data. Its architecture typically includes:</p>
<ul>
<li><strong>Input layer</strong>: Takes a random noise vector.</li>
<li><strong>Transposed convolutional layers</strong>: For images, these layers upsample the noise vector to the desired output size.</li>
<li><strong>Fully connected layers</strong>: Map the noise vector to the data space.</li>
<li><strong>Output layer</strong>: Produces samples in the same format as real data.</li>
</ul>
</section>
<section id="residual-networks-resnets-in-gans" class="level3">
<h3 class="anchored" data-anchor-id="residual-networks-resnets-in-gans"><strong>Residual Networks (ResNets) in GANs</strong></h3>
<p>Residual networks incorporate skip connections, allowing gradients to flow more easily through deeper networks. This helps address the vanishing gradient problem and stabilizes training.</p>
<ul>
<li><strong>Residual Blocks</strong>: Incorporate skip connections and batch normalization to improve gradient flow and convergence.</li>
<li><strong>Generator</strong>: Uses residual blocks to upsample the noise vector.</li>
<li><strong>Discriminator</strong>: Uses residual blocks to extract features from the input data.</li>
</ul>
</section>
<section id="attention-mechanisms-in-gans" class="level3">
<h3 class="anchored" data-anchor-id="attention-mechanisms-in-gans"><strong>Attention Mechanisms in GANs</strong></h3>
<p>Attention mechanisms allow the model to focus on different parts of the input data, capturing long-range dependencies and improving the quality of generated samples.</p>
<ul>
<li><strong>Self-Attention Layers</strong>: Compute attention scores between all pairs of positions in the input, allowing the model to weigh the importance of different regions.</li>
<li><strong>Generator</strong>: Uses self-attention layers to capture global dependencies in the generated samples.</li>
<li><strong>Discriminator</strong>: Uses self-attention layers to improve feature extraction and classification.</li>
</ul>
</section>
</section>
<section id="training-stability-and-convergence-issues" class="level2">
<h2 class="anchored" data-anchor-id="training-stability-and-convergence-issues">Training Stability and Convergence Issues</h2>
<p>GANs are notoriously difficult to train due to several issues:</p>
<ol type="1">
<li><strong>Mode collapse</strong>: The generator produces limited varieties of samples.</li>
<li><strong>Vanishing gradients</strong>: The discriminator becomes too good, providing no useful gradient for the generator.</li>
<li><strong>Non-convergence</strong>: The generator and discriminator fail to reach equilibrium.</li>
<li><strong>Balancing generator and discriminator training</strong>: One network may overpower the other, leading to poor results.</li>
</ol>
<section id="mode-collapse-1" class="level3">
<h3 class="anchored" data-anchor-id="mode-collapse-1">Mode Collapse</h3>
<p>Mode collapse occurs when the generator produces only a few types of outputs. This happens because the generator finds a way to fool the discriminator with limited variations of samples. The discriminator, in turn, fails to learn to distinguish between different modes of the data.</p>
</section>
<section id="vanishing-gradients" class="level3">
<h3 class="anchored" data-anchor-id="vanishing-gradients">Vanishing Gradients</h3>
<p>When the discriminator becomes too good at distinguishing real from fake data, the generator receives gradients that are too small to make significant updates. This issue arises because the discriminator’s loss function approaches zero, leading to minimal gradients.</p>
</section>
<section id="non-convergence" class="level3">
<h3 class="anchored" data-anchor-id="non-convergence">Non-Convergence</h3>
<p>GANs may not converge to a stable point where the generator produces realistic data, and the discriminator cannot distinguish between real and fake data. Instead, they may oscillate or diverge, resulting in poor-quality generated data.</p>
</section>
<section id="balancing-generator-and-discriminator-training" class="level3">
<h3 class="anchored" data-anchor-id="balancing-generator-and-discriminator-training">Balancing Generator and Discriminator Training</h3>
<p>If one network (either the generator or the discriminator) overpowers the other, it can hinder the training process. For example, if the discriminator becomes too strong, the generator cannot learn effectively. Conversely, if the generator becomes too good too quickly, the discriminator cannot catch up.</p>
</section>
<section id="evaluation-metrics-for-gans" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-metrics-for-gans"><strong>Evaluation Metrics for GANs</strong></h3>
<p>Evaluating GANs is challenging due to the subjective nature of visual quality. However, several metrics have been developed to quantify the performance of GANs:</p>
<ul>
<li><strong>Inception Score (IS)</strong>: Measures the quality and diversity of generated samples using a pre-trained Inception network.</li>
<li><strong>Fréchet Inception Distance (FID)</strong>: Computes the distance between the feature distributions of real and generated samples, providing a measure of sample quality and diversity.</li>
<li><strong>Precision and Recall for GANs</strong>: Quantify the fidelity and diversity of generated samples by comparing the distributions of real and generated data.</li>
</ul>
</section>
</section>
<section id="techniques-for-improving-gan-performance" class="level2">
<h2 class="anchored" data-anchor-id="techniques-for-improving-gan-performance">Techniques for Improving GAN Performance</h2>
<section id="minibatch-discrimination" class="level3">
<h3 class="anchored" data-anchor-id="minibatch-discrimination">Minibatch Discrimination</h3>
<p>Minibatch discrimination helps prevent mode collapse by allowing the discriminator to look at multiple examples in combination, rather than in isolation. This is achieved by adding a layer to the discriminator that computes features across samples in a minibatch.</p>
<section id="implementation" class="level4">
<h4 class="anchored" data-anchor-id="implementation"><strong>Implementation</strong></h4>
<p>A minibatch discrimination layer computes the distances between each pair of samples in the minibatch and produces a feature vector that depends on the distances. This allows the discriminator to consider the diversity of the generated samples.</p>
</section>
</section>
<section id="historical-averaging" class="level3">
<h3 class="anchored" data-anchor-id="historical-averaging">Historical Averaging</h3>
<p>Historical averaging involves keeping track of the historical average of the model parameters and adding a regularization term to the objective function:</p>
<p><span class="math display">\[
\theta_t = \theta_t + \eta(\theta - \frac{1}{t}\sum_{i=1}^t \theta_i)
\]</span></p>
<p>Where <span class="math inline">\(\theta_t\)</span> are the current parameters, and <span class="math inline">\(\theta_i\)</span> are the historical parameters. This technique helps stabilize training by encouraging smooth parameter updates.</p>
</section>
<section id="gradient-penalty-1" class="level3">
<h3 class="anchored" data-anchor-id="gradient-penalty-1">Gradient Penalty</h3>
<p>Gradient penalty is an alternative to weight clipping in WGANs. It adds a penalty term to the discriminator loss:</p>
<p><span class="math display">\[
L_D = \mathbb{E}_{\tilde{x} \sim p_g}[D(\tilde{x})] - \mathbb{E}_{x \sim p_r}[D(x)] + \lambda \mathbb{E}_{\hat{x} \sim p_{\hat{x}}}[(\|\nabla_{\hat{x}}D(\hat{x})\|_2 - 1)^2]
\]</span></p>
<p>Where <span class="math inline">\(\hat{x}\)</span> is sampled uniformly along straight lines between pairs of real and generated samples. This technique enforces the Lipschitz constraint more effectively than weight clipping and improves training stability.</p>
</section>
<section id="spectral-normalization" class="level3">
<h3 class="anchored" data-anchor-id="spectral-normalization">Spectral Normalization</h3>
<p>Spectral normalization is another technique to enforce the Lipschitz constraint. It normalizes the spectral norm of each layer’s weight matrix, ensuring that the discriminator remains within the Lipschitz continuity bounds. This helps stabilize the training process and prevents the discriminator from becoming too powerful.</p>
</section>
<section id="two-timescale-update-rule-ttur" class="level3">
<h3 class="anchored" data-anchor-id="two-timescale-update-rule-ttur">Two-Timescale Update Rule (TTUR)</h3>
<p>TTUR involves updating the discriminator and generator with different learning rates. Typically, the discriminator is updated more frequently or with a higher learning rate than the generator. This helps balance the training dynamics and prevents one network from overpowering the other.</p>
</section>
<section id="self-attention-mechanisms" class="level3">
<h3 class="anchored" data-anchor-id="self-attention-mechanisms">Self-Attention Mechanisms</h3>
<p>Self-attention mechanisms allow the model to focus on different parts of the input data, capturing long-range dependencies and improving the quality of generated samples. This is particularly useful for high-resolution image generation, where spatial relationships are crucial.</p>
<section id="self-attention-in-gans" class="level4">
<h4 class="anchored" data-anchor-id="self-attention-in-gans"><strong>Self-Attention in GANs</strong></h4>
<p>Self-attention layers compute attention scores between all pairs of positions in the input, allowing the model to weigh the importance of different regions. This enhances the ability of the model to capture global dependencies.</p>
</section>
</section>
<section id="progressive-growing-of-gans" class="level3">
<h3 class="anchored" data-anchor-id="progressive-growing-of-gans">Progressive Growing of GANs</h3>
<p>Progressive growing involves starting with low-resolution images and gradually increasing the resolution during training. This technique helps stabilize training and allows the generator to learn coarse-to-fine details, resulting in higher-quality images.</p>
<section id="implementation-1" class="level4">
<h4 class="anchored" data-anchor-id="implementation-1"><strong>Implementation</strong></h4>
<ol type="1">
<li>Start with a small image resolution (e.g., 4x4).</li>
<li>Train the GAN on this resolution.</li>
<li>Gradually add layers to both the generator and discriminator to increase the resolution.</li>
<li>Continue training on higher resolutions until the desired resolution is reached.</li>
</ol>
</section>
</section>
<section id="adaptive-learning-rates" class="level3">
<h3 class="anchored" data-anchor-id="adaptive-learning-rates">Adaptive Learning Rates</h3>
<p>Adaptive learning rates adjust the learning rate dynamically based on the training progress. Techniques like the Adam optimizer with adaptive moment estimation help maintain stable training and convergence.</p>
</section>
<section id="other-techniques" class="level3">
<h3 class="anchored" data-anchor-id="other-techniques">Other Techniques</h3>
<ul>
<li><strong>Feature Matching</strong>: Matching the intermediate features of real and generated samples to improve the quality of generated data.</li>
<li><strong>Virtual Batch Normalization</strong>: Normalizing each sample with respect to a reference batch to reduce batch dependence.</li>
<li><strong>Noise Injection</strong>: Adding noise to the inputs of the discriminator to improve robustness and prevent overfitting.</li>
</ul>
<p>These advanced techniques have led to significant improvements in the quality and stability of GAN training, enabling the generation of highly realistic samples across various domains.</p>
</section>
</section>
</section>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>