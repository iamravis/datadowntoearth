<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.47">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ravi Shankar">

<title>autoregressive_models – Data Down To Earth</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../logo.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
<link rel="stylesheet" href="../../content.css">
<meta property="og:title" content="– Data Down To Earth">
<meta property="og:site_name" content="Data Down To Earth">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Data Down To Earth</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projects" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Projects</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-projects">    
        <li>
    <a class="dropdown-item" href="../../../projects/dsml_projects.html">
 <span class="dropdown-text">Data Science and ML Projects</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../projects/genai_projects.html">
 <span class="dropdown-text">Generative AI Projects</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-tutorials" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Tutorials</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-tutorials">    
        <li>
    <a class="dropdown-item" href="../../../topics/statistics.html">
 <span class="dropdown-text">Statistics &amp; Probability</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/machine_learning.html">
 <span class="dropdown-text">Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/de.html">
 <span class="dropdown-text">Data Engineering</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/generative_ai.html">
 <span class="dropdown-text">Generative AI</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/public_health.html">
 <span class="dropdown-text">Public Health</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/product_sense.html">
 <span class="dropdown-text">Product Sense</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../blogs/blogs.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/iamrsps"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/iamravishankar/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content column-page" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
</div>



<div class="quarto-title-meta column-page">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ravi Shankar </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="chapter-15-autoregressive-models" class="level1 text-content">
<h1>Chapter 15: Autoregressive Models</h1>
<section id="autoregressive-models" class="level2">
<h2 class="anchored" data-anchor-id="autoregressive-models">Autoregressive Models</h2>
<p>Autoregressive models are a class of generative models that predict the next element in a sequence based on previous elements. They are widely used in various domains such as text, image, and audio generation.</p>
</section>
<section id="modeling-sequences-with-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="modeling-sequences-with-dependencies">1. Modeling Sequences with Dependencies</h2>
<p>Autoregressive models capture dependencies between elements in a sequence by conditioning the prediction of each element on the previous elements.</p>
<section id="autoregressive-property" class="level3">
<h3 class="anchored" data-anchor-id="autoregressive-property">1.1 Autoregressive Property</h3>
<p>The core principle of autoregressive models is the factorization of the joint probability of a sequence into a product of conditional probabilities:</p>
<p><span class="math display">\[
p(x_1, x_2, \ldots, x_T) = \prod_{t=1}^T p(x_t | x_{1:t-1})
\]</span></p>
<p>Where <span class="math inline">\(x_t\)</span> is the element at time step <span class="math inline">\(t\)</span> and <span class="math inline">\(x_{1:t-1}\)</span> represents all previous elements. This factorization allows the model to generate sequences by sampling each element conditioned on the past elements.</p>
</section>
<section id="training-objective" class="level3">
<h3 class="anchored" data-anchor-id="training-objective">1.2 Training Objective</h3>
<p>The training objective is to maximize the likelihood of the observed data, which is equivalent to minimizing the negative log-likelihood:</p>
<p><span class="math display">\[
\mathcal{L}(\theta) = -\sum_{t=1}^T \log p_\theta(x_t | x_{1:t-1})
\]</span></p>
<p>Where <span class="math inline">\(\theta\)</span> represents the model parameters. By maximizing this likelihood, the model learns to predict each element in the sequence based on the preceding elements.</p>
</section>
<section id="challenges-in-modeling-dependencies" class="level3">
<h3 class="anchored" data-anchor-id="challenges-in-modeling-dependencies">1.3 Challenges in Modeling Dependencies</h3>
<ol type="1">
<li><strong>Long-Range Dependencies</strong>: Capturing dependencies over long sequences can be challenging due to the vanishing gradient problem. This issue occurs because gradients propagated through long sequences tend to diminish, making it difficult for the model to learn long-range relationships.</li>
<li><strong>Computational Complexity</strong>: Autoregressive models often require sequential processing, which can be computationally intensive, especially for long sequences. Each element must be predicted in order, limiting parallelization.</li>
<li><strong>Data Sparsity</strong>: Sparse data can make it difficult to learn accurate conditional distributions. In high-dimensional spaces, many possible sequences may be underrepresented in the training data.</li>
</ol>
</section>
</section>
<section id="transformers-and-self-attention" class="level2">
<h2 class="anchored" data-anchor-id="transformers-and-self-attention">2. Transformers and Self-Attention</h2>
<p>Transformers have revolutionized autoregressive modeling by introducing self-attention mechanisms, which allow the model to capture dependencies across the entire sequence.</p>
<section id="self-attention-mechanism" class="level3">
<h3 class="anchored" data-anchor-id="self-attention-mechanism">2.1 Self-Attention Mechanism</h3>
<p>Self-attention computes a weighted sum of the input elements, where the weights are determined by the similarity between elements:</p>
<p><span class="math display">\[
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\]</span></p>
<p>Where <span class="math inline">\(Q\)</span>, <span class="math inline">\(K\)</span>, and <span class="math inline">\(V\)</span> are query, key, and value matrices derived from the input, and <span class="math inline">\(d_k\)</span> is the dimensionality of the key vectors.</p>
<section id="scaled-dot-product-attention" class="level4">
<h4 class="anchored" data-anchor-id="scaled-dot-product-attention">2.1.1 Scaled Dot-Product Attention</h4>
<p>Scaled dot-product attention is the most common form of self-attention:</p>
<p><span class="math display">\[
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\]</span></p>
<p>The scaling factor <span class="math inline">\(\sqrt{d_k}\)</span> helps to mitigate the issue of small gradients for large values of <span class="math inline">\(d_k\)</span>.</p>
</section>
<section id="multi-head-attention" class="level4">
<h4 class="anchored" data-anchor-id="multi-head-attention">2.1.2 Multi-Head Attention</h4>
<p>Multi-head attention allows the model to attend to different parts of the input simultaneously:</p>
<p><span class="math display">\[
\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h)W^O
\]</span></p>
<p>Where each head is computed as:</p>
<p><span class="math display">\[
\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)
\]</span></p>
<p>This mechanism enables the model to capture various types of dependencies by using different learned projections <span class="math inline">\(W_i^Q\)</span>, <span class="math inline">\(W_i^K\)</span>, and <span class="math inline">\(W_i^V\)</span> for each head.</p>
</section>
</section>
<section id="transformer-architecture" class="level3">
<h3 class="anchored" data-anchor-id="transformer-architecture">2.2 Transformer Architecture</h3>
<p>The Transformer architecture consists of an encoder and a decoder, both built using self-attention layers and feed-forward networks.</p>
<section id="encoder" class="level4">
<h4 class="anchored" data-anchor-id="encoder">2.2.1 Encoder</h4>
<p>The encoder processes the input sequence using self-attention and feed-forward layers:</p>
<p><span class="math display">\[
\text{Encoder}(x) = \text{SelfAttention}(x) + \text{FeedForward}(x)
\]</span></p>
<p>The self-attention layer allows each element to attend to all other elements in the sequence, while the feed-forward layer applies a non-linear transformation to each position independently.</p>
</section>
<section id="decoder" class="level4">
<h4 class="anchored" data-anchor-id="decoder">2.2.2 Decoder</h4>
<p>The decoder generates the output sequence by attending to both the input sequence and the previously generated output:</p>
<p><span class="math display">\[
\text{Decoder}(y, x) = \text{SelfAttention}(y) + \text{CrossAttention}(y, x) + \text{FeedForward}(y)
\]</span></p>
<p>The cross-attention mechanism allows the decoder to focus on relevant parts of the input sequence, enabling the generation of contextually appropriate outputs.</p>
</section>
</section>
</section>
<section id="generating-coherent-and-long-range-text" class="level2">
<h2 class="anchored" data-anchor-id="generating-coherent-and-long-range-text">3. Generating Coherent and Long-Range Text</h2>
<p>Autoregressive models have been highly successful in generating coherent and long-range text. Some notable models include GPT, CTRL, and Megatron-LM.</p>
<section id="gpt-generative-pre-trained-transformer" class="level3">
<h3 class="anchored" data-anchor-id="gpt-generative-pre-trained-transformer">3.1 GPT (Generative Pre-trained Transformer)</h3>
<p>GPT is a transformer-based model pre-trained on a large corpus of text and fine-tuned for specific tasks.</p>
<section id="gpt-architecture" class="level4">
<h4 class="anchored" data-anchor-id="gpt-architecture">3.1.1 GPT Architecture</h4>
<p>GPT uses a stack of transformer decoder layers:</p>
<p><span class="math display">\[
\text{GPT}(x) = \text{DecoderStack}(x)
\]</span></p>
<p>Each layer in the decoder stack includes self-attention and feed-forward sub-layers.</p>
</section>
<section id="training-objective-1" class="level4">
<h4 class="anchored" data-anchor-id="training-objective-1">3.1.2 Training Objective</h4>
<p>GPT is trained using a language modeling objective:</p>
<p><span class="math display">\[
\mathcal{L}(\theta) = -\sum_{t=1}^T \log p_\theta(x_t | x_{1:t-1})
\]</span></p>
<p>This objective encourages the model to learn the conditional distributions of text sequences, allowing it to generate coherent and contextually relevant text.</p>
</section>
</section>
<section id="ctrl-conditional-transformer-language-model" class="level3">
<h3 class="anchored" data-anchor-id="ctrl-conditional-transformer-language-model">3.2 CTRL (Conditional Transformer Language Model)</h3>
<p>CTRL is designed to generate text conditioned on control codes, allowing for more controlled text generation.</p>
<section id="control-codes" class="level4">
<h4 class="anchored" data-anchor-id="control-codes">3.2.1 Control Codes</h4>
<p>Control codes are special tokens that guide the generation process:</p>
<p><span class="math display">\[
\text{CTRL}(c, x) = \text{DecoderStack}(c \oplus x)
\]</span></p>
<p>Where <span class="math inline">\(c\)</span> is the control code and <span class="math inline">\(\oplus\)</span> denotes concatenation. These codes can represent different styles, topics, or other guiding factors.</p>
</section>
<section id="training-objective-2" class="level4">
<h4 class="anchored" data-anchor-id="training-objective-2">3.2.2 Training Objective</h4>
<p>CTRL is trained to maximize the likelihood of the text given the control codes:</p>
<p><span class="math display">\[
\mathcal{L}(\theta) = -\sum_{t=1}^T \log p_\theta(x_t | c, x_{1:t-1})
\]</span></p>
<p>This objective allows the model to generate text that adheres to the specified control codes, enabling more targeted and customizable text generation.</p>
</section>
</section>
<section id="megatron-lm" class="level3">
<h3 class="anchored" data-anchor-id="megatron-lm">3.3 Megatron-LM</h3>
<p>Megatron-LM is a large-scale transformer model designed for efficient training on massive datasets.</p>
<section id="model-parallelism" class="level4">
<h4 class="anchored" data-anchor-id="model-parallelism">3.3.1 Model Parallelism</h4>
<p>Megatron-LM uses model parallelism to distribute the model across multiple GPUs:</p>
<p><span class="math display">\[
\text{Megatron}(x) = \text{ParallelDecoderStack}(x)
\]</span></p>
<p>Model parallelism enables the training of very large models by splitting the computation across several devices.</p>
</section>
<section id="training-objective-3" class="level4">
<h4 class="anchored" data-anchor-id="training-objective-3">3.3.2 Training Objective</h4>
<p>Megatron-LM is trained using a language modeling objective similar to GPT:</p>
<p><span class="math display">\[
\mathcal{L}(\theta) = -\sum_{t=1}^T \log p_\theta(x_t | x_{1:t-1})
\]</span></p>
<p>The large scale and efficient parallelism allow Megatron-LM to handle extensive datasets, improving its performance on a variety of text generation tasks.</p>
</section>
</section>
</section>
<section id="autoregressive-models-for-image-generation" class="level2">
<h2 class="anchored" data-anchor-id="autoregressive-models-for-image-generation">4. Autoregressive Models for Image Generation</h2>
<p>Autoregressive models have also been applied to image generation, where they generate images pixel by pixel.</p>
<section id="pixelcnn" class="level3">
<h3 class="anchored" data-anchor-id="pixelcnn">4.1 PixelCNN</h3>
<p>PixelCNN generates images by modeling the conditional distribution of each pixel given the previous pixels.</p>
<section id="pixelcnn-architecture" class="level4">
<h4 class="anchored" data-anchor-id="pixelcnn-architecture">4.1.1 PixelCNN Architecture</h4>
<p>PixelCNN uses convolutional layers with masked filters to ensure that each pixel is only conditioned on previous pixels:</p>
<p><span class="math display">\[
\text{PixelCNN}(x) = \text{MaskedConv}(x)
\]</span></p>
<p>Masked convolutions prevent information from future pixels from being used in the generation of the current pixel.</p>
</section>
<section id="training-objective-4" class="level4">
<h4 class="anchored" data-anchor-id="training-objective-4">4.1.2 Training Objective</h4>
<p>PixelCNN is trained to maximize the likelihood of the image pixels:</p>
<p><span class="math display">\[
\mathcal{L}(\theta) = -\sum_{i=1}^H \sum_{j=1}^W \log p_\theta(x_{i,j} | x_{1:i-1,1:W}, x_{i,1:j-1})
\]</span></p>
<p>This objective ensures that the model learns to generate each pixel based on the context provided by the preceding pixels.</p>
</section>
</section>
<section id="pixelsnail" class="level3">
<h3 class="anchored" data-anchor-id="pixelsnail">4.2 PixelSNAIL</h3>
<p>PixelSNAIL extends PixelCNN by incorporating self-attention mechanisms to capture long-range dependencies.</p>
<section id="pixelsnail-architecture" class="level4">
<h4 class="anchored" data-anchor-id="pixelsnail-architecture">4.2.1 PixelSNAIL Architecture</h4>
<p>PixelSNAIL combines masked convolutions with self-attention layers:</p>
<p><span class="math display">\[
\text{PixelSNAIL}(x) = \text{MaskedConv}(x) + \text{SelfAttention}(x)
\]</span></p>
<p>The self-attention layers allow the model to capture dependencies across the entire image, improving the generation of coherent structures.</p>
</section>
<section id="training-objective-5" class="level4">
<h4 class="anchored" data-anchor-id="training-objective-5">4.2.2 Training Objective</h4>
<p>PixelSNAIL is trained to maximize the likelihood of the image pixels:</p>
<p><span class="math display">\[
\mathcal{L}(\theta) = -\sum_{i=1}^H \sum_{j=1}^W \log p_\theta(x_{i,j} | x_{1:i-1,1:W}, x_{i,1:j-1})
\]</span></p>
<p>The inclusion of self-attention helps the model generate more globally consistent images.</p>
</section>
</section>
<section id="spn-sparse-pixel-network" class="level3">
<h3 class="anchored" data-anchor-id="spn-sparse-pixel-network">4.3 SPN (Sparse Pixel Network)</h3>
<p>SPN introduces sparsity in the autoregressive model to improve efficiency.</p>
<section id="sparse-connections" class="level4">
<h4 class="anchored" data-anchor-id="sparse-connections">4.3.1 Sparse Connections</h4>
<p>SPN uses sparse connections to reduce the computational complexity:</p>
<p><span class="math display">\[
\text{SPN}(x) = \text{SparseMaskedConv}(x)
\]</span></p>
<p>Sparse connections limit the number of interactions between pixels, making the model more computationally efficient.</p>
</section>
<section id="training-objective-6" class="level4">
<h4 class="anchored" data-anchor-id="training-objective-6">4.3.2 Training Objective</h4>
<p>SPN is trained to maximize the likelihood of the image pixels:</p>
<p><span class="math display">\[
\mathcal{L}(\theta) = -\sum_{i=1}^H \sum_{j=1}^W \log p_\theta(x_{i,j} | x_{1:i-1,1:W}, x_{i,1:j-1})
\]</span></p>
<p>By focusing on sparsely connected regions, SPN achieves a balance between accuracy and computational efficiency.</p>
</section>
</section>
</section>
<section id="techniques-for-improving-autoregressive-models" class="level2">
<h2 class="anchored" data-anchor-id="techniques-for-improving-autoregressive-models">5. Techniques for Improving Autoregressive Models</h2>
<p>Several techniques have been developed to improve the performance of autoregressive models.</p>
<section id="sparse-attention" class="level3">
<h3 class="anchored" data-anchor-id="sparse-attention">5.1 Sparse Attention</h3>
<p>Sparse attention mechanisms reduce the computational complexity of self-attention by focusing on a subset of relevant elements.</p>
<section id="local-attention" class="level4">
<h4 class="anchored" data-anchor-id="local-attention">5.1.1 Local Attention</h4>
<p>Local attention restricts the attention mechanism to a local window around each element:</p>
<p><span class="math display">\[
\text{LocalAttention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\]</span></p>
<p>Where <span class="math inline">\(Q\)</span>, <span class="math inline">\(K\)</span>, and <span class="math inline">\(V\)</span> are restricted to a local window. This reduces the computational cost while capturing local dependencies effectively.</p>
</section>
<section id="strided-attention" class="level4">
<h4 class="anchored" data-anchor-id="strided-attention">5.1.2 Strided Attention</h4>
<p>Strided attention attends to elements at regular intervals, reducing the number of computations:</p>
<p><span class="math display">\[
\text{StridedAttention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\]</span></p>
<p>Where <span class="math inline">\(Q\)</span>, <span class="math inline">\(K\)</span>, and <span class="math inline">\(V\)</span> are sampled at regular intervals. This method balances the trade-off between computational efficiency and capturing dependencies.</p>
</section>
</section>
<section id="local-attention-1" class="level3">
<h3 class="anchored" data-anchor-id="local-attention-1">5.2 Local Attention</h3>
<p>Local attention mechanisms focus on capturing dependencies within a local context.</p>
<section id="sliding-window-attention" class="level4">
<h4 class="anchored" data-anchor-id="sliding-window-attention">5.2.1 Sliding Window Attention</h4>
<p>Sliding window attention applies attention within a sliding window over the sequence:</p>
<p><span class="math display">\[
\text{SlidingWindow}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\]</span></p>
<p>Where <span class="math inline">\(Q\)</span>, <span class="math inline">\(K\)</span>, and <span class="math inline">\(V\)</span> are restricted to the sliding window. This technique ensures that each element only attends to its immediate neighbors, capturing local patterns.</p>
</section>
<section id="dilated-attention" class="level4">
<h4 class="anchored" data-anchor-id="dilated-attention">5.2.2 Dilated Attention</h4>
<p>Dilated attention uses dilated convolutions to capture dependencies at multiple scales:</p>
<p><span class="math display">\[
\text{DilatedAttention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\]</span></p>
<p>Where <span class="math inline">\(Q\)</span>, <span class="math inline">\(K\)</span>, and <span class="math inline">\(V\)</span> are processed with dilated convolutions. This method captures both local and long-range dependencies efficiently.</p>
</section>
</section>
<section id="hierarchical-generation" class="level3">
<h3 class="anchored" data-anchor-id="hierarchical-generation">5.3 Hierarchical Generation</h3>
<p>Hierarchical generation techniques decompose the generation process into multiple levels of abstraction.</p>
<section id="coarse-to-fine-generation" class="level4">
<h4 class="anchored" data-anchor-id="coarse-to-fine-generation">5.3.1 Coarse-to-Fine Generation</h4>
<p>Coarse-to-fine generation generates a coarse representation of the sequence first, followed by finer details:</p>
<p><span class="math display">\[
\text{Coarse}(x) = \text{GenerateCoarse}(x)
\]</span></p>
<p><span class="math display">\[
\text{Fine}(x) = \text{GenerateFine}(x)
\]</span></p>
<p>This hierarchical approach ensures that the global structure is coherent before adding detailed elements.</p>
</section>
<section id="multi-scale-generation" class="level4">
<h4 class="anchored" data-anchor-id="multi-scale-generation">5.3.2 Multi-Scale Generation</h4>
<p>Multi-scale generation generates the sequence at multiple scales simultaneously:</p>
<p><span class="math display">\[
\text{MultiScale}(x) = \text{GenerateMultiScale}(x)
\]</span></p>
<p>Where the sequence is generated at different resolutions and combined. This technique captures both global and local structures effectively.</p>
</section>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Autoregressive models provide a powerful framework for generative modeling, offering both efficient density estimation and sampling. By leveraging dependencies within sequences, they can model complex distributions while maintaining tractability. Recent advancements in architecture design and training techniques have further improved their performance across various domains, making them a valuable tool in the machine learning toolkit.</p>
</section>
</section>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>