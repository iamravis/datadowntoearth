<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.47">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ravi Shankar">

<title>chapter2_data_preprocessing – Data Down To Earth</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../logo.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
<link rel="stylesheet" href="../../content.css">
<meta property="og:title" content="– Data Down To Earth">
<meta property="og:site_name" content="Data Down To Earth">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Data Down To Earth</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projects" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Projects</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-projects">    
        <li>
    <a class="dropdown-item" href="../../../projects/dsml_projects.html">
 <span class="dropdown-text">Data Science and ML Projects</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../projects/genai_projects.html">
 <span class="dropdown-text">Generative AI Projects</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-tutorials" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Tutorials</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-tutorials">    
        <li>
    <a class="dropdown-item" href="../../../topics/statistics.html">
 <span class="dropdown-text">Statistics &amp; Probability</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/machine_learning.html">
 <span class="dropdown-text">Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/de.html">
 <span class="dropdown-text">Data Engineering</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/generative_ai.html">
 <span class="dropdown-text">Generative AI</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/public_health.html">
 <span class="dropdown-text">Public Health</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/product_sense.html">
 <span class="dropdown-text">Product Sense</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../notes/notes.html"> 
<span class="menu-text">Notes &amp; Research</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/iamrsps"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/iamravishankar/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content column-page" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
</div>



<div class="quarto-title-meta column-page">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ravi Shankar </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<div class="text-content">
<section id="data-cleaning" class="level1">
<h1>2.1. Data Cleaning</h1>
<section id="handling-missing-values" class="level2">
<h2 class="anchored" data-anchor-id="handling-missing-values">2.1.1. Handling Missing Values</h2>
<section id="deletion-methods" class="level4">
<h4 class="anchored" data-anchor-id="deletion-methods">2.1.1.1. Deletion Methods</h4>
<ul>
<li><strong>Listwise Deletion</strong>: Removing all data for an observation that has one or more missing values.
<ul>
<li>Pros: Simplifies analysis; no imputation bias.</li>
<li>Cons: Loss of data; can reduce statistical power.</li>
</ul></li>
<li><strong>Pairwise Deletion</strong>: Using all available data points to calculate statistics, even if some observations are missing data.
<ul>
<li>Pros: Retains more data than listwise deletion.</li>
<li>Cons: Can lead to inconsistent sample sizes and biased results.</li>
</ul></li>
</ul>
</section>
<section id="imputation-techniques" class="level4">
<h4 class="anchored" data-anchor-id="imputation-techniques">2.1.1.2. Imputation Techniques</h4>
<ul>
<li><strong>Mean/Median/Mode Imputation</strong>: Replacing missing values with the mean, median, or mode of the observed data.
<ul>
<li>Pros: Simple and quick.</li>
<li>Cons: Can reduce variability; might introduce bias.</li>
</ul></li>
<li><strong>Hot Deck Imputation</strong>: Filling missing values with observed responses from similar respondents.
<ul>
<li>Pros: Maintains data distribution.</li>
<li>Cons: Assumes data similarity; can be computationally intensive.</li>
</ul></li>
<li><strong>Cold Deck Imputation</strong>: Using values from external sources to fill missing data.
<ul>
<li>Pros: Utilizes external reliable data.</li>
<li>Cons: May not be accurate if external data is not well-matched.</li>
</ul></li>
<li><strong>Regression Imputation</strong>: Predicting missing values using regression models based on other variables.
<ul>
<li>Pros: Uses relationships in data.</li>
<li>Cons: Assumes linear relationships; can introduce bias.</li>
</ul></li>
<li><strong>Multiple Imputation</strong>: Creating multiple complete datasets by imputing missing values several times and then combining results.
<ul>
<li>Pros: Reflects uncertainty of missing data; robust statistical properties.</li>
<li>Cons: Complex and computationally intensive.</li>
</ul></li>
<li><strong>K-Nearest Neighbours Imputation</strong>: Imputing values based on the k-nearest neighbours.
<ul>
<li>Pros: Captures local structure in data.</li>
<li>Cons: Computationally intensive for large datasets.</li>
</ul></li>
</ul>
<div id="bb944c82" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> SimpleImputer, KNNImputer</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.experimental <span class="im">import</span> enable_iterative_imputer</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> IterativeImputer</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'A'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, np.nan, <span class="dv">4</span>, <span class="dv">5</span>],</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'B'</span>: [np.nan, <span class="dv">2</span>, <span class="dv">3</span>, np.nan, <span class="dv">5</span>],</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'C'</span>: [<span class="dv">1</span>, np.nan, <span class="dv">3</span>, <span class="dv">4</span>, np.nan]</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.1. Data Cleaning</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.1.1. Handling Missing Values</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.1.1.1. Deletion Methods</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Listwise Deletion</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>df_listwise <span class="op">=</span> df.dropna()</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Pairwise Deletion (example with calculating mean of each column)</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>mean_A <span class="op">=</span> df[<span class="st">'A'</span>].mean(skipna<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>mean_B <span class="op">=</span> df[<span class="st">'B'</span>].mean(skipna<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>mean_C <span class="op">=</span> df[<span class="st">'C'</span>].mean(skipna<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.1.1.2. Imputation Techniques</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Mean/Median/Mode Imputation</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>mean_imputer <span class="op">=</span> SimpleImputer(strategy<span class="op">=</span><span class="st">'mean'</span>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>df_mean_imputed <span class="op">=</span> pd.DataFrame(mean_imputer.fit_transform(df), columns<span class="op">=</span>df.columns)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>median_imputer <span class="op">=</span> SimpleImputer(strategy<span class="op">=</span><span class="st">'median'</span>)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>df_median_imputed <span class="op">=</span> pd.DataFrame(median_imputer.fit_transform(df), columns<span class="op">=</span>df.columns)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>mode_imputer <span class="op">=</span> SimpleImputer(strategy<span class="op">=</span><span class="st">'most_frequent'</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>df_mode_imputed <span class="op">=</span> pd.DataFrame(mode_imputer.fit_transform(df), columns<span class="op">=</span>df.columns)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Hot Deck Imputation (simple example using fillna with forward fill)</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>df_hot_deck <span class="op">=</span> df.fillna(method<span class="op">=</span><span class="st">'ffill'</span>)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Cold Deck Imputation (using external data, here as an example we use a static value)</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>df_cold_deck <span class="op">=</span> df.fillna({<span class="st">'A'</span>: <span class="dv">0</span>, <span class="st">'B'</span>: <span class="dv">1</span>, <span class="st">'C'</span>: <span class="dv">2</span>})</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Regression Imputation (handled by IterativeImputer for simplicity)</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>imputer <span class="op">=</span> IterativeImputer(estimator<span class="op">=</span>LinearRegression(), max_iter<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>df_regression_imputed <span class="op">=</span> pd.DataFrame(imputer.fit_transform(df), columns<span class="op">=</span>df.columns)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiple Imputation (simplified example using IterativeImputer)</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>df_multiple_imputed <span class="op">=</span> pd.DataFrame(imputer.fit_transform(df), columns<span class="op">=</span>df.columns)</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="co"># K-Nearest Neighbours Imputation</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>knn_imputer <span class="op">=</span> KNNImputer(n_neighbors<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>df_knn_imputed <span class="op">=</span> pd.DataFrame(knn_imputer.fit_transform(df), columns<span class="op">=</span>df.columns)</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Listwise Deletion:</span><span class="ch">\n</span><span class="st">"</span>, df_listwise)</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Pairwise Deletion Mean A:"</span>, mean_A, <span class="st">"Mean B:"</span>, mean_B, <span class="st">"Mean C:"</span>, mean_C)</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Mean Imputation:</span><span class="ch">\n</span><span class="st">"</span>, df_mean_imputed)</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Median Imputation:</span><span class="ch">\n</span><span class="st">"</span>, df_median_imputed)</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Mode Imputation:</span><span class="ch">\n</span><span class="st">"</span>, df_mode_imputed)</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Hot Deck Imputation:</span><span class="ch">\n</span><span class="st">"</span>, df_hot_deck)</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Cold Deck Imputation:</span><span class="ch">\n</span><span class="st">"</span>, df_cold_deck)</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Regression Imputation:</span><span class="ch">\n</span><span class="st">"</span>, df_regression_imputed)</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Multiple Imputation:</span><span class="ch">\n</span><span class="st">"</span>, df_multiple_imputed)</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">K-Nearest Neighbours Imputation:</span><span class="ch">\n</span><span class="st">"</span>, df_knn_imputed)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Original DataFrame:
      A    B    C
0  1.0  NaN  1.0
1  2.0  2.0  NaN
2  NaN  3.0  3.0
3  4.0  NaN  4.0
4  5.0  5.0  NaN

Listwise Deletion:
 Empty DataFrame
Columns: [A, B, C]
Index: []

Pairwise Deletion Mean A: 3.0 Mean B: 3.3333333333333335 Mean C: 2.6666666666666665

Mean Imputation:
      A         B         C
0  1.0  3.333333  1.000000
1  2.0  2.000000  2.666667
2  3.0  3.000000  3.000000
3  4.0  3.333333  4.000000
4  5.0  5.000000  2.666667

Median Imputation:
      A    B    C
0  1.0  3.0  1.0
1  2.0  2.0  3.0
2  3.0  3.0  3.0
3  4.0  3.0  4.0
4  5.0  5.0  3.0

Mode Imputation:
      A    B    C
0  1.0  2.0  1.0
1  2.0  2.0  1.0
2  1.0  3.0  3.0
3  4.0  2.0  4.0
4  5.0  5.0  1.0

Hot Deck Imputation:
      A    B    C
0  1.0  NaN  1.0
1  2.0  2.0  1.0
2  2.0  3.0  3.0
3  4.0  3.0  4.0
4  5.0  5.0  4.0

Cold Deck Imputation:
      A    B    C
0  1.0  1.0  1.0
1  2.0  2.0  2.0
2  0.0  3.0  3.0
3  4.0  1.0  4.0
4  5.0  5.0  2.0

Regression Imputation:
      A    B    C
0  1.0  1.0  1.0
1  2.0  2.0  2.0
2  3.0  3.0  3.0
3  4.0  4.0  4.0
4  5.0  5.0  5.0

Multiple Imputation:
      A    B    C
0  1.0  1.0  1.0
1  2.0  2.0  2.0
2  3.0  3.0  3.0
3  4.0  4.0  4.0
4  5.0  5.0  5.0

K-Nearest Neighbours Imputation:
      A    B    C
0  1.0  2.5  1.0
1  2.0  2.0  2.0
2  3.0  3.0  3.0
3  4.0  4.0  4.0
4  5.0  5.0  3.5</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/v8/l5r44ftx4g5bx2y5fhdpcmmh0000gn/T/ipykernel_20299/2475623061.py:43: FutureWarning:

DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="dealing-with-outliers" class="level2">
<h2 class="anchored" data-anchor-id="dealing-with-outliers">2.1.2. Dealing with Outliers</h2>
<section id="statistical-methods" class="level4">
<h4 class="anchored" data-anchor-id="statistical-methods">2.1.2.1. Statistical Methods</h4>
<ul>
<li><strong>Z-Score Method</strong>: Identifying outliers by their z-scores, with thresholds often set at ±3 standard deviations.
<ul>
<li>Pros: Simple and effective for normal distributions.</li>
<li>Cons: Not suitable for non-normal distributions.</li>
</ul></li>
<li><strong>IQR Method</strong>: Using the Interquartile Range (IQR) to identify outliers, typically values below Q1 - 1.5<em>IQR or above Q3 + 1.5</em>IQR.
<ul>
<li>Pros: Robust to non-normal distributions.</li>
<li>Cons: Can miss outliers in certain distributions.</li>
</ul></li>
<li><strong>Boxplots</strong>: Visual method to detect outliers using the IQR.
<ul>
<li>Pros: Easy visual identification.</li>
<li>Cons: Subjective; depends on plot interpretation.</li>
</ul></li>
</ul>
<div id="0145a2ff" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> zscore</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'A'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">100</span>],</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'B'</span>: [<span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">15</span>, <span class="dv">12</span>, <span class="dv">14</span>],</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'C'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">2</span>]</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.1.2.1. Statistical Methods</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Z-Score Method</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>z_scores <span class="op">=</span> np.<span class="bu">abs</span>(zscore(df))</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>outliers_z <span class="op">=</span> df[(z_scores <span class="op">&gt;</span> <span class="dv">3</span>).<span class="bu">any</span>(axis<span class="op">=</span><span class="dv">1</span>)]</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="co"># IQR Method</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>Q1 <span class="op">=</span> df.quantile(<span class="fl">0.25</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>Q3 <span class="op">=</span> df.quantile(<span class="fl">0.75</span>)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>IQR <span class="op">=</span> Q3 <span class="op">-</span> Q1</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>outliers_iqr <span class="op">=</span> df[((df <span class="op">&lt;</span> (Q1 <span class="op">-</span> <span class="fl">1.5</span> <span class="op">*</span> IQR)) <span class="op">|</span> (df <span class="op">&gt;</span> (Q3 <span class="op">+</span> <span class="fl">1.5</span> <span class="op">*</span> IQR))).<span class="bu">any</span>(axis<span class="op">=</span><span class="dv">1</span>)]</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Boxplots</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>df.boxplot()</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Boxplot for Outlier Detection'</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Z-Score Method Outliers:</span><span class="ch">\n</span><span class="st">"</span>, outliers_z)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">IQR Method Outliers:</span><span class="ch">\n</span><span class="st">"</span>, outliers_iqr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-3-output-1.png" width="798" height="431" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Original DataFrame:
      A   B  C
0    1  10  1
1    2  12  2
2    3  13  2
3    4  15  3
4    5  12  3
5  100  14  2

Z-Score Method Outliers:
 Empty DataFrame
Columns: [A, B, C]
Index: []

IQR Method Outliers:
      A   B  C
5  100  14  2</code></pre>
</div>
</div>
<hr>
</section>
<section id="machine-learning-based-methods" class="level4">
<h4 class="anchored" data-anchor-id="machine-learning-based-methods">2.1.2.2. Machine Learning-Based Methods</h4>
<ul>
<li><strong>Isolation Forest</strong>: Anomaly detection using tree-based methods to isolate observations.
<ul>
<li>Pros: Effective for high-dimensional data; handles anomalies naturally.</li>
<li>Cons: Requires parameter tuning.</li>
</ul></li>
<li><strong>Local Outlier Factor (LOF)</strong>: Identifies anomalies based on local density deviations.
<ul>
<li>Pros: Detects local outliers; effective in clusters.</li>
<li>Cons: Computationally intensive; parameter sensitive.</li>
</ul></li>
<li><strong>Autoencoders</strong>: Neural networks used for anomaly detection by reconstructing data and comparing reconstruction error.
<ul>
<li>Pros: Effective for complex and high-dimensional data.</li>
<li>Cons: Requires significant computational resources; complex implementation.</li>
</ul></li>
</ul>
<div id="0d75a560" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> IsolationForest</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> LocalOutlierFactor</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'A'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">100</span>],</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'B'</span>: [<span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">15</span>, <span class="dv">12</span>, <span class="dv">14</span>],</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'C'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">2</span>]</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize data</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>df_scaled <span class="op">=</span> scaler.fit_transform(df)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.1.2.2. Machine Learning-Based Methods</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Isolation Forest</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>iso_forest <span class="op">=</span> IsolationForest(contamination<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'IsolationForest_Outlier'</span>] <span class="op">=</span> iso_forest.fit_predict(df_scaled)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Local Outlier Factor (LOF)</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>lof <span class="op">=</span> LocalOutlierFactor(n_neighbors<span class="op">=</span><span class="dv">20</span>, contamination<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'LOF_Outlier'</span>] <span class="op">=</span> lof.fit_predict(df_scaled)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Autoencoders (simplified example using PCA for reconstruction error)</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA for reconstruction</span></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>df_pca <span class="op">=</span> pca.fit_transform(df_scaled)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>df_reconstructed <span class="op">=</span> pca.inverse_transform(df_pca)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>reconstruction_error <span class="op">=</span> np.mean((df_scaled <span class="op">-</span> df_reconstructed)<span class="op">**</span><span class="dv">2</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Define outliers based on reconstruction error threshold</span></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> np.percentile(reconstruction_error, <span class="dv">90</span>)</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Autoencoder_Outlier'</span>] <span class="op">=</span> np.where(reconstruction_error <span class="op">&gt;</span> threshold, <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results</span></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Isolation Forest Outliers:</span><span class="ch">\n</span><span class="st">"</span>, df[df[<span class="st">'IsolationForest_Outlier'</span>] <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Local Outlier Factor Outliers:</span><span class="ch">\n</span><span class="st">"</span>, df[df[<span class="st">'LOF_Outlier'</span>] <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Autoencoder Outliers:</span><span class="ch">\n</span><span class="st">"</span>, df[df[<span class="st">'Autoencoder_Outlier'</span>] <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization of Outliers</span></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>plt.scatter(df.index, df[<span class="st">'A'</span>], c<span class="op">=</span>df[<span class="st">'IsolationForest_Outlier'</span>], cmap<span class="op">=</span><span class="st">'coolwarm'</span>)</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Isolation Forest'</span>)</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>plt.scatter(df.index, df[<span class="st">'A'</span>], c<span class="op">=</span>df[<span class="st">'LOF_Outlier'</span>], cmap<span class="op">=</span><span class="st">'coolwarm'</span>)</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Local Outlier Factor'</span>)</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>plt.scatter(df.index, df[<span class="st">'A'</span>], c<span class="op">=</span>df[<span class="st">'Autoencoder_Outlier'</span>], cmap<span class="op">=</span><span class="st">'coolwarm'</span>)</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Autoencoder'</span>)</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/ravishankar/miniforge3/lib/python3.10/site-packages/sklearn/neighbors/_lof.py:282: UserWarning:

n_neighbors (20) is greater than the total number of samples (6). n_neighbors will be set to (n_samples - 1) for estimation.
</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Original DataFrame:
      A   B  C  IsolationForest_Outlier  LOF_Outlier  Autoencoder_Outlier
0    1  10  1                        1            1                    1
1    2  12  2                        1            1                    1
2    3  13  2                        1           -1                    1
3    4  15  3                        1            1                    1
4    5  12  3                        1            1                   -1
5  100  14  2                       -1            1                    1

Isolation Forest Outliers:
      A   B  C  IsolationForest_Outlier  LOF_Outlier  Autoencoder_Outlier
5  100  14  2                       -1            1                    1

Local Outlier Factor Outliers:
    A   B  C  IsolationForest_Outlier  LOF_Outlier  Autoencoder_Outlier
2  3  13  2                        1           -1                    1

Autoencoder Outliers:
    A   B  C  IsolationForest_Outlier  LOF_Outlier  Autoencoder_Outlier
4  5  12  3                        1            1                   -1</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-4-output-3.png" width="1142" height="565" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="correcting-inconsistent-data" class="level2">
<h2 class="anchored" data-anchor-id="correcting-inconsistent-data">2.1.3. Correcting Inconsistent Data</h2>
<ul>
<li><strong>Standardisation of Data Entry</strong>: Ensuring data follows consistent formats, such as date formats, units of measurement, etc.</li>
<li><strong>Normalization</strong>: Adjusting values measured on different scales to a common scale.</li>
<li><strong>Validation Rules</strong>: Applying rules to ensure data consistency, such as constraints and business rules.</li>
<li><strong>Manual Review and Correction</strong>: Manually identifying and correcting inconsistent data entries.</li>
<li><strong>Automated Tools</strong>: Using software tools to detect and correct inconsistencies.</li>
</ul>
<hr>
</section>
<section id="handling-duplicate-data" class="level2">
<h2 class="anchored" data-anchor-id="handling-duplicate-data">2.1.4. Handling Duplicate Data</h2>
<ul>
<li><strong>Exact Matching</strong>: Identifying duplicates by comparing data fields exactly.
<ul>
<li>Pros: Simple and quick.</li>
<li>Cons: Misses near-duplicates due to minor differences.</li>
</ul></li>
<li><strong>Fuzzy Matching</strong>: Identifying near-duplicates using similarity measures like Levenshtein distance, Jaccard similarity, etc.
<ul>
<li>Pros: Captures more duplicates; robust to minor differences.</li>
<li>Cons: More complex and computationally intensive.</li>
</ul></li>
<li><strong>Machine Learning Approaches</strong>: Using clustering and classification algorithms to detect duplicates.
<ul>
<li>Pros: Can handle complex and large datasets; adaptive.</li>
<li>Cons: Requires training data and parameter tuning.</li>
</ul></li>
<li><strong>Rule-Based Systems</strong>: Applying predefined rules to identify duplicates, such as matching on key fields.
<ul>
<li>Pros: Tailored to specific needs; interpretable.</li>
<li>Cons: Rigid; requires maintenance and updating.</li>
</ul></li>
</ul>
<div id="dd3dd1b8" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fuzzywuzzy <span class="im">import</span> fuzz, process</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data with duplicates</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Name'</span>: [<span class="st">'John Doe'</span>, <span class="st">'Jane Smith'</span>, <span class="st">'John Doe'</span>, <span class="st">'Jane Smith'</span>, <span class="st">'Jake Doe'</span>, <span class="st">'Jon Doe'</span>],</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Age'</span>: [<span class="dv">28</span>, <span class="dv">34</span>, <span class="dv">28</span>, <span class="dv">34</span>, <span class="dv">29</span>, <span class="dv">28</span>],</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'City'</span>: [<span class="st">'New York'</span>, <span class="st">'Los Angeles'</span>, <span class="st">'New York'</span>, <span class="st">'LA'</span>, <span class="st">'Chicago'</span>, <span class="st">'New York'</span>]</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.1.4. Handling Duplicate Data</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Exact Matching</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>exact_duplicates <span class="op">=</span> df[df.duplicated()]</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Fuzzy Matching using Levenshtein distance</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fuzzy_match(df, column, threshold<span class="op">=</span><span class="dv">90</span>):</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    matches <span class="op">=</span> []</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, value <span class="kw">in</span> <span class="bu">enumerate</span>(df[column]):</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j, other_value <span class="kw">in</span> <span class="bu">enumerate</span>(df[column]):</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">!=</span> j:</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>                score <span class="op">=</span> fuzz.ratio(value, other_value)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> score <span class="op">&gt;</span> threshold:</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>                    matches.append((i, j, score))</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> matches</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>fuzzy_matches <span class="op">=</span> fuzzy_match(df, <span class="st">'Name'</span>)</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Machine Learning Approaches using DBSCAN</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>df_scaled <span class="op">=</span> scaler.fit_transform(df.select_dtypes(include<span class="op">=</span>[np.number]))</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>dbscan <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">0.5</span>, min_samples<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Cluster'</span>] <span class="op">=</span> dbscan.fit_predict(df_scaled)</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>ml_duplicates <span class="op">=</span> df[df[<span class="st">'Cluster'</span>] <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Rule-Based Systems</span></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rule_based_duplicates(df):</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>    rules <span class="op">=</span> [</span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>        df[<span class="st">'Name'</span>].duplicated(),</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>        (df[<span class="st">'Age'</span>] <span class="op">==</span> <span class="dv">28</span>) <span class="op">&amp;</span> (df[<span class="st">'City'</span>] <span class="op">==</span> <span class="st">'New York'</span>)</span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df[np.<span class="bu">any</span>(rules, axis<span class="op">=</span><span class="dv">0</span>)]</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>rule_based <span class="op">=</span> rule_based_duplicates(df)</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results</span></span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Exact Duplicates:</span><span class="ch">\n</span><span class="st">"</span>, exact_duplicates)</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Fuzzy Matches (indexes and score):</span><span class="ch">\n</span><span class="st">"</span>, fuzzy_matches)</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Machine Learning-Based Duplicates:</span><span class="ch">\n</span><span class="st">"</span>, ml_duplicates)</span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Rule-Based Duplicates:</span><span class="ch">\n</span><span class="st">"</span>, rule_based)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/ravishankar/miniforge3/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning:

Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning
</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Original DataFrame:
          Name  Age         City  Cluster
0    John Doe   28     New York        0
1  Jane Smith   34  Los Angeles        1
2    John Doe   28     New York        0
3  Jane Smith   34           LA        1
4    Jake Doe   29      Chicago        0
5     Jon Doe   28     New York        0

Exact Duplicates:
        Name  Age      City
2  John Doe   28  New York

Fuzzy Matches (indexes and score):
 [(0, 2, 100), (0, 5, 93), (1, 3, 100), (2, 0, 100), (2, 5, 93), (3, 1, 100), (5, 0, 93), (5, 2, 93)]

Machine Learning-Based Duplicates:
          Name  Age         City  Cluster
0    John Doe   28     New York        0
1  Jane Smith   34  Los Angeles        1
2    John Doe   28     New York        0
3  Jane Smith   34           LA        1
4    Jake Doe   29      Chicago        0
5     Jon Doe   28     New York        0

Rule-Based Duplicates:
          Name  Age      City  Cluster
0    John Doe   28  New York        0
2    John Doe   28  New York        0
3  Jane Smith   34        LA        1
5     Jon Doe   28  New York        0</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="feature-scaling-and-normalization" class="level1">
<h1>2.2 Feature Scaling and Normalization</h1>
<p>Feature scaling and normalization are crucial steps in data preprocessing, especially for machine learning algorithms. They ensure that features contribute equally to the model’s performance, improving convergence and accuracy. Below is a comprehensive guide from basic to advanced levels.</p>
<section id="min-max-scaling" class="level2">
<h2 class="anchored" data-anchor-id="min-max-scaling">2.2.1 Min-Max Scaling</h2>
<p>Min-Max scaling, also known as normalization, rescales the feature to a fixed range, usually [0, 1]. This transformation is defined as:</p>
<p><span class="math display">\[
x' = \frac{x - \min(x)}{\max(x) - \min(x)}
\]</span></p>
<p>Min-Max scaling is sensitive to outliers since it uses the minimum and maximum values of the features. It’s most useful when the data distribution is not Gaussian and varies in scales.</p>
<p>For advanced applications, Min-Max scaling can be extended to any desired range [a, b]:</p>
<p><span class="math display">\[
x' = a + \frac{(x - \min(x)) \times (b - a)}{\max(x) - \min(x)}
\]</span></p>
<p>Understanding the impact of Min-Max scaling on model performance and ensuring the transformation is applied consistently in training and test datasets are critical aspects at this level.</p>
<div id="35c5fee4" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'A'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">100</span>],</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'B'</span>: [<span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">15</span>, <span class="dv">12</span>, <span class="dv">14</span>],</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'C'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">2</span>]</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.2 Feature Scaling and Normalization</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.2.1 Min-Max Scaling</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying Min-Max Scaling to scale features to [0, 1]</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>min_max_scaler <span class="op">=</span> MinMaxScaler()</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>df_min_max_scaled <span class="op">=</span> pd.DataFrame(min_max_scaler.fit_transform(df), columns<span class="op">=</span>df.columns)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to apply Min-Max Scaling to any desired range [a, b]</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> min_max_scale(df, feature_range<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">1</span>)):</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    scaler <span class="op">=</span> MinMaxScaler(feature_range<span class="op">=</span>feature_range)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(scaler.fit_transform(df), columns<span class="op">=</span>df.columns)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying Min-Max Scaling to scale features to [-1, 1]</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>df_min_max_scaled_custom <span class="op">=</span> min_max_scale(df, feature_range<span class="op">=</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting original and scaled data</span></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>plt.scatter(df.index, df[<span class="st">'A'</span>], c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Original'</span>)</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Original Data'</span>)</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Values'</span>)</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>plt.scatter(df_min_max_scaled.index, df_min_max_scaled[<span class="st">'A'</span>], c<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'Scaled [0, 1]'</span>)</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Min-Max Scaled [0, 1]'</span>)</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Values'</span>)</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>plt.scatter(df_min_max_scaled_custom.index, df_min_max_scaled_custom[<span class="st">'A'</span>], c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Scaled [-1, 1]'</span>)</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Min-Max Scaled [-1, 1]'</span>)</span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Values'</span>)</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results</span></span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Min-Max Scaled DataFrame [0, 1]:</span><span class="ch">\n</span><span class="st">"</span>, df_min_max_scaled)</span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Min-Max Scaled DataFrame [-1, 1]:</span><span class="ch">\n</span><span class="st">"</span>, df_min_max_scaled_custom)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-6-output-1.png" width="1141" height="564" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Original DataFrame:
      A   B  C
0    1  10  1
1    2  12  2
2    3  13  2
3    4  15  3
4    5  12  3
5  100  14  2

Min-Max Scaled DataFrame [0, 1]:
           A    B    C
0  0.000000  0.0  0.0
1  0.010101  0.4  0.5
2  0.020202  0.6  0.5
3  0.030303  1.0  1.0
4  0.040404  0.4  1.0
5  1.000000  0.8  0.5

Min-Max Scaled DataFrame [-1, 1]:
           A    B    C
0 -1.000000 -1.0 -1.0
1 -0.979798 -0.2  0.0
2 -0.959596  0.2  0.0
3 -0.939394  1.0  1.0
4 -0.919192 -0.2  1.0
5  1.000000  0.6  0.0</code></pre>
</div>
</div>
<hr>
</section>
<section id="standardization-z-score-normalization" class="level2">
<h2 class="anchored" data-anchor-id="standardization-z-score-normalization">2.2.2 Standardization (Z-score normalization)</h2>
<p>Standardization transforms the data to have a mean of 0 and a standard deviation of 1. This is achieved by the formula:</p>
<p><span class="math display">\[
x' = \frac{x - \mu}{\sigma}
\]</span></p>
<p>where $ $ is the mean of the feature and $ $ is the standard deviation.</p>
<p>Standardization is particularly useful when the features have different units or the data follows a Gaussian distribution. It centres the data and scales it to unit variance.</p>
<p>At the advanced level, consider the following aspects:</p>
<ul>
<li><p>Handling datasets with outliers and how they affect the mean and standard deviation.</p></li>
<li><p>Applying standardization in the presence of skewed data distributions.</p></li>
<li><p>Understanding the mathematical properties and implications of the transformation in high-dimensional spaces.</p></li>
</ul>
<div id="1b7eac7a" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'A'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">100</span>],</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'B'</span>: [<span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">15</span>, <span class="dv">12</span>, <span class="dv">14</span>],</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'C'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">2</span>]</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.2.2 Standardization (Z-score normalization)</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying Standardization to scale features to mean 0 and standard deviation 1</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>standard_scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>df_standardized <span class="op">=</span> pd.DataFrame(standard_scaler.fit_transform(df), columns<span class="op">=</span>df.columns)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to calculate Z-score</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> z_score_standardize(series):</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (series <span class="op">-</span> series.mean()) <span class="op">/</span> series.std()</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying Z-score standardization manually for each column</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>df_manual_standardized <span class="op">=</span> df.<span class="bu">apply</span>(z_score_standardize)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting original and standardized data</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>plt.scatter(df.index, df[<span class="st">'A'</span>], c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Original'</span>)</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Original Data'</span>)</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Values'</span>)</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>plt.scatter(df_standardized.index, df_standardized[<span class="st">'A'</span>], c<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'Standardized (sklearn)'</span>)</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Standardized Data (sklearn)'</span>)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Values'</span>)</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>plt.scatter(df_manual_standardized.index, df_manual_standardized[<span class="st">'A'</span>], c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Standardized (manual)'</span>)</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Standardized Data (manual)'</span>)</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Values'</span>)</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results</span></span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Standardized DataFrame (sklearn):</span><span class="ch">\n</span><span class="st">"</span>, df_standardized)</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Standardized DataFrame (manual):</span><span class="ch">\n</span><span class="st">"</span>, df_manual_standardized)</span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations</span></span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Handling outliers in datasets</span></span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>outliers <span class="op">=</span> df[(np.<span class="bu">abs</span>(df_standardized) <span class="op">&gt;</span> <span class="dv">3</span>).<span class="bu">any</span>(axis<span class="op">=</span><span class="dv">1</span>)]</span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Detected Outliers:</span><span class="ch">\n</span><span class="st">"</span>, outliers)</span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Skewed data distributions</span></span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a>skewed_data <span class="op">=</span> {</span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a>    <span class="st">'A'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">100</span>],</span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a>    <span class="st">'B'</span>: [<span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>],</span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a>    <span class="st">'C'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]</span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a>df_skewed <span class="op">=</span> pd.DataFrame(skewed_data)</span>
<span id="cb14-68"><a href="#cb14-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-69"><a href="#cb14-69" aria-hidden="true" tabindex="-1"></a>df_skewed_standardized <span class="op">=</span> pd.DataFrame(standard_scaler.fit_transform(df_skewed), columns<span class="op">=</span>df_skewed.columns)</span>
<span id="cb14-70"><a href="#cb14-70" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Standardized Skewed DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df_skewed_standardized)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-7-output-1.png" width="1141" height="564" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Original DataFrame:
      A   B  C
0    1  10  1
1    2  12  2
2    3  13  2
3    4  15  3
4    5  12  3
5  100  14  2

Standardized DataFrame (sklearn):
           A         B         C
0 -0.502219 -1.668115 -1.697749
1 -0.474574 -0.417029 -0.242536
2 -0.446929  0.208514 -0.242536
3 -0.419284  1.459601  1.212678
4 -0.391639 -0.417029  1.212678
5  2.234643  0.834058 -0.242536

Standardized DataFrame (manual):
           A         B         C
0 -0.458461 -1.522774 -1.549826
1 -0.433225 -0.380693 -0.221404
2 -0.407988  0.190347 -0.221404
3 -0.382752  1.332427  1.107019
4 -0.357515 -0.380693  1.107019
5  2.039941  0.761387 -0.221404

Detected Outliers:
 Empty DataFrame
Columns: [A, B, C]
Index: []

Standardized Skewed DataFrame:
           A    B        C
0 -0.502219  0.0 -1.46385
1 -0.474574  0.0 -0.87831
2 -0.446929  0.0 -0.29277
3 -0.419284  0.0  0.29277
4 -0.391639  0.0  0.87831
5  2.234643  0.0  1.46385</code></pre>
</div>
</div>
<hr>
</section>
<section id="robust-scaling" class="level2">
<h2 class="anchored" data-anchor-id="robust-scaling">2.2.3 Robust Scaling</h2>
<p>Robust scaling uses statistics that are robust to outliers, specifically the median and the interquartile range (IQR). The transformation is given by:</p>
<p><span class="math display">\[
x' = \frac{x - \text{median}(x)}{\text{IQR}(x)}
\]</span></p>
<p>The interquartile range (IQR) is the difference between the 75th and 25th percentiles. Robust scaling is less sensitive to outliers compared to Min-Max scaling and standardization.</p>
<p>Advanced considerations include:</p>
<ul>
<li><p>The effect of different types of outliers on the scaling process.</p></li>
<li><p>Application of robust scaling to various data distributions.</p></li>
<li><p>Combining robust scaling with other preprocessing techniques for optimal performance.</p></li>
</ul>
<div id="9f91b325" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> RobustScaler</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data with outliers</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'A'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">100</span>],</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'B'</span>: [<span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">15</span>, <span class="dv">12</span>, <span class="dv">14</span>],</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'C'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">2</span>]</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.2.3 Robust Scaling</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying Robust Scaling to scale features using median and IQR</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>robust_scaler <span class="op">=</span> RobustScaler()</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>df_robust_scaled <span class="op">=</span> pd.DataFrame(robust_scaler.fit_transform(df), columns<span class="op">=</span>df.columns)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to manually calculate Robust Scaling</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> robust_scale(series):</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    median <span class="op">=</span> series.median()</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    iqr <span class="op">=</span> series.quantile(<span class="fl">0.75</span>) <span class="op">-</span> series.quantile(<span class="fl">0.25</span>)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (series <span class="op">-</span> median) <span class="op">/</span> iqr</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying Robust Scaling manually for each column</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>df_manual_robust_scaled <span class="op">=</span> df.<span class="bu">apply</span>(robust_scale)</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting original and robust scaled data</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>plt.scatter(df.index, df[<span class="st">'A'</span>], c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Original'</span>)</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Original Data'</span>)</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Values'</span>)</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>plt.scatter(df_robust_scaled.index, df_robust_scaled[<span class="st">'A'</span>], c<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'Robust Scaled (sklearn)'</span>)</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Robust Scaled Data (sklearn)'</span>)</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Values'</span>)</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>plt.scatter(df_manual_robust_scaled.index, df_manual_robust_scaled[<span class="st">'A'</span>], c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Robust Scaled (manual)'</span>)</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Robust Scaled Data (manual)'</span>)</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Values'</span>)</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results</span></span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Robust Scaled DataFrame (sklearn):</span><span class="ch">\n</span><span class="st">"</span>, df_robust_scaled)</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Robust Scaled DataFrame (manual):</span><span class="ch">\n</span><span class="st">"</span>, df_manual_robust_scaled)</span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations</span></span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Effect of different types of outliers</span></span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a>outliers <span class="op">=</span> df[(np.<span class="bu">abs</span>(df_robust_scaled) <span class="op">&gt;</span> <span class="dv">3</span>).<span class="bu">any</span>(axis<span class="op">=</span><span class="dv">1</span>)]</span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Detected Outliers after Robust Scaling:</span><span class="ch">\n</span><span class="st">"</span>, outliers)</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Application to various data distributions</span></span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a>different_distributions <span class="op">=</span> {</span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Normal'</span>: np.random.normal(size<span class="op">=</span><span class="dv">100</span>),</span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Uniform'</span>: np.random.uniform(size<span class="op">=</span><span class="dv">100</span>),</span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Skewed'</span>: np.random.exponential(size<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a>df_distributions <span class="op">=</span> pd.DataFrame(different_distributions)</span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a>df_distributions_robust_scaled <span class="op">=</span> pd.DataFrame(robust_scaler.fit_transform(df_distributions), columns<span class="op">=</span>df_distributions.columns)</span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Robust Scaled DataFrame for Different Distributions:</span><span class="ch">\n</span><span class="st">"</span>, df_distributions_robust_scaled)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-8-output-1.png" width="1141" height="564" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Original DataFrame:
      A   B  C
0    1  10  1
1    2  12  2
2    3  13  2
3    4  15  3
4    5  12  3
5  100  14  2

Robust Scaled DataFrame (sklearn):
       A         B         C
0  -1.0 -1.428571 -1.333333
1  -0.6 -0.285714  0.000000
2  -0.2  0.285714  0.000000
3   0.2  1.428571  1.333333
4   0.6 -0.285714  1.333333
5  38.6  0.857143  0.000000

Robust Scaled DataFrame (manual):
       A         B         C
0  -1.0 -1.428571 -1.333333
1  -0.6 -0.285714  0.000000
2  -0.2  0.285714  0.000000
3   0.2  1.428571  1.333333
4   0.6 -0.285714  1.333333
5  38.6  0.857143  0.000000

Detected Outliers after Robust Scaling:
      A   B  C
5  100  14  2

Robust Scaled DataFrame for Different Distributions:
       Normal   Uniform    Skewed
0  -0.356526  0.076544 -0.526567
1   0.417068  0.049326 -0.391730
2   0.423635 -0.262941 -0.485219
3  -0.585500  0.645111 -0.010001
4   1.060866  0.211180 -0.548701
..       ...       ...       ...
95 -0.270829 -0.839940  0.086674
96  0.007962 -0.791294 -0.482408
97  0.899137 -0.222425  1.140212
98  0.413091 -0.362783  1.324141
99 -0.954352 -0.773522 -0.245877

[100 rows x 3 columns]</code></pre>
</div>
</div>
<hr>
</section>
<section id="log-transformation" class="level2">
<h2 class="anchored" data-anchor-id="log-transformation">2.2.4 Log Transformation</h2>
<p>Log transformation helps in handling skewed data by compressing the range of the data. It is defined as:</p>
<p><span class="math display">\[
x' = \log(x + 1)
\]</span></p>
<p>The constant 1 is added to avoid issues with taking the log of zero.</p>
<p>Log transformation is useful for features that follow an exponential or power-law distribution. It reduces the skewness and brings the data closer to a Gaussian distribution.</p>
<p>Advanced topics include:</p>
<ul>
<li><p>Applying log transformation to different types of skewed distributions.</p></li>
<li><p>Understanding the implications of the transformation in the context of machine learning algorithms.</p></li>
<li><p>Combining log transformation with other scaling techniques for better performance.</p></li>
</ul>
<div id="73aa4e8c" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample skewed data</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'A'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">100</span>],</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'B'</span>: [<span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">15</span>, <span class="dv">12</span>, <span class="dv">14</span>],</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'C'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">2</span>]</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.2.4 Log Transformation</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying Log Transformation</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>df_log_transformed <span class="op">=</span> df.applymap(<span class="kw">lambda</span> x: np.log1p(x))</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to apply log transformation</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_transform(series):</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.log1p(series)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying Log Transformation manually for each column</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>df_manual_log_transformed <span class="op">=</span> df.<span class="bu">apply</span>(log_transform)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting original and log-transformed data</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>plt.scatter(df.index, df[<span class="st">'A'</span>], c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Original'</span>)</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Original Data'</span>)</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Values'</span>)</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>plt.scatter(df_log_transformed.index, df_log_transformed[<span class="st">'A'</span>], c<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'Log Transformed (applymap)'</span>)</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Log Transformed Data (applymap)'</span>)</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Values'</span>)</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>plt.scatter(df_manual_log_transformed.index, df_manual_log_transformed[<span class="st">'A'</span>], c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Log Transformed (manual)'</span>)</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Log Transformed Data (manual)'</span>)</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Values'</span>)</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results</span></span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Log Transformed DataFrame (applymap):</span><span class="ch">\n</span><span class="st">"</span>, df_log_transformed)</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Log Transformed DataFrame (manual):</span><span class="ch">\n</span><span class="st">"</span>, df_manual_log_transformed)</span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations</span></span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying log transformation to different skewed distributions</span></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>skewed_data <span class="op">=</span> {</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Exponential'</span>: np.random.exponential(scale<span class="op">=</span><span class="dv">2</span>, size<span class="op">=</span><span class="dv">100</span>),</span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a>    <span class="st">'PowerLaw'</span>: np.random.pareto(a<span class="op">=</span><span class="dv">2</span>, size<span class="op">=</span><span class="dv">100</span>) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>df_skewed <span class="op">=</span> pd.DataFrame(skewed_data)</span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a>df_skewed_log_transformed <span class="op">=</span> df_skewed.applymap(<span class="kw">lambda</span> x: np.log1p(x))</span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Original Skewed DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df_skewed)</span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Log Transformed Skewed DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df_skewed_log_transformed)</span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizing the distributions before and after log transformation</span></span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">10</span>))</span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(df_skewed.columns):</span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>, i].hist(df_skewed[col], bins<span class="op">=</span><span class="dv">30</span>, color<span class="op">=</span><span class="st">'blue'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>, i].set_title(<span class="ss">f'Original </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss"> Distribution'</span>)</span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>, i].hist(df_skewed_log_transformed[col], bins<span class="op">=</span><span class="dv">30</span>, color<span class="op">=</span><span class="st">'green'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>, i].set_title(<span class="ss">f'Log Transformed </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss"> Distribution'</span>)</span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/v8/l5r44ftx4g5bx2y5fhdpcmmh0000gn/T/ipykernel_20299/3728224437.py:15: FutureWarning:

DataFrame.applymap has been deprecated. Use DataFrame.map instead.
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-9-output-2.png" width="1141" height="564" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Original DataFrame:
      A   B  C
0    1  10  1
1    2  12  2
2    3  13  2
3    4  15  3
4    5  12  3
5  100  14  2

Log Transformed DataFrame (applymap):
           A         B         C
0  0.693147  2.397895  0.693147
1  1.098612  2.564949  1.098612
2  1.386294  2.639057  1.098612
3  1.609438  2.772589  1.386294
4  1.791759  2.564949  1.386294
5  4.615121  2.708050  1.098612

Log Transformed DataFrame (manual):
           A         B         C
0  0.693147  2.397895  0.693147
1  1.098612  2.564949  1.098612
2  1.386294  2.639057  1.098612
3  1.609438  2.772589  1.386294
4  1.791759  2.564949  1.386294
5  4.615121  2.708050  1.098612

Original Skewed DataFrame:
     Exponential  PowerLaw
0      1.906811  1.072804
1      2.755858  1.096370
2      2.741588  1.727950
3      3.341742  1.655206
4      0.723236  1.196989
..          ...       ...
95     1.477264  1.301568
96     1.272792  3.624408
97     0.871978  1.202865
98     0.152154  1.081406
99     0.692300  1.810866

[100 rows x 2 columns]

Log Transformed Skewed DataFrame:
     Exponential  PowerLaw
0      1.067057  0.728902
1      1.323317  0.740207
2      1.319510  1.003550
3      1.468276  0.976522
4      0.544204  0.787088
..          ...       ...
95     0.907155  0.833591
96     0.821009  1.531348
97     0.626996  0.789759
98     0.141633  0.733044
99     0.526089  1.033493

[100 rows x 2 columns]</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/v8/l5r44ftx4g5bx2y5fhdpcmmh0000gn/T/ipykernel_20299/3728224437.py:62: FutureWarning:

DataFrame.applymap has been deprecated. Use DataFrame.map instead.
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-9-output-5.png" width="1334" height="949" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<hr>
</section>
<section id="box-cox-transformation" class="level2">
<h2 class="anchored" data-anchor-id="box-cox-transformation">2.2.5 Box-Cox Transformation</h2>
<p>Box-Cox transformation is a family of power transformations indexed by a parameter <span class="math inline">\(\lambda\)</span>. It is defined as:</p>
<p><span class="math display">\[
y(\lambda) =
\begin{cases}
\frac{y^\lambda - 1}{\lambda}, &amp; \text{if } \lambda \neq 0 \\
\log(y), &amp; \text{if } \lambda = 0
\end{cases}
\]</span></p>
<p>Box-Cox transformation is useful for stabilizing variance and making the data more Gaussian-like. The parameter <span class="math inline">\(\lambda\)</span> is estimated using maximum likelihood estimation.</p>
<p>For advanced applications:</p>
<ul>
<li><p>Understanding the mathematical derivation and properties of the Box-Cox transformation.</p></li>
<li><p>Applying the transformation to multivariate data and analysing its impact.</p></li>
<li><p>Integrating Box-Cox transformation with other advanced preprocessing and modelling techniques.</p></li>
</ul>
<div id="5ca3e5d3" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> boxcox</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.special <span class="im">import</span> inv_boxcox</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample skewed data</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'A'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">100</span>],</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'B'</span>: [<span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">15</span>, <span class="dv">12</span>, <span class="dv">14</span>],</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'C'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">2</span>]</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.2.5 Box-Cox Transformation</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying Box-Cox Transformation</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>df_boxcox_transformed <span class="op">=</span> pd.DataFrame()</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply Box-Cox transformation to each column (Box-Cox requires positive data)</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> df.columns:</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    df_boxcox_transformed[col], fitted_lambda <span class="op">=</span> boxcox(df[col] <span class="op">+</span> <span class="dv">1</span>)  <span class="co"># Adding 1 to avoid issues with zero values</span></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Lambda for </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>fitted_lambda<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to apply Box-Cox transformation</span></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> boxcox_transform(series):</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>    transformed, fitted_lambda <span class="op">=</span> boxcox(series <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> transformed, fitted_lambda</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying Box-Cox Transformation manually for each column</span></span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>df_manual_boxcox_transformed <span class="op">=</span> pd.DataFrame()</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>lambdas <span class="op">=</span> {}</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> df.columns:</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>    df_manual_boxcox_transformed[col], lambdas[col] <span class="op">=</span> boxcox_transform(df[col])</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting original and Box-Cox transformed data</span></span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>plt.scatter(df.index, df[<span class="st">'A'</span>], c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Original'</span>)</span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Original Data'</span>)</span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Values'</span>)</span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a>plt.scatter(df_boxcox_transformed.index, df_boxcox_transformed[<span class="st">'A'</span>], c<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'Box-Cox Transformed (scipy)'</span>)</span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Box-Cox Transformed Data (scipy)'</span>)</span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Values'</span>)</span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a>plt.scatter(df_manual_boxcox_transformed.index, df_manual_boxcox_transformed[<span class="st">'A'</span>], c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Box-Cox Transformed (manual)'</span>)</span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Box-Cox Transformed Data (manual)'</span>)</span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Values'</span>)</span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-59"><a href="#cb22-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results</span></span>
<span id="cb22-60"><a href="#cb22-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb22-61"><a href="#cb22-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Box-Cox Transformed DataFrame (scipy):</span><span class="ch">\n</span><span class="st">"</span>, df_boxcox_transformed)</span>
<span id="cb22-62"><a href="#cb22-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Box-Cox Transformed DataFrame (manual):</span><span class="ch">\n</span><span class="st">"</span>, df_manual_boxcox_transformed)</span>
<span id="cb22-63"><a href="#cb22-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-64"><a href="#cb22-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations</span></span>
<span id="cb22-65"><a href="#cb22-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-66"><a href="#cb22-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying Box-Cox transformation to different skewed distributions</span></span>
<span id="cb22-67"><a href="#cb22-67" aria-hidden="true" tabindex="-1"></a>skewed_data <span class="op">=</span> {</span>
<span id="cb22-68"><a href="#cb22-68" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Exponential'</span>: np.random.exponential(scale<span class="op">=</span><span class="dv">2</span>, size<span class="op">=</span><span class="dv">100</span>),</span>
<span id="cb22-69"><a href="#cb22-69" aria-hidden="true" tabindex="-1"></a>    <span class="st">'PowerLaw'</span>: np.random.pareto(a<span class="op">=</span><span class="dv">2</span>, size<span class="op">=</span><span class="dv">100</span>) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb22-70"><a href="#cb22-70" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-71"><a href="#cb22-71" aria-hidden="true" tabindex="-1"></a>df_skewed <span class="op">=</span> pd.DataFrame(skewed_data)</span>
<span id="cb22-72"><a href="#cb22-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-73"><a href="#cb22-73" aria-hidden="true" tabindex="-1"></a>df_skewed_boxcox_transformed <span class="op">=</span> pd.DataFrame()</span>
<span id="cb22-74"><a href="#cb22-74" aria-hidden="true" tabindex="-1"></a>lambdas_skewed <span class="op">=</span> {}</span>
<span id="cb22-75"><a href="#cb22-75" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> df_skewed.columns:</span>
<span id="cb22-76"><a href="#cb22-76" aria-hidden="true" tabindex="-1"></a>    df_skewed_boxcox_transformed[col], lambdas_skewed[col] <span class="op">=</span> boxcox_transform(df_skewed[col])</span>
<span id="cb22-77"><a href="#cb22-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-78"><a href="#cb22-78" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Original Skewed DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df_skewed)</span>
<span id="cb22-79"><a href="#cb22-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Box-Cox Transformed Skewed DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df_skewed_boxcox_transformed)</span>
<span id="cb22-80"><a href="#cb22-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-81"><a href="#cb22-81" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizing the distributions before and after Box-Cox transformation</span></span>
<span id="cb22-82"><a href="#cb22-82" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">10</span>))</span>
<span id="cb22-83"><a href="#cb22-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-84"><a href="#cb22-84" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(df_skewed.columns):</span>
<span id="cb22-85"><a href="#cb22-85" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>, i].hist(df_skewed[col], bins<span class="op">=</span><span class="dv">30</span>, color<span class="op">=</span><span class="st">'blue'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb22-86"><a href="#cb22-86" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>, i].set_title(<span class="ss">f'Original </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss"> Distribution'</span>)</span>
<span id="cb22-87"><a href="#cb22-87" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>, i].hist(df_skewed_boxcox_transformed[col], bins<span class="op">=</span><span class="dv">30</span>, color<span class="op">=</span><span class="st">'green'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb22-88"><a href="#cb22-88" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>, i].set_title(<span class="ss">f'Box-Cox Transformed </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss"> Distribution'</span>)</span>
<span id="cb22-89"><a href="#cb22-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-90"><a href="#cb22-90" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb22-91"><a href="#cb22-91" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Lambda for A: -0.6948827121821288
Lambda for B: 1.6211440208702976
Lambda for C: 1.345269264290123</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-10-output-2.png" width="1141" height="564" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Original DataFrame:
      A   B  C
0    1  10  1
1    2  12  2
2    3  13  2
3    4  15  3
4    5  12  3
5  100  14  2

Box-Cox Transformed DataFrame (scipy):
           A          B         C
0  0.550079  29.473411  1.145329
1  0.768366  38.832607  2.515377
2  0.889896  43.868502  2.515377
3  0.968779  54.620181  4.055354
4  1.024744  38.832607  4.055354
5  1.380839  49.132995  2.515377

Box-Cox Transformed DataFrame (manual):
           A          B         C
0  0.550079  29.473411  1.145329
1  0.768366  38.832607  2.515377
2  0.889896  43.868502  2.515377
3  0.968779  54.620181  4.055354
4  1.024744  38.832607  4.055354
5  1.380839  49.132995  2.515377

Original Skewed DataFrame:
     Exponential  PowerLaw
0      1.816835  1.175111
1      2.429203  1.095880
2      0.362405  5.488890
3      0.159528  1.560426
4      2.080300  1.526427
..          ...       ...
95     1.941602  1.056733
96     0.654848  1.649614
97     0.880464  2.103837
98     2.401227  5.330780
99     0.409299  1.854550

[100 rows x 2 columns]

Box-Cox Transformed Skewed DataFrame:
     Exponential  PowerLaw
0      0.892654  0.366375
1      1.033560  0.359675
2      0.295593  0.436567
3      0.144835  0.389995
4      0.957713  0.388369
..          ...       ...
95     0.924403  0.356049
96     0.468145  0.393942
97     0.576295  0.408697
98     1.027854  0.436195
99     0.326336  0.401546

[100 rows x 2 columns]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-10-output-4.png" width="1334" height="949" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="encoding-categorical-variables" class="level1">
<h1>2.3 Encoding Categorical Variables</h1>
<p>Encoding categorical variables is a crucial step in data preprocessing, enabling machine learning algorithms to handle non-numeric data effectively. Below is a comprehensive guide from basic to advanced levels.</p>
<section id="one-hot-encoding" class="level2">
<h2 class="anchored" data-anchor-id="one-hot-encoding">2.3.1 One-hot Encoding</h2>
<p>One-hot encoding converts categorical variables into a binary matrix, where each category is represented by a one-hot vector. For example, a categorical feature with three categories, <code>Red</code>, <code>Green</code>, and <code>Blue</code>, would be encoded as:</p>
<p><code>Red   -&gt; [1, 0, 0]</code></p>
<p><code>Green -&gt; [0, 1, 0]</code></p>
<p><code>Blue  -&gt; [0, 0, 1]</code></p>
<p>One-hot encoding is useful for nominal (unordered) categories. It avoids ordinal relationships among categories, making it suitable for algorithms like linear regression.</p>
<p>Advanced considerations include:</p>
<ul>
<li><p>Handling high cardinality features, which can lead to a large number of binary columns.</p></li>
<li><p>Memory efficiency and computational considerations in high-dimensional datasets.</p></li>
<li><p>Using sparse matrices to efficiently store one-hot encoded features.</p></li>
</ul>
<div id="dd884818" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data with categorical features</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Color'</span>: [<span class="st">'Red'</span>, <span class="st">'Green'</span>, <span class="st">'Blue'</span>, <span class="st">'Green'</span>, <span class="st">'Red'</span>, <span class="st">'Blue'</span>],</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Size'</span>: [<span class="st">'S'</span>, <span class="st">'M'</span>, <span class="st">'L'</span>, <span class="st">'M'</span>, <span class="st">'S'</span>, <span class="st">'L'</span>]</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.3.1 One-hot Encoding</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying One-hot Encoding using pandas</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>df_one_hot <span class="op">=</span> pd.get_dummies(df)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced: Handling high cardinality features</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data with a high cardinality feature</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>high_card_data <span class="op">=</span> {</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ID'</span>: <span class="bu">range</span>(<span class="dv">1000</span>),</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Category'</span>: [<span class="st">'Category_'</span> <span class="op">+</span> <span class="bu">str</span>(i <span class="op">%</span> <span class="dv">100</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>)]  <span class="co"># 100 unique categories</span></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>df_high_card <span class="op">=</span> pd.DataFrame(high_card_data)</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying One-hot Encoding to high cardinality feature using pandas</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>df_high_card_one_hot <span class="op">=</span> pd.get_dummies(df_high_card, columns<span class="op">=</span>[<span class="st">'Category'</span>])</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Using sparse matrices to efficiently store one-hot encoded features</span></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.sparse <span class="im">import</span> csr_matrix</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Converting to sparse matrix</span></span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>sparse_matrix <span class="op">=</span> csr_matrix(pd.get_dummies(df_high_card[<span class="st">'Category'</span>]))</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results</span></span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">One-hot Encoded DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df_one_hot)</span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">High Cardinality DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df_high_card.head())</span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">One-hot Encoded High Cardinality DataFrame (first 5 columns):</span><span class="ch">\n</span><span class="st">"</span>, df_high_card_one_hot.iloc[:, :<span class="dv">5</span>])</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Demonstrating the memory efficiency of sparse matrix</span></span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Sparse Matrix Shape:"</span>, sparse_matrix.shape)</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sparse Matrix Memory Usage:"</span>, sparse_matrix.data.nbytes, <span class="st">"bytes"</span>)</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualising the encoded features for original dataframe</span></span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">One-hot Encoded Features for Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df_one_hot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Original DataFrame:
    Color Size
0    Red    S
1  Green    M
2   Blue    L
3  Green    M
4    Red    S
5   Blue    L

One-hot Encoded DataFrame:
    Color_Blue  Color_Green  Color_Red  Size_L  Size_M  Size_S
0       False        False       True   False   False    True
1       False         True      False   False    True   False
2        True        False      False    True   False   False
3       False         True      False   False    True   False
4       False        False       True   False   False    True
5        True        False      False    True   False   False

High Cardinality DataFrame:
    ID    Category
0   0  Category_0
1   1  Category_1
2   2  Category_2
3   3  Category_3
4   4  Category_4

One-hot Encoded High Cardinality DataFrame (first 5 columns):
       ID  Category_Category_0  Category_Category_1  Category_Category_10  \
0      0                 True                False                 False   
1      1                False                 True                 False   
2      2                False                False                 False   
3      3                False                False                 False   
4      4                False                False                 False   
..   ...                  ...                  ...                   ...   
995  995                False                False                 False   
996  996                False                False                 False   
997  997                False                False                 False   
998  998                False                False                 False   
999  999                False                False                 False   

     Category_Category_11  
0                   False  
1                   False  
2                   False  
3                   False  
4                   False  
..                    ...  
995                 False  
996                 False  
997                 False  
998                 False  
999                 False  

[1000 rows x 5 columns]

Sparse Matrix Shape: (1000, 100)
Sparse Matrix Memory Usage: 1000 bytes

One-hot Encoded Features for Original DataFrame:
    Color_Blue  Color_Green  Color_Red  Size_L  Size_M  Size_S
0       False        False       True   False   False    True
1       False         True      False   False    True   False
2        True        False      False    True   False   False
3       False         True      False   False    True   False
4       False        False       True   False   False    True
5        True        False      False    True   False   False</code></pre>
</div>
</div>
<hr>
</section>
<section id="label-encoding" class="level2">
<h2 class="anchored" data-anchor-id="label-encoding">2.3.2 Label Encoding</h2>
<p>Label encoding converts categorical variables into numeric labels, assigning a unique integer to each category. For example:</p>
<p><code>Red   -&gt; 0</code></p>
<p><code>Green -&gt; 1</code></p>
<p><code>Blue  -&gt; 2</code></p>
<p>Label encoding is suitable for ordinal categories where the order matters. However, it can introduce ordinal relationships in nominal categories, which may not be appropriate.</p>
<p>Advanced topics include:</p>
<ul>
<li><p>Combining label encoding with other encoding techniques for better performance.</p></li>
<li><p>Handling categorical features with high cardinality using advanced label encoding strategies.</p></li>
<li><p>Understanding the impact of label encoding on different machine learning algorithms.</p></li>
</ul>
<div id="3e68ce0d" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data with categorical features</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Color'</span>: [<span class="st">'Red'</span>, <span class="st">'Green'</span>, <span class="st">'Blue'</span>, <span class="st">'Green'</span>, <span class="st">'Red'</span>, <span class="st">'Blue'</span>],</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Size'</span>: [<span class="st">'S'</span>, <span class="st">'M'</span>, <span class="st">'L'</span>, <span class="st">'M'</span>, <span class="st">'S'</span>, <span class="st">'L'</span>]</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.3.2 Label Encoding</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying Label Encoding using sklearn</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>label_encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Encoding the 'Color' column</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Color_Encoded'</span>] <span class="op">=</span> label_encoder.fit_transform(df[<span class="st">'Color'</span>])</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Encoding the 'Size' column</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Size_Encoded'</span>] <span class="op">=</span> label_encoder.fit_transform(df[<span class="st">'Size'</span>])</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Label Encoded DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df[[<span class="st">'Color'</span>, <span class="st">'Color_Encoded'</span>, <span class="st">'Size'</span>, <span class="st">'Size_Encoded'</span>]])</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations</span></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Combining label encoding with one-hot encoding</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>df_combined <span class="op">=</span> df.copy()</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>df_combined[<span class="st">'Size_Label'</span>] <span class="op">=</span> label_encoder.fit_transform(df_combined[<span class="st">'Size'</span>])</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>df_combined <span class="op">=</span> pd.get_dummies(df_combined, columns<span class="op">=</span>[<span class="st">'Size_Label'</span>], prefix<span class="op">=</span><span class="st">'Size_OneHot'</span>)</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Combined Label and One-Hot Encoded DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df_combined)</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Handling high cardinality categorical features</span></span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>high_card_data <span class="op">=</span> {</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ID'</span>: <span class="bu">range</span>(<span class="dv">1000</span>),</span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Category'</span>: [<span class="st">'Category_'</span> <span class="op">+</span> <span class="bu">str</span>(i <span class="op">%</span> <span class="dv">100</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>)]  <span class="co"># 100 unique categories</span></span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>df_high_card <span class="op">=</span> pd.DataFrame(high_card_data)</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying label encoding to high cardinality feature</span></span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>df_high_card[<span class="st">'Category_Encoded'</span>] <span class="op">=</span> label_encoder.fit_transform(df_high_card[<span class="st">'Category'</span>])</span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results for high cardinality feature</span></span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">High Cardinality DataFrame with Label Encoding:</span><span class="ch">\n</span><span class="st">"</span>, df_high_card.head())</span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Understanding the impact on machine learning algorithms</span></span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Example using a simple decision tree classifier</span></span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating a simple dataset for demonstration</span></span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a>ml_data <span class="op">=</span> {</span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: [<span class="st">'A'</span>, <span class="st">'B'</span>, <span class="st">'C'</span>, <span class="st">'A'</span>, <span class="st">'B'</span>, <span class="st">'C'</span>],</span>
<span id="cb27-57"><a href="#cb27-57" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Target'</span>: [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb27-58"><a href="#cb27-58" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-59"><a href="#cb27-59" aria-hidden="true" tabindex="-1"></a>df_ml <span class="op">=</span> pd.DataFrame(ml_data)</span>
<span id="cb27-60"><a href="#cb27-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-61"><a href="#cb27-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying label encoding</span></span>
<span id="cb27-62"><a href="#cb27-62" aria-hidden="true" tabindex="-1"></a>df_ml[<span class="st">'Feature_Encoded'</span>] <span class="op">=</span> label_encoder.fit_transform(df_ml[<span class="st">'Feature'</span>])</span>
<span id="cb27-63"><a href="#cb27-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-64"><a href="#cb27-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the data</span></span>
<span id="cb27-65"><a href="#cb27-65" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_ml[[<span class="st">'Feature_Encoded'</span>]]</span>
<span id="cb27-66"><a href="#cb27-66" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_ml[<span class="st">'Target'</span>]</span>
<span id="cb27-67"><a href="#cb27-67" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.33</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb27-68"><a href="#cb27-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-69"><a href="#cb27-69" aria-hidden="true" tabindex="-1"></a><span class="co"># Training a simple decision tree classifier</span></span>
<span id="cb27-70"><a href="#cb27-70" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> DecisionTreeClassifier()</span>
<span id="cb27-71"><a href="#cb27-71" aria-hidden="true" tabindex="-1"></a>clf.fit(X_train, y_train)</span>
<span id="cb27-72"><a href="#cb27-72" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb27-73"><a href="#cb27-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-74"><a href="#cb27-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating accuracy</span></span>
<span id="cb27-75"><a href="#cb27-75" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb27-76"><a href="#cb27-76" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Decision Tree Classifier Accuracy with Label Encoding:"</span>, accuracy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Original DataFrame:
    Color Size  Color_Encoded  Size_Encoded
0    Red    S              2             2
1  Green    M              1             1
2   Blue    L              0             0
3  Green    M              1             1
4    Red    S              2             2
5   Blue    L              0             0

Label Encoded DataFrame:
    Color  Color_Encoded Size  Size_Encoded
0    Red              2    S             2
1  Green              1    M             1
2   Blue              0    L             0
3  Green              1    M             1
4    Red              2    S             2
5   Blue              0    L             0

Combined Label and One-Hot Encoded DataFrame:
    Color Size  Color_Encoded  Size_Encoded  Size_OneHot_0  Size_OneHot_1  \
0    Red    S              2             2          False          False   
1  Green    M              1             1          False           True   
2   Blue    L              0             0           True          False   
3  Green    M              1             1          False           True   
4    Red    S              2             2          False          False   
5   Blue    L              0             0           True          False   

   Size_OneHot_2  
0           True  
1          False  
2          False  
3          False  
4           True  
5          False  

High Cardinality DataFrame with Label Encoding:
    ID    Category  Category_Encoded
0   0  Category_0                 0
1   1  Category_1                 1
2   2  Category_2                12
3   3  Category_3                23
4   4  Category_4                34

Decision Tree Classifier Accuracy with Label Encoding: 0.0</code></pre>
</div>
</div>
<hr>
</section>
<section id="ordinal-encoding" class="level2">
<h2 class="anchored" data-anchor-id="ordinal-encoding">2.3.3 Ordinal Encoding</h2>
<p>Ordinal encoding assigns integers to categories based on their order. For example, if a feature has levels like <code>Low</code>, <code>Medium</code>, and <code>High</code>, they can be encoded as:</p>
<p><code>Low    -&gt; 1</code></p>
<p><code>Medium -&gt; 2</code></p>
<p><code>High   -&gt; 3</code></p>
<p>Ordinal encoding is appropriate for ordinal data where the order matters but the intervals between values are not uniform.</p>
<p>Advanced considerations include:</p>
<ul>
<li><p>Handling inconsistent or ambiguous ordinal relationships.</p></li>
<li><p>Impact of ordinal encoding on model performance and interpretability.</p></li>
<li><p>Combining ordinal encoding with other preprocessing techniques.</p></li>
</ul>
<div id="a4be7278" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OrdinalEncoder</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data with ordinal features</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Size'</span>: [<span class="st">'Small'</span>, <span class="st">'Medium'</span>, <span class="st">'Large'</span>, <span class="st">'Medium'</span>, <span class="st">'Small'</span>, <span class="st">'Large'</span>],</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Priority'</span>: [<span class="st">'Low'</span>, <span class="st">'Medium'</span>, <span class="st">'High'</span>, <span class="st">'Medium'</span>, <span class="st">'Low'</span>, <span class="st">'High'</span>]</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.3.3 Ordinal Encoding</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Defining the order for ordinal features</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>size_categories <span class="op">=</span> [<span class="st">'Small'</span>, <span class="st">'Medium'</span>, <span class="st">'Large'</span>]</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>priority_categories <span class="op">=</span> [<span class="st">'Low'</span>, <span class="st">'Medium'</span>, <span class="st">'High'</span>]</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating an OrdinalEncoder instance with defined categories</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>ordinal_encoder <span class="op">=</span> OrdinalEncoder(categories<span class="op">=</span>[size_categories, priority_categories])</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting and transforming the data</span></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>df[[<span class="st">'Size_Encoded'</span>, <span class="st">'Priority_Encoded'</span>]] <span class="op">=</span> ordinal_encoder.fit_transform(df[[<span class="st">'Size'</span>, <span class="st">'Priority'</span>]])</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results</span></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Ordinal Encoded DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df[[<span class="st">'Size'</span>, <span class="st">'Size_Encoded'</span>, <span class="st">'Priority'</span>, <span class="st">'Priority_Encoded'</span>]])</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations</span></span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Handling inconsistent or ambiguous ordinal relationships</span></span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Different interpretations of 'Size' in another context</span></span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>contextual_size_categories <span class="op">=</span> [<span class="st">'Tiny'</span>, <span class="st">'Small'</span>, <span class="st">'Medium'</span>, <span class="st">'Large'</span>, <span class="st">'Huge'</span>]</span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a>contextual_data <span class="op">=</span> {</span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Size'</span>: [<span class="st">'Tiny'</span>, <span class="st">'Small'</span>, <span class="st">'Medium'</span>, <span class="st">'Large'</span>, <span class="st">'Huge'</span>]</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a>df_contextual <span class="op">=</span> pd.DataFrame(contextual_data)</span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying ordinal encoding with a different context</span></span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a>contextual_ordinal_encoder <span class="op">=</span> OrdinalEncoder(categories<span class="op">=</span>[contextual_size_categories])</span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a>df_contextual[<span class="st">'Size_Encoded'</span>] <span class="op">=</span> contextual_ordinal_encoder.fit_transform(df_contextual[[<span class="st">'Size'</span>]])</span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Contextual Ordinal Encoding:</span><span class="ch">\n</span><span class="st">"</span>, df_contextual)</span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Impact on model performance and interpretability</span></span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Example using a simple linear regression model</span></span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb29-47"><a href="#cb29-47" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb29-48"><a href="#cb29-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-49"><a href="#cb29-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating a simple dataset for demonstration</span></span>
<span id="cb29-50"><a href="#cb29-50" aria-hidden="true" tabindex="-1"></a>ml_data <span class="op">=</span> {</span>
<span id="cb29-51"><a href="#cb29-51" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Experience'</span>: [<span class="st">'Junior'</span>, <span class="st">'Mid'</span>, <span class="st">'Senior'</span>, <span class="st">'Mid'</span>, <span class="st">'Junior'</span>, <span class="st">'Senior'</span>],</span>
<span id="cb29-52"><a href="#cb29-52" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Salary'</span>: [<span class="dv">30</span>, <span class="dv">50</span>, <span class="dv">80</span>, <span class="dv">55</span>, <span class="dv">35</span>, <span class="dv">85</span>]</span>
<span id="cb29-53"><a href="#cb29-53" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-54"><a href="#cb29-54" aria-hidden="true" tabindex="-1"></a>df_ml <span class="op">=</span> pd.DataFrame(ml_data)</span>
<span id="cb29-55"><a href="#cb29-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-56"><a href="#cb29-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Defining the order for the 'Experience' feature</span></span>
<span id="cb29-57"><a href="#cb29-57" aria-hidden="true" tabindex="-1"></a>experience_categories <span class="op">=</span> [<span class="st">'Junior'</span>, <span class="st">'Mid'</span>, <span class="st">'Senior'</span>]</span>
<span id="cb29-58"><a href="#cb29-58" aria-hidden="true" tabindex="-1"></a>ordinal_encoder_experience <span class="op">=</span> OrdinalEncoder(categories<span class="op">=</span>[experience_categories])</span>
<span id="cb29-59"><a href="#cb29-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-60"><a href="#cb29-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Encoding the 'Experience' feature</span></span>
<span id="cb29-61"><a href="#cb29-61" aria-hidden="true" tabindex="-1"></a>df_ml[<span class="st">'Experience_Encoded'</span>] <span class="op">=</span> ordinal_encoder_experience.fit_transform(df_ml[[<span class="st">'Experience'</span>]])</span>
<span id="cb29-62"><a href="#cb29-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-63"><a href="#cb29-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the data</span></span>
<span id="cb29-64"><a href="#cb29-64" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_ml[[<span class="st">'Experience_Encoded'</span>]]</span>
<span id="cb29-65"><a href="#cb29-65" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_ml[<span class="st">'Salary'</span>]</span>
<span id="cb29-66"><a href="#cb29-66" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.33</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb29-67"><a href="#cb29-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-68"><a href="#cb29-68" aria-hidden="true" tabindex="-1"></a><span class="co"># Training a simple linear regression model</span></span>
<span id="cb29-69"><a href="#cb29-69" aria-hidden="true" tabindex="-1"></a>regressor <span class="op">=</span> LinearRegression()</span>
<span id="cb29-70"><a href="#cb29-70" aria-hidden="true" tabindex="-1"></a>regressor.fit(X_train, y_train)</span>
<span id="cb29-71"><a href="#cb29-71" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> regressor.predict(X_test)</span>
<span id="cb29-72"><a href="#cb29-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-73"><a href="#cb29-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating mean squared error</span></span>
<span id="cb29-74"><a href="#cb29-74" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb29-75"><a href="#cb29-75" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Linear Regression Mean Squared Error with Ordinal Encoding:"</span>, mse)</span>
<span id="cb29-76"><a href="#cb29-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-77"><a href="#cb29-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Combining ordinal encoding with other preprocessing techniques</span></span>
<span id="cb29-78"><a href="#cb29-78" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Scaling the encoded feature</span></span>
<span id="cb29-79"><a href="#cb29-79" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb29-80"><a href="#cb29-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-81"><a href="#cb29-81" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb29-82"><a href="#cb29-82" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb29-83"><a href="#cb29-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-84"><a href="#cb29-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the scaled data</span></span>
<span id="cb29-85"><a href="#cb29-85" aria-hidden="true" tabindex="-1"></a>X_train_scaled, X_test_scaled, y_train, y_test <span class="op">=</span> train_test_split(X_scaled, y, test_size<span class="op">=</span><span class="fl">0.33</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb29-86"><a href="#cb29-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-87"><a href="#cb29-87" aria-hidden="true" tabindex="-1"></a><span class="co"># Training a linear regression model on scaled data</span></span>
<span id="cb29-88"><a href="#cb29-88" aria-hidden="true" tabindex="-1"></a>regressor_scaled <span class="op">=</span> LinearRegression()</span>
<span id="cb29-89"><a href="#cb29-89" aria-hidden="true" tabindex="-1"></a>regressor_scaled.fit(X_train_scaled, y_train)</span>
<span id="cb29-90"><a href="#cb29-90" aria-hidden="true" tabindex="-1"></a>y_pred_scaled <span class="op">=</span> regressor_scaled.predict(X_test_scaled)</span>
<span id="cb29-91"><a href="#cb29-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-92"><a href="#cb29-92" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating mean squared error for scaled data</span></span>
<span id="cb29-93"><a href="#cb29-93" aria-hidden="true" tabindex="-1"></a>mse_scaled <span class="op">=</span> mean_squared_error(y_test, y_pred_scaled)</span>
<span id="cb29-94"><a href="#cb29-94" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Linear Regression Mean Squared Error with Ordinal Encoding and Scaling:"</span>, mse_scaled)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Original DataFrame:
      Size Priority  Size_Encoded  Priority_Encoded
0   Small      Low           0.0               0.0
1  Medium   Medium           1.0               1.0
2   Large     High           2.0               2.0
3  Medium   Medium           1.0               1.0
4   Small      Low           0.0               0.0
5   Large     High           2.0               2.0

Ordinal Encoded DataFrame:
      Size  Size_Encoded Priority  Priority_Encoded
0   Small           0.0      Low               0.0
1  Medium           1.0   Medium               1.0
2   Large           2.0     High               2.0
3  Medium           1.0   Medium               1.0
4   Small           0.0      Low               0.0
5   Large           2.0     High               2.0

Contextual Ordinal Encoding:
      Size  Size_Encoded
0    Tiny           0.0
1   Small           1.0
2  Medium           2.0
3   Large           3.0
4    Huge           4.0

Linear Regression Mean Squared Error with Ordinal Encoding: 36.46694214876029

Linear Regression Mean Squared Error with Ordinal Encoding and Scaling: 36.46694214876029</code></pre>
</div>
</div>
<hr>
</section>
<section id="binary-encoding" class="level2">
<h2 class="anchored" data-anchor-id="binary-encoding">2.3.4 Binary Encoding</h2>
<p>Binary encoding converts each category into binary digits. Each category is first converted into an integer and then into a binary code. For example:</p>
<p><code>Red   -&gt; 1  -&gt; 01</code></p>
<p><code>Green -&gt; 2  -&gt; 10</code></p>
<p><code>Blue  -&gt; 3  -&gt; 11</code></p>
<p>Binary encoding is more memory-efficient than one-hot encoding for features with many categories. It reduces the dimensionality of the encoded data.</p>
<p>Advanced topics include:</p>
<ul>
<li><p>Implementing binary encoding for high-cardinality features.</p></li>
<li><p>Combining binary encoding with other techniques to improve model performance.</p></li>
<li><p>Understanding the mathematical properties of binary encoding and its impact on algorithms.</p></li>
</ul>
<div id="1ff3266f" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> category_encoders <span class="im">import</span> BinaryEncoder</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data with categorical features</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Color'</span>: [<span class="st">'Red'</span>, <span class="st">'Green'</span>, <span class="st">'Blue'</span>, <span class="st">'Green'</span>, <span class="st">'Red'</span>, <span class="st">'Blue'</span>],</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Size'</span>: [<span class="st">'S'</span>, <span class="st">'M'</span>, <span class="st">'L'</span>, <span class="st">'M'</span>, <span class="st">'S'</span>, <span class="st">'L'</span>]</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.3.4 Binary Encoding</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying Binary Encoding using category_encoders</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>binary_encoder <span class="op">=</span> BinaryEncoder(cols<span class="op">=</span>[<span class="st">'Color'</span>, <span class="st">'Size'</span>])</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>df_binary_encoded <span class="op">=</span> binary_encoder.fit_transform(df)</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results</span></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Binary Encoded DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df_binary_encoded)</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations</span></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Handling high cardinality features</span></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data with a high cardinality feature</span></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>high_card_data <span class="op">=</span> {</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ID'</span>: <span class="bu">range</span>(<span class="dv">1000</span>),</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Category'</span>: [<span class="st">'Category_'</span> <span class="op">+</span> <span class="bu">str</span>(i <span class="op">%</span> <span class="dv">100</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>)]  <span class="co"># 100 unique categories</span></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>df_high_card <span class="op">=</span> pd.DataFrame(high_card_data)</span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying binary encoding to high cardinality feature</span></span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>binary_encoder_high_card <span class="op">=</span> BinaryEncoder(cols<span class="op">=</span>[<span class="st">'Category'</span>])</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>df_high_card_binary_encoded <span class="op">=</span> binary_encoder_high_card.fit_transform(df_high_card)</span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results for high cardinality feature</span></span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">High Cardinality DataFrame with Binary Encoding (first 5 columns):</span><span class="ch">\n</span><span class="st">"</span>, df_high_card_binary_encoded.iloc[:, :<span class="dv">5</span>])</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Combining binary encoding with other techniques</span></span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Scaling the binary encoded features</span></span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a>df_binary_encoded_scaled <span class="op">=</span> pd.DataFrame(scaler.fit_transform(df_binary_encoded), columns<span class="op">=</span>df_binary_encoded.columns)</span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results for scaled binary encoded features</span></span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Scaled Binary Encoded DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df_binary_encoded_scaled)</span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Understanding the impact on machine learning algorithms</span></span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Example using a simple logistic regression model</span></span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating a simple dataset for demonstration</span></span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a>ml_data <span class="op">=</span> {</span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: [<span class="st">'A'</span>, <span class="st">'B'</span>, <span class="st">'C'</span>, <span class="st">'A'</span>, <span class="st">'B'</span>, <span class="st">'C'</span>],</span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Target'</span>: [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb31-57"><a href="#cb31-57" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb31-58"><a href="#cb31-58" aria-hidden="true" tabindex="-1"></a>df_ml <span class="op">=</span> pd.DataFrame(ml_data)</span>
<span id="cb31-59"><a href="#cb31-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-60"><a href="#cb31-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying binary encoding</span></span>
<span id="cb31-61"><a href="#cb31-61" aria-hidden="true" tabindex="-1"></a>binary_encoder_ml <span class="op">=</span> BinaryEncoder(cols<span class="op">=</span>[<span class="st">'Feature'</span>])</span>
<span id="cb31-62"><a href="#cb31-62" aria-hidden="true" tabindex="-1"></a>df_ml_binary_encoded <span class="op">=</span> binary_encoder_ml.fit_transform(df_ml)</span>
<span id="cb31-63"><a href="#cb31-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-64"><a href="#cb31-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the data</span></span>
<span id="cb31-65"><a href="#cb31-65" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_ml_binary_encoded</span>
<span id="cb31-66"><a href="#cb31-66" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_ml[<span class="st">'Target'</span>]</span>
<span id="cb31-67"><a href="#cb31-67" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.33</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb31-68"><a href="#cb31-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-69"><a href="#cb31-69" aria-hidden="true" tabindex="-1"></a><span class="co"># Training a logistic regression model</span></span>
<span id="cb31-70"><a href="#cb31-70" aria-hidden="true" tabindex="-1"></a>log_reg <span class="op">=</span> LogisticRegression()</span>
<span id="cb31-71"><a href="#cb31-71" aria-hidden="true" tabindex="-1"></a>log_reg.fit(X_train, y_train)</span>
<span id="cb31-72"><a href="#cb31-72" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> log_reg.predict(X_test)</span>
<span id="cb31-73"><a href="#cb31-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-74"><a href="#cb31-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating accuracy</span></span>
<span id="cb31-75"><a href="#cb31-75" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb31-76"><a href="#cb31-76" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Logistic Regression Accuracy with Binary Encoding:"</span>, accuracy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Original DataFrame:
    Color Size
0    Red    S
1  Green    M
2   Blue    L
3  Green    M
4    Red    S
5   Blue    L

Binary Encoded DataFrame:
    Color_0  Color_1  Size_0  Size_1
0        0        1       0       1
1        1        0       1       0
2        1        1       1       1
3        1        0       1       0
4        0        1       0       1
5        1        1       1       1

High Cardinality DataFrame with Binary Encoding (first 5 columns):
       ID  Category_0  Category_1  Category_2  Category_3
0      0           0           0           0           0
1      1           0           0           0           0
2      2           0           0           0           0
3      3           0           0           0           0
4      4           0           0           0           0
..   ...         ...         ...         ...         ...
995  995           1           1           0           0
996  996           1           1           0           0
997  997           1           1           0           0
998  998           1           1           0           0
999  999           1           1           0           0

[1000 rows x 5 columns]

Scaled Binary Encoded DataFrame:
     Color_0   Color_1    Size_0    Size_1
0 -1.414214  0.707107 -1.414214  0.707107
1  0.707107 -1.414214  0.707107 -1.414214
2  0.707107  0.707107  0.707107  0.707107
3  0.707107 -1.414214  0.707107 -1.414214
4 -1.414214  0.707107 -1.414214  0.707107
5  0.707107  0.707107  0.707107  0.707107

Logistic Regression Accuracy with Binary Encoding: 1.0</code></pre>
</div>
</div>
<hr>
</section>
<section id="frequency-encoding" class="level2">
<h2 class="anchored" data-anchor-id="frequency-encoding">2.3.5 Frequency Encoding</h2>
<p>Frequency encoding replaces each category with its frequency in the dataset. For example, if <code>Red</code> appears 10 times, <code>Green</code> 20 times, and <code>Blue</code> 15 times:</p>
<p><code>Red   -&gt; 10</code></p>
<p><code>Green -&gt; 20</code></p>
<p><code>Blue  -&gt; 15</code></p>
<p>Frequency encoding is useful for handling high-cardinality features and can be beneficial for tree-based algorithms.</p>
<p>Advanced considerations include: - Dealing with imbalanced datasets and their effect on frequency encoding.</p>
<ul>
<li><p>Combining frequency encoding with other techniques to handle categorical data.</p></li>
<li><p>Impact of frequency encoding on different machine learning models.</p></li>
</ul>
<div id="53da29ed" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data with categorical features</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Color'</span>: [<span class="st">'Red'</span>, <span class="st">'Green'</span>, <span class="st">'Blue'</span>, <span class="st">'Green'</span>, <span class="st">'Red'</span>, <span class="st">'Blue'</span>, <span class="st">'Red'</span>, <span class="st">'Green'</span>, <span class="st">'Blue'</span>],</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Size'</span>: [<span class="st">'S'</span>, <span class="st">'M'</span>, <span class="st">'L'</span>, <span class="st">'M'</span>, <span class="st">'S'</span>, <span class="st">'L'</span>, <span class="st">'M'</span>, <span class="st">'M'</span>, <span class="st">'S'</span>],</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Target'</span>: [<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.3.5 Frequency Encoding</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying Frequency Encoding</span></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> frequency_encoding(df, column):</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>    freq_encoding <span class="op">=</span> df[column].value_counts().to_dict()</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df[column].<span class="bu">map</span>(freq_encoding)</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Color_Freq_Encoded'</span>] <span class="op">=</span> frequency_encoding(df, <span class="st">'Color'</span>)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Size_Freq_Encoded'</span>] <span class="op">=</span> frequency_encoding(df, <span class="st">'Size'</span>)</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Frequency Encoded DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df[[<span class="st">'Color'</span>, <span class="st">'Color_Freq_Encoded'</span>, <span class="st">'Size'</span>, <span class="st">'Size_Freq_Encoded'</span>, <span class="st">'Target'</span>]])</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations</span></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Handling imbalanced datasets</span></span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Adding imbalance to the dataset</span></span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>imbalanced_data <span class="op">=</span> {</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Color'</span>: [<span class="st">'Red'</span>] <span class="op">*</span> <span class="dv">50</span> <span class="op">+</span> [<span class="st">'Green'</span>] <span class="op">*</span> <span class="dv">5</span> <span class="op">+</span> [<span class="st">'Blue'</span>] <span class="op">*</span> <span class="dv">10</span>,</span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Size'</span>: [<span class="st">'S'</span>] <span class="op">*</span> <span class="dv">30</span> <span class="op">+</span> [<span class="st">'M'</span>] <span class="op">*</span> <span class="dv">25</span> <span class="op">+</span> [<span class="st">'L'</span>] <span class="op">*</span> <span class="dv">10</span>,</span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Target'</span>: [<span class="dv">1</span>] <span class="op">*</span> <span class="dv">50</span> <span class="op">+</span> [<span class="dv">0</span>] <span class="op">*</span> <span class="dv">5</span> <span class="op">+</span> [<span class="dv">1</span>] <span class="op">*</span> <span class="dv">10</span></span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a>df_imbalanced <span class="op">=</span> pd.DataFrame(imbalanced_data)</span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying frequency encoding to imbalanced dataset</span></span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a>df_imbalanced[<span class="st">'Color_Freq_Encoded'</span>] <span class="op">=</span> frequency_encoding(df_imbalanced, <span class="st">'Color'</span>)</span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a>df_imbalanced[<span class="st">'Size_Freq_Encoded'</span>] <span class="op">=</span> frequency_encoding(df_imbalanced, <span class="st">'Size'</span>)</span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Imbalanced DataFrame with Frequency Encoding:</span><span class="ch">\n</span><span class="st">"</span>, df_imbalanced[[<span class="st">'Color'</span>, <span class="st">'Color_Freq_Encoded'</span>, <span class="st">'Size'</span>, <span class="st">'Size_Freq_Encoded'</span>, <span class="st">'Target'</span>]])</span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Combining frequency encoding with other techniques</span></span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Scaling the frequency encoded features</span></span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a>df_scaled <span class="op">=</span> pd.DataFrame(scaler.fit_transform(df[[<span class="st">'Color_Freq_Encoded'</span>, <span class="st">'Size_Freq_Encoded'</span>]]), columns<span class="op">=</span>[<span class="st">'Color_Freq_Encoded'</span>, <span class="st">'Size_Freq_Encoded'</span>])</span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Scaled Frequency Encoded DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df_scaled)</span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-54"><a href="#cb33-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Impact on machine learning models</span></span>
<span id="cb33-55"><a href="#cb33-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Example using a simple logistic regression model</span></span>
<span id="cb33-56"><a href="#cb33-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-57"><a href="#cb33-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the data</span></span>
<span id="cb33-58"><a href="#cb33-58" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">'Color_Freq_Encoded'</span>, <span class="st">'Size_Freq_Encoded'</span>]]</span>
<span id="cb33-59"><a href="#cb33-59" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'Target'</span>]</span>
<span id="cb33-60"><a href="#cb33-60" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.33</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb33-61"><a href="#cb33-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-62"><a href="#cb33-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Training a logistic regression model</span></span>
<span id="cb33-63"><a href="#cb33-63" aria-hidden="true" tabindex="-1"></a>log_reg <span class="op">=</span> LogisticRegression()</span>
<span id="cb33-64"><a href="#cb33-64" aria-hidden="true" tabindex="-1"></a>log_reg.fit(X_train, y_train)</span>
<span id="cb33-65"><a href="#cb33-65" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> log_reg.predict(X_test)</span>
<span id="cb33-66"><a href="#cb33-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-67"><a href="#cb33-67" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating accuracy</span></span>
<span id="cb33-68"><a href="#cb33-68" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb33-69"><a href="#cb33-69" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Logistic Regression Accuracy with Frequency Encoding:"</span>, accuracy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Original DataFrame:
    Color Size  Target  Color_Freq_Encoded  Size_Freq_Encoded
0    Red    S       1                   3                  3
1  Green    M       0                   3                  4
2   Blue    L       1                   3                  2
3  Green    M       0                   3                  4
4    Red    S       1                   3                  3
5   Blue    L       0                   3                  2
6    Red    M       1                   3                  4
7  Green    M       0                   3                  4
8   Blue    S       1                   3                  3

Frequency Encoded DataFrame:
    Color  Color_Freq_Encoded Size  Size_Freq_Encoded  Target
0    Red                   3    S                  3       1
1  Green                   3    M                  4       0
2   Blue                   3    L                  2       1
3  Green                   3    M                  4       0
4    Red                   3    S                  3       1
5   Blue                   3    L                  2       0
6    Red                   3    M                  4       1
7  Green                   3    M                  4       0
8   Blue                   3    S                  3       1

Imbalanced DataFrame with Frequency Encoding:
    Color  Color_Freq_Encoded Size  Size_Freq_Encoded  Target
0    Red                  50    S                 30       1
1    Red                  50    S                 30       1
2    Red                  50    S                 30       1
3    Red                  50    S                 30       1
4    Red                  50    S                 30       1
..   ...                 ...  ...                ...     ...
60  Blue                  10    L                 10       1
61  Blue                  10    L                 10       1
62  Blue                  10    L                 10       1
63  Blue                  10    L                 10       1
64  Blue                  10    L                 10       1

[65 rows x 5 columns]

Scaled Frequency Encoded DataFrame:
    Color_Freq_Encoded  Size_Freq_Encoded
0                 0.0          -0.282843
1                 0.0           0.989949
2                 0.0          -1.555635
3                 0.0           0.989949
4                 0.0          -0.282843
5                 0.0          -1.555635
6                 0.0           0.989949
7                 0.0           0.989949
8                 0.0          -0.282843

Logistic Regression Accuracy with Frequency Encoding: 0.0</code></pre>
</div>
</div>
<hr>
</section>
<section id="target-encoding" class="level2">
<h2 class="anchored" data-anchor-id="target-encoding">2.3.6 Target Encoding</h2>
<p>Target encoding replaces each category with a mean value of the target variable for that category. For example, if the target variable is <code>Sales</code>:</p>
<p><code>Red   -&gt; mean(Sales for Red)</code></p>
<p><code>Green -&gt; mean(Sales for Green)</code></p>
<p><code>Blue  -&gt; mean(Sales for Blue)</code></p>
<p>Target encoding can lead to data leakage if not handled properly. It’s useful for models like linear regression and tree-based methods.</p>
<p>Advanced topics include:</p>
<ul>
<li><p>Regularization techniques to prevent overfitting in target encoding.</p></li>
<li><p>Cross-validation strategies to ensure robust target encoding.</p></li>
<li><p>Combining target encoding with other encoding methods for improved model performance.</p></li>
</ul>
<div id="4f12d844" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, KFold</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data with categorical features and target variable</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Color'</span>: [<span class="st">'Red'</span>, <span class="st">'Green'</span>, <span class="st">'Blue'</span>, <span class="st">'Green'</span>, <span class="st">'Red'</span>, <span class="st">'Blue'</span>, <span class="st">'Red'</span>, <span class="st">'Green'</span>, <span class="st">'Blue'</span>],</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Size'</span>: [<span class="st">'S'</span>, <span class="st">'M'</span>, <span class="st">'L'</span>, <span class="st">'M'</span>, <span class="st">'S'</span>, <span class="st">'L'</span>, <span class="st">'M'</span>, <span class="st">'M'</span>, <span class="st">'S'</span>],</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Sales'</span>: [<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">15</span>, <span class="dv">25</span>, <span class="dv">30</span>, <span class="dv">35</span>, <span class="dv">40</span>, <span class="dv">50</span>, <span class="dv">45</span>]</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.3.6 Target Encoding</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying Target Encoding</span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> target_encoding(train, test, target, column):</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>    target_mean <span class="op">=</span> train.groupby(column)[target].mean()</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>    test[column <span class="op">+</span> <span class="st">'_Target_Encoded'</span>] <span class="op">=</span> test[column].<span class="bu">map</span>(target_mean)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>    train[column <span class="op">+</span> <span class="st">'_Target_Encoded'</span>] <span class="op">=</span> train[column].<span class="bu">map</span>(target_mean)</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train, test</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the data for target encoding</span></span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">'Color'</span>, <span class="st">'Size'</span>]]</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'Sales'</span>]</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.33</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying target encoding to 'Color' column</span></span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>X_train[<span class="st">'Sales'</span>] <span class="op">=</span> y_train  <span class="co"># Adding target variable to the training set for encoding</span></span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>X_train, X_test <span class="op">=</span> target_encoding(X_train, X_test, <span class="st">'Sales'</span>, <span class="st">'Color'</span>)</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying target encoding to 'Size' column</span></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>X_train, X_test <span class="op">=</span> target_encoding(X_train, X_test, <span class="st">'Sales'</span>, <span class="st">'Size'</span>)</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Removing target column from X_train</span></span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>])</span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results</span></span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Target Encoded Train DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, X_train)</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Target Encoded Test DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, X_test)</span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations</span></span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Regularization techniques to prevent overfitting in target encoding</span></span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Adding a regularization term to smooth the target encoding</span></span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> regularized_target_encoding(train, test, target, column, min_samples_leaf<span class="op">=</span><span class="dv">1</span>, smoothing<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a>    target_mean <span class="op">=</span> train.groupby(column)[target].mean()</span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a>    target_count <span class="op">=</span> train.groupby(column)[target].count()</span>
<span id="cb35-50"><a href="#cb35-50" aria-hidden="true" tabindex="-1"></a>    overall_mean <span class="op">=</span> train[target].mean()</span>
<span id="cb35-51"><a href="#cb35-51" aria-hidden="true" tabindex="-1"></a>    train[column <span class="op">+</span> <span class="st">'_Target_Encoded'</span>] <span class="op">=</span> ((target_mean <span class="op">*</span> target_count <span class="op">+</span> overall_mean <span class="op">*</span> smoothing) <span class="op">/</span></span>
<span id="cb35-52"><a href="#cb35-52" aria-hidden="true" tabindex="-1"></a>                                         (target_count <span class="op">+</span> smoothing)).reindex(train[column]).values</span>
<span id="cb35-53"><a href="#cb35-53" aria-hidden="true" tabindex="-1"></a>    test[column <span class="op">+</span> <span class="st">'_Target_Encoded'</span>] <span class="op">=</span> ((target_mean <span class="op">*</span> target_count <span class="op">+</span> overall_mean <span class="op">*</span> smoothing) <span class="op">/</span></span>
<span id="cb35-54"><a href="#cb35-54" aria-hidden="true" tabindex="-1"></a>                                        (target_count <span class="op">+</span> smoothing)).reindex(test[column]).values</span>
<span id="cb35-55"><a href="#cb35-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train, test</span>
<span id="cb35-56"><a href="#cb35-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-57"><a href="#cb35-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying regularized target encoding to 'Color' column</span></span>
<span id="cb35-58"><a href="#cb35-58" aria-hidden="true" tabindex="-1"></a>X_train[<span class="st">'Sales'</span>] <span class="op">=</span> y_train  <span class="co"># Adding target variable to the training set for encoding</span></span>
<span id="cb35-59"><a href="#cb35-59" aria-hidden="true" tabindex="-1"></a>X_train, X_test <span class="op">=</span> regularized_target_encoding(X_train, X_test, <span class="st">'Sales'</span>, <span class="st">'Color'</span>)</span>
<span id="cb35-60"><a href="#cb35-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-61"><a href="#cb35-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying regularized target encoding to 'Size' column</span></span>
<span id="cb35-62"><a href="#cb35-62" aria-hidden="true" tabindex="-1"></a>X_train, X_test <span class="op">=</span> regularized_target_encoding(X_train, X_test, <span class="st">'Sales'</span>, <span class="st">'Size'</span>)</span>
<span id="cb35-63"><a href="#cb35-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-64"><a href="#cb35-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Removing target column from X_train</span></span>
<span id="cb35-65"><a href="#cb35-65" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>])</span>
<span id="cb35-66"><a href="#cb35-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-67"><a href="#cb35-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Regularized Target Encoded Train DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, X_train)</span>
<span id="cb35-68"><a href="#cb35-68" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Regularized Target Encoded Test DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, X_test)</span>
<span id="cb35-69"><a href="#cb35-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-70"><a href="#cb35-70" aria-hidden="true" tabindex="-1"></a><span class="co"># Cross-validation strategies to ensure robust target encoding</span></span>
<span id="cb35-71"><a href="#cb35-71" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cross_validated_target_encoding(df, target, column, n_splits<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb35-72"><a href="#cb35-72" aria-hidden="true" tabindex="-1"></a>    kf <span class="op">=</span> KFold(n_splits<span class="op">=</span>n_splits, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb35-73"><a href="#cb35-73" aria-hidden="true" tabindex="-1"></a>    df[column <span class="op">+</span> <span class="st">'_Target_Encoded'</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb35-74"><a href="#cb35-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> train_idx, val_idx <span class="kw">in</span> kf.split(df):</span>
<span id="cb35-75"><a href="#cb35-75" aria-hidden="true" tabindex="-1"></a>        train_fold, val_fold <span class="op">=</span> df.iloc[train_idx], df.iloc[val_idx]</span>
<span id="cb35-76"><a href="#cb35-76" aria-hidden="true" tabindex="-1"></a>        val_fold[column <span class="op">+</span> <span class="st">'_Target_Encoded'</span>] <span class="op">=</span> val_fold[column].<span class="bu">map</span>(train_fold.groupby(column)[target].mean())</span>
<span id="cb35-77"><a href="#cb35-77" aria-hidden="true" tabindex="-1"></a>        df.iloc[val_idx] <span class="op">=</span> val_fold</span>
<span id="cb35-78"><a href="#cb35-78" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb35-79"><a href="#cb35-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-80"><a href="#cb35-80" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying cross-validated target encoding to the entire dataframe</span></span>
<span id="cb35-81"><a href="#cb35-81" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> cross_validated_target_encoding(df, <span class="st">'Sales'</span>, <span class="st">'Color'</span>)</span>
<span id="cb35-82"><a href="#cb35-82" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> cross_validated_target_encoding(df, <span class="st">'Sales'</span>, <span class="st">'Size'</span>)</span>
<span id="cb35-83"><a href="#cb35-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-84"><a href="#cb35-84" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Cross-Validated Target Encoded DataFrame:</span><span class="ch">\n</span><span class="st">"</span>, df)</span>
<span id="cb35-85"><a href="#cb35-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-86"><a href="#cb35-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Impact on model performance</span></span>
<span id="cb35-87"><a href="#cb35-87" aria-hidden="true" tabindex="-1"></a><span class="co"># Example using a simple linear regression model</span></span>
<span id="cb35-88"><a href="#cb35-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-89"><a href="#cb35-89" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the data again after cross-validated target encoding</span></span>
<span id="cb35-90"><a href="#cb35-90" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">'Color_Target_Encoded'</span>, <span class="st">'Size_Target_Encoded'</span>]]</span>
<span id="cb35-91"><a href="#cb35-91" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'Sales'</span>]</span>
<span id="cb35-92"><a href="#cb35-92" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.33</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb35-93"><a href="#cb35-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-94"><a href="#cb35-94" aria-hidden="true" tabindex="-1"></a><span class="co"># Training a linear regression model</span></span>
<span id="cb35-95"><a href="#cb35-95" aria-hidden="true" tabindex="-1"></a>regressor <span class="op">=</span> LinearRegression()</span>
<span id="cb35-96"><a href="#cb35-96" aria-hidden="true" tabindex="-1"></a>regressor.fit(X_train, y_train)</span>
<span id="cb35-97"><a href="#cb35-97" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> regressor.predict(X_test)</span>
<span id="cb35-98"><a href="#cb35-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-99"><a href="#cb35-99" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating mean squared error</span></span>
<span id="cb35-100"><a href="#cb35-100" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb35-101"><a href="#cb35-101" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Linear Regression Mean Squared Error with Target Encoding:"</span>, mse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Original DataFrame:
    Color Size  Sales
0    Red    S     10
1  Green    M     20
2   Blue    L     15
3  Green    M     25
4    Red    S     30
5   Blue    L     35
6    Red    M     40
7  Green    M     50
8   Blue    S     45

Target Encoded Train DataFrame:
    Color Size  Color_Target_Encoded  Size_Target_Encoded
0    Red    S             26.666667            28.333333
8   Blue    S             30.000000            28.333333
2   Blue    L             30.000000            15.000000
4    Red    S             26.666667            28.333333
3  Green    M             25.000000            32.500000
6    Red    M             26.666667            32.500000

Target Encoded Test DataFrame:
    Color Size  Color_Target_Encoded  Size_Target_Encoded
7  Green    M                  25.0                 32.5
1  Green    M                  25.0                 32.5
5   Blue    L                  30.0                 15.0

Regularized Target Encoded Train DataFrame:
    Color Size  Color_Target_Encoded  Size_Target_Encoded
0    Red    S             26.875000            28.125000
8   Blue    S             29.166667            28.125000
2   Blue    L             29.166667            21.250000
4    Red    S             26.875000            28.125000
3  Green    M             26.250000            30.833333
6    Red    M             26.875000            30.833333

Regularized Target Encoded Test DataFrame:
    Color Size  Color_Target_Encoded  Size_Target_Encoded
7  Green    M             26.250000            30.833333
1  Green    M             26.250000            30.833333
5   Blue    L             29.166667            21.250000

Cross-Validated Target Encoded DataFrame:
    Color Size  Sales  Color_Target_Encoded  Size_Target_Encoded
0    Red    S     10                    35            37.500000
1  Green    M     20                    25            32.500000
2   Blue    L     15                    35            35.000000
3  Green    M     25                    35            36.666667
4    Red    S     30                    25            27.500000
5   Blue    L     35                    30            15.000000
6    Red    M     40                    20            31.666667
7  Green    M     50                    25            32.500000
8   Blue    S     45                    35            20.000000

Linear Regression Mean Squared Error with Target Encoding: 280.9782887682148</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/v8/l5r44ftx4g5bx2y5fhdpcmmh0000gn/T/ipykernel_20299/3899796125.py:76: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

/var/folders/v8/l5r44ftx4g5bx2y5fhdpcmmh0000gn/T/ipykernel_20299/3899796125.py:76: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

/var/folders/v8/l5r44ftx4g5bx2y5fhdpcmmh0000gn/T/ipykernel_20299/3899796125.py:76: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

/var/folders/v8/l5r44ftx4g5bx2y5fhdpcmmh0000gn/T/ipykernel_20299/3899796125.py:76: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

/var/folders/v8/l5r44ftx4g5bx2y5fhdpcmmh0000gn/T/ipykernel_20299/3899796125.py:76: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

/var/folders/v8/l5r44ftx4g5bx2y5fhdpcmmh0000gn/T/ipykernel_20299/3899796125.py:76: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

/var/folders/v8/l5r44ftx4g5bx2y5fhdpcmmh0000gn/T/ipykernel_20299/3899796125.py:77: FutureWarning:

Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[32.5 32.5]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.

/var/folders/v8/l5r44ftx4g5bx2y5fhdpcmmh0000gn/T/ipykernel_20299/3899796125.py:76: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

/var/folders/v8/l5r44ftx4g5bx2y5fhdpcmmh0000gn/T/ipykernel_20299/3899796125.py:76: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

/var/folders/v8/l5r44ftx4g5bx2y5fhdpcmmh0000gn/T/ipykernel_20299/3899796125.py:76: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

/var/folders/v8/l5r44ftx4g5bx2y5fhdpcmmh0000gn/T/ipykernel_20299/3899796125.py:76: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="handling-imbalanced-datasets" class="level1">
<h1>2.4 Handling Imbalanced Datasets</h1>
<p>Imbalanced datasets are common in machine learning, particularly in classification problems where one class significantly outnumbers the other(s). Handling imbalanced datasets is crucial to ensure that the model performs well across all classes. Below is a detailed guide from basic to advanced techniques.</p>
<section id="oversampling-techniques" class="level2">
<h2 class="anchored" data-anchor-id="oversampling-techniques">2.4.1 Oversampling Techniques</h2>
<section id="random-oversampling" class="level4">
<h4 class="anchored" data-anchor-id="random-oversampling">2.4.1.1 Random Oversampling</h4>
<p>Random oversampling involves duplicating examples from the minority class to balance the dataset. This method can be effective but may lead to overfitting.</p>
</section>
<section id="smote-synthetic-minority-over-sampling-technique" class="level4">
<h4 class="anchored" data-anchor-id="smote-synthetic-minority-over-sampling-technique">2.4.1.2 SMOTE (Synthetic Minority Over-sampling Technique)</h4>
<p>SMOTE generates synthetic samples for the minority class by interpolating between existing minority examples. It is less prone to overfitting compared to random oversampling. The process is as follows:</p>
<ol type="1">
<li><p>For each minority class sample, select k nearest neighbours.</p></li>
<li><p>Randomly choose one of the k neighbours and generate a synthetic example by interpolating between the chosen sample and its neighbour.</p></li>
</ol>
</section>
<section id="adasyn-adaptive-synthetic" class="level4">
<h4 class="anchored" data-anchor-id="adasyn-adaptive-synthetic">2.4.1.3 ADASYN (Adaptive Synthetic)</h4>
<p>ADASYN improves on SMOTE by generating more synthetic data for minority class examples that are harder to learn. The number of synthetic samples generated is proportional to the difficulty of learning those examples. It follows these steps:</p>
<ol type="1">
<li><p>Compute the ratio of minority to majority samples for each minority sample.</p></li>
<li><p>Generate synthetic samples, with more samples generated for minority examples with higher difficulty ratios.</p></li>
</ol>
<div id="34ef3f68" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.over_sampling <span class="im">import</span> RandomOverSampler, SMOTE, ADASYN</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a sample imbalanced dataset</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification(n_samples<span class="op">=</span><span class="dv">1000</span>, n_features<span class="op">=</span><span class="dv">20</span>, n_informative<span class="op">=</span><span class="dv">2</span>, n_redundant<span class="op">=</span><span class="dv">10</span>, n_clusters_per_class<span class="op">=</span><span class="dv">1</span>, weights<span class="op">=</span>[<span class="fl">0.95</span>], flip_y<span class="op">=</span><span class="dv">0</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the data into training and test sets</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.4.1 Oversampling Techniques</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.4.1.1 Random Oversampling</span></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>ros <span class="op">=</span> RandomOverSampler(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>X_resampled_ros, y_resampled_ros <span class="op">=</span> ros.fit_resample(X_train, y_train)</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Training a model on randomly oversampled data</span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>clf_ros <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>clf_ros.fit(X_resampled_ros, y_resampled_ros)</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>y_pred_ros <span class="op">=</span> clf_ros.predict(X_test)</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report for Random Oversampling:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_ros))</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.4.1.2 SMOTE (Synthetic Minority Over-sampling Technique)</span></span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a>smote <span class="op">=</span> SMOTE(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a>X_resampled_smote, y_resampled_smote <span class="op">=</span> smote.fit_resample(X_train, y_train)</span>
<span id="cb38-31"><a href="#cb38-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-32"><a href="#cb38-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Training a model on SMOTE oversampled data</span></span>
<span id="cb38-33"><a href="#cb38-33" aria-hidden="true" tabindex="-1"></a>clf_smote <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb38-34"><a href="#cb38-34" aria-hidden="true" tabindex="-1"></a>clf_smote.fit(X_resampled_smote, y_resampled_smote)</span>
<span id="cb38-35"><a href="#cb38-35" aria-hidden="true" tabindex="-1"></a>y_pred_smote <span class="op">=</span> clf_smote.predict(X_test)</span>
<span id="cb38-36"><a href="#cb38-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-37"><a href="#cb38-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report for SMOTE:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb38-38"><a href="#cb38-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_smote))</span>
<span id="cb38-39"><a href="#cb38-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-40"><a href="#cb38-40" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.4.1.3 ADASYN (Adaptive Synthetic)</span></span>
<span id="cb38-41"><a href="#cb38-41" aria-hidden="true" tabindex="-1"></a>adasyn <span class="op">=</span> ADASYN(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb38-42"><a href="#cb38-42" aria-hidden="true" tabindex="-1"></a>X_resampled_adasyn, y_resampled_adasyn <span class="op">=</span> adasyn.fit_resample(X_train, y_train)</span>
<span id="cb38-43"><a href="#cb38-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-44"><a href="#cb38-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Training a model on ADASYN oversampled data</span></span>
<span id="cb38-45"><a href="#cb38-45" aria-hidden="true" tabindex="-1"></a>clf_adasyn <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb38-46"><a href="#cb38-46" aria-hidden="true" tabindex="-1"></a>clf_adasyn.fit(X_resampled_adasyn, y_resampled_adasyn)</span>
<span id="cb38-47"><a href="#cb38-47" aria-hidden="true" tabindex="-1"></a>y_pred_adasyn <span class="op">=</span> clf_adasyn.predict(X_test)</span>
<span id="cb38-48"><a href="#cb38-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-49"><a href="#cb38-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report for ADASYN:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb38-50"><a href="#cb38-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_adasyn))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Classification Report for Random Oversampling:

              precision    recall  f1-score   support

           0       0.99      1.00      0.99       290
           1       0.89      0.80      0.84        10

    accuracy                           0.99       300
   macro avg       0.94      0.90      0.92       300
weighted avg       0.99      0.99      0.99       300

Classification Report for SMOTE:

              precision    recall  f1-score   support

           0       0.99      1.00      0.99       290
           1       0.89      0.80      0.84        10

    accuracy                           0.99       300
   macro avg       0.94      0.90      0.92       300
weighted avg       0.99      0.99      0.99       300

Classification Report for ADASYN:

              precision    recall  f1-score   support

           0       0.99      0.99      0.99       290
           1       0.80      0.80      0.80        10

    accuracy                           0.99       300
   macro avg       0.90      0.90      0.90       300
weighted avg       0.99      0.99      0.99       300
</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="undersampling-techniques" class="level2">
<h2 class="anchored" data-anchor-id="undersampling-techniques">2.4.2 Undersampling Techniques</h2>
<section id="random-undersampling" class="level4">
<h4 class="anchored" data-anchor-id="random-undersampling">2.4.2.1 Random Undersampling</h4>
<p>Random undersampling reduces the number of majority class samples to balance the dataset. This method can lead to loss of important information but is straightforward to implement.</p>
</section>
<section id="tomek-links" class="level4">
<h4 class="anchored" data-anchor-id="tomek-links">2.4.2.2 Tomek Links</h4>
<p>Tomek links identify pairs of examples from opposite classes that are each other’s nearest neighbours. Removing these pairs helps to clean the data and reduce the majority class. The steps are:</p>
<ol type="1">
<li><p>Find all pairs of nearest neighbours from different classes.</p></li>
<li><p>Remove the majority class examples from these pairs.</p></li>
</ol>
</section>
<section id="cluster-centroids" class="level4">
<h4 class="anchored" data-anchor-id="cluster-centroids">2.4.2.3 Cluster Centroids</h4>
<p>Cluster centroids method involves clustering the majority class examples and replacing clusters with their centroids. This reduces the number of majority class examples while preserving their distribution. The process is:</p>
<ol type="1">
<li><p>Apply a clustering algorithm to the majority class.</p></li>
<li><p>Replace each cluster with its centroid.</p></li>
</ol>
<div id="e70798e9" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.under_sampling <span class="im">import</span> RandomUnderSampler, TomekLinks, ClusterCentroids</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a sample imbalanced dataset</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification(n_samples<span class="op">=</span><span class="dv">1000</span>, n_features<span class="op">=</span><span class="dv">20</span>, n_informative<span class="op">=</span><span class="dv">2</span>, n_redundant<span class="op">=</span><span class="dv">10</span>, n_clusters_per_class<span class="op">=</span><span class="dv">1</span>, weights<span class="op">=</span>[<span class="fl">0.95</span>], flip_y<span class="op">=</span><span class="dv">0</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the data into training and test sets</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.4.2 Undersampling Techniques</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.4.2.1 Random Undersampling</span></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>rus <span class="op">=</span> RandomUnderSampler(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>X_resampled_rus, y_resampled_rus <span class="op">=</span> rus.fit_resample(X_train, y_train)</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Training a model on randomly undersampled data</span></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>clf_rus <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>clf_rus.fit(X_resampled_rus, y_resampled_rus)</span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>y_pred_rus <span class="op">=</span> clf_rus.predict(X_test)</span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report for Random Undersampling:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_rus))</span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.4.2.2 Tomek Links</span></span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a>tl <span class="op">=</span> TomekLinks()</span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a>X_resampled_tl, y_resampled_tl <span class="op">=</span> tl.fit_resample(X_train, y_train)</span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Training a model on Tomek links undersampled data</span></span>
<span id="cb40-33"><a href="#cb40-33" aria-hidden="true" tabindex="-1"></a>clf_tl <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb40-34"><a href="#cb40-34" aria-hidden="true" tabindex="-1"></a>clf_tl.fit(X_resampled_tl, y_resampled_tl)</span>
<span id="cb40-35"><a href="#cb40-35" aria-hidden="true" tabindex="-1"></a>y_pred_tl <span class="op">=</span> clf_tl.predict(X_test)</span>
<span id="cb40-36"><a href="#cb40-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-37"><a href="#cb40-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report for Tomek Links:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb40-38"><a href="#cb40-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_tl))</span>
<span id="cb40-39"><a href="#cb40-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-40"><a href="#cb40-40" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.4.2.3 Cluster Centroids</span></span>
<span id="cb40-41"><a href="#cb40-41" aria-hidden="true" tabindex="-1"></a>cc <span class="op">=</span> ClusterCentroids(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb40-42"><a href="#cb40-42" aria-hidden="true" tabindex="-1"></a>X_resampled_cc, y_resampled_cc <span class="op">=</span> cc.fit_resample(X_train, y_train)</span>
<span id="cb40-43"><a href="#cb40-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-44"><a href="#cb40-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Training a model on cluster centroids undersampled data</span></span>
<span id="cb40-45"><a href="#cb40-45" aria-hidden="true" tabindex="-1"></a>clf_cc <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb40-46"><a href="#cb40-46" aria-hidden="true" tabindex="-1"></a>clf_cc.fit(X_resampled_cc, y_resampled_cc)</span>
<span id="cb40-47"><a href="#cb40-47" aria-hidden="true" tabindex="-1"></a>y_pred_cc <span class="op">=</span> clf_cc.predict(X_test)</span>
<span id="cb40-48"><a href="#cb40-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-49"><a href="#cb40-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report for Cluster Centroids:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb40-50"><a href="#cb40-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_cc))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Classification Report for Random Undersampling:

              precision    recall  f1-score   support

           0       0.99      0.98      0.99       290
           1       0.57      0.80      0.67        10

    accuracy                           0.97       300
   macro avg       0.78      0.89      0.83       300
weighted avg       0.98      0.97      0.98       300

Classification Report for Tomek Links:

              precision    recall  f1-score   support

           0       0.99      0.99      0.99       290
           1       0.78      0.70      0.74        10

    accuracy                           0.98       300
   macro avg       0.88      0.85      0.86       300
weighted avg       0.98      0.98      0.98       300

Classification Report for Cluster Centroids:

              precision    recall  f1-score   support

           0       0.99      0.99      0.99       290
           1       0.73      0.80      0.76        10

    accuracy                           0.98       300
   macro avg       0.86      0.89      0.88       300
weighted avg       0.98      0.98      0.98       300
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/ravishankar/miniforge3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning:

The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="combination-methods" class="level2">
<h2 class="anchored" data-anchor-id="combination-methods">2.4.3 Combination Methods</h2>
<section id="smoteenn" class="level4">
<h4 class="anchored" data-anchor-id="smoteenn">2.4.3.1 SMOTEENN</h4>
<p>SMOTEENN combines SMOTE and Edited Nearest Neighbours (ENN) for balancing datasets. The steps are:</p>
<ol type="1">
<li><p>Apply SMOTE to generate synthetic minority class examples.</p></li>
<li><p>Use ENN to remove noisy samples from the dataset.</p></li>
</ol>
</section>
<section id="smotetomek" class="level4">
<h4 class="anchored" data-anchor-id="smotetomek">2.4.3.2 SMOTETomek</h4>
<p>SMOTETomek combines SMOTE and Tomek links for better balancing. The process involves:</p>
<ol type="1">
<li><p>Apply SMOTE to create synthetic minority class examples.</p></li>
<li><p>Use Tomek links to remove overlapping examples from both classes.</p></li>
</ol>
<div id="6c212687" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.combine <span class="im">import</span> SMOTEENN, SMOTETomek</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a sample imbalanced dataset</span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification(n_samples<span class="op">=</span><span class="dv">1000</span>, n_features<span class="op">=</span><span class="dv">20</span>, n_informative<span class="op">=</span><span class="dv">2</span>, n_redundant<span class="op">=</span><span class="dv">10</span>, n_clusters_per_class<span class="op">=</span><span class="dv">1</span>, weights<span class="op">=</span>[<span class="fl">0.95</span>], flip_y<span class="op">=</span><span class="dv">0</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the data into training and test sets</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.4.3 Combination Methods</span></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.4.3.1 SMOTEENN</span></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>smoteenn <span class="op">=</span> SMOTEENN(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>X_resampled_smoteenn, y_resampled_smoteenn <span class="op">=</span> smoteenn.fit_resample(X_train, y_train)</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Training a model on SMOTEENN resampled data</span></span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>clf_smoteenn <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>clf_smoteenn.fit(X_resampled_smoteenn, y_resampled_smoteenn)</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>y_pred_smoteenn <span class="op">=</span> clf_smoteenn.predict(X_test)</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report for SMOTEENN:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_smoteenn))</span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.4.3.2 SMOTETomek</span></span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>smotetomek <span class="op">=</span> SMOTETomek(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>X_resampled_smotetomek, y_resampled_smotetomek <span class="op">=</span> smotetomek.fit_resample(X_train, y_train)</span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Training a model on SMOTETomek resampled data</span></span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>clf_smotetomek <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a>clf_smotetomek.fit(X_resampled_smotetomek, y_resampled_smotetomek)</span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a>y_pred_smotetomek <span class="op">=</span> clf_smotetomek.predict(X_test)</span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report for SMOTETomek:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_smotetomek))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Classification Report for SMOTEENN:

              precision    recall  f1-score   support

           0       0.99      0.99      0.99       290
           1       0.80      0.80      0.80        10

    accuracy                           0.99       300
   macro avg       0.90      0.90      0.90       300
weighted avg       0.99      0.99      0.99       300

Classification Report for SMOTETomek:

              precision    recall  f1-score   support

           0       0.99      1.00      0.99       290
           1       0.89      0.80      0.84        10

    accuracy                           0.99       300
   macro avg       0.94      0.90      0.92       300
weighted avg       0.99      0.99      0.99       300
</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="ensemble-methods-for-imbalanced-learning" class="level2">
<h2 class="anchored" data-anchor-id="ensemble-methods-for-imbalanced-learning">2.4.4 Ensemble Methods for Imbalanced Learning</h2>
<p>Ensemble methods combine multiple models to improve performance on imbalanced datasets. Techniques include:</p>
<ul>
<li><p><strong>Bagging:</strong> Building multiple models from different subsets of the data, such as BalancedRandomForest.</p></li>
<li><p><strong>Boosting:</strong> Adjusting the weight of each sample based on previous classification results, such as AdaBoost and Gradient Boosting.</p></li>
<li><p><strong>Hybrid Methods:</strong> Combining different ensemble methods and resampling techniques, like BalancedBaggingClassifier and EasyEnsemble.</p></li>
</ul>
<p>Advanced considerations include: - Tuning the parameters of ensemble methods to optimize performance for imbalanced datasets.</p>
<ul>
<li><p>Combining ensemble methods with oversampling and undersampling techniques.</p></li>
<li><p>Evaluating model performance using appropriate metrics like precision-recall curves and F1 score.</p></li>
</ul>
<div id="f150d182" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.ensemble <span class="im">import</span> BalancedRandomForestClassifier, BalancedBaggingClassifier, EasyEnsembleClassifier</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, precision_recall_curve, f1_score</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a sample imbalanced dataset</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification(n_samples<span class="op">=</span><span class="dv">1000</span>, n_features<span class="op">=</span><span class="dv">20</span>, n_informative<span class="op">=</span><span class="dv">2</span>, n_redundant<span class="op">=</span><span class="dv">10</span>, n_clusters_per_class<span class="op">=</span><span class="dv">1</span>, weights<span class="op">=</span>[<span class="fl">0.95</span>], flip_y<span class="op">=</span><span class="dv">0</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the data into training and test sets</span></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.4.4 Ensemble Methods for Imbalanced Learning</span></span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Balanced Random Forest</span></span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>brf <span class="op">=</span> BalancedRandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>brf.fit(X_train, y_train)</span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>y_pred_brf <span class="op">=</span> brf.predict(X_test)</span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report for Balanced Random Forest:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_brf))</span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a><span class="co"># AdaBoost</span></span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a>ada <span class="op">=</span> AdaBoostClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a>ada.fit(X_train, y_train)</span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a>y_pred_ada <span class="op">=</span> ada.predict(X_test)</span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report for AdaBoost:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb45-29"><a href="#cb45-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_ada))</span>
<span id="cb45-30"><a href="#cb45-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-31"><a href="#cb45-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Gradient Boosting</span></span>
<span id="cb45-32"><a href="#cb45-32" aria-hidden="true" tabindex="-1"></a>gb <span class="op">=</span> GradientBoostingClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb45-33"><a href="#cb45-33" aria-hidden="true" tabindex="-1"></a>gb.fit(X_train, y_train)</span>
<span id="cb45-34"><a href="#cb45-34" aria-hidden="true" tabindex="-1"></a>y_pred_gb <span class="op">=</span> gb.predict(X_test)</span>
<span id="cb45-35"><a href="#cb45-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report for Gradient Boosting:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb45-36"><a href="#cb45-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_gb))</span>
<span id="cb45-37"><a href="#cb45-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-38"><a href="#cb45-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Balanced Bagging Classifier</span></span>
<span id="cb45-39"><a href="#cb45-39" aria-hidden="true" tabindex="-1"></a>bbc <span class="op">=</span> BalancedBaggingClassifier(estimator<span class="op">=</span>RandomForestClassifier(), random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb45-40"><a href="#cb45-40" aria-hidden="true" tabindex="-1"></a>bbc.fit(X_train, y_train)</span>
<span id="cb45-41"><a href="#cb45-41" aria-hidden="true" tabindex="-1"></a>y_pred_bbc <span class="op">=</span> bbc.predict(X_test)</span>
<span id="cb45-42"><a href="#cb45-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report for Balanced Bagging Classifier:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb45-43"><a href="#cb45-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_bbc))</span>
<span id="cb45-44"><a href="#cb45-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-45"><a href="#cb45-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Easy Ensemble Classifier</span></span>
<span id="cb45-46"><a href="#cb45-46" aria-hidden="true" tabindex="-1"></a>eec <span class="op">=</span> EasyEnsembleClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb45-47"><a href="#cb45-47" aria-hidden="true" tabindex="-1"></a>eec.fit(X_train, y_train)</span>
<span id="cb45-48"><a href="#cb45-48" aria-hidden="true" tabindex="-1"></a>y_pred_eec <span class="op">=</span> eec.predict(X_test)</span>
<span id="cb45-49"><a href="#cb45-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report for Easy Ensemble Classifier:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb45-50"><a href="#cb45-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_eec))</span>
<span id="cb45-51"><a href="#cb45-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-52"><a href="#cb45-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations</span></span>
<span id="cb45-53"><a href="#cb45-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-54"><a href="#cb45-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Combining ensemble methods with oversampling techniques</span></span>
<span id="cb45-55"><a href="#cb45-55" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.over_sampling <span class="im">import</span> SMOTE</span>
<span id="cb45-56"><a href="#cb45-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-57"><a href="#cb45-57" aria-hidden="true" tabindex="-1"></a>smote <span class="op">=</span> SMOTE(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb45-58"><a href="#cb45-58" aria-hidden="true" tabindex="-1"></a>X_resampled, y_resampled <span class="op">=</span> smote.fit_resample(X_train, y_train)</span>
<span id="cb45-59"><a href="#cb45-59" aria-hidden="true" tabindex="-1"></a>brf_smote <span class="op">=</span> BalancedRandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb45-60"><a href="#cb45-60" aria-hidden="true" tabindex="-1"></a>brf_smote.fit(X_resampled, y_resampled)</span>
<span id="cb45-61"><a href="#cb45-61" aria-hidden="true" tabindex="-1"></a>y_pred_brf_smote <span class="op">=</span> brf_smote.predict(X_test)</span>
<span id="cb45-62"><a href="#cb45-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report for Balanced Random Forest with SMOTE:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb45-63"><a href="#cb45-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_brf_smote))</span>
<span id="cb45-64"><a href="#cb45-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-65"><a href="#cb45-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluating model performance using precision-recall curves and F1 score</span></span>
<span id="cb45-66"><a href="#cb45-66" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_precision_recall_curve(y_true, y_pred, model_name):</span>
<span id="cb45-67"><a href="#cb45-67" aria-hidden="true" tabindex="-1"></a>    precision, recall, _ <span class="op">=</span> precision_recall_curve(y_true, y_pred)</span>
<span id="cb45-68"><a href="#cb45-68" aria-hidden="true" tabindex="-1"></a>    plt.plot(recall, precision, marker<span class="op">=</span><span class="st">'.'</span>, label<span class="op">=</span>model_name)</span>
<span id="cb45-69"><a href="#cb45-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-70"><a href="#cb45-70" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb45-71"><a href="#cb45-71" aria-hidden="true" tabindex="-1"></a>plot_precision_recall_curve(y_test, y_pred_brf, <span class="st">"Balanced Random Forest"</span>)</span>
<span id="cb45-72"><a href="#cb45-72" aria-hidden="true" tabindex="-1"></a>plot_precision_recall_curve(y_test, y_pred_ada, <span class="st">"AdaBoost"</span>)</span>
<span id="cb45-73"><a href="#cb45-73" aria-hidden="true" tabindex="-1"></a>plot_precision_recall_curve(y_test, y_pred_gb, <span class="st">"Gradient Boosting"</span>)</span>
<span id="cb45-74"><a href="#cb45-74" aria-hidden="true" tabindex="-1"></a>plot_precision_recall_curve(y_test, y_pred_bbc, <span class="st">"Balanced Bagging Classifier"</span>)</span>
<span id="cb45-75"><a href="#cb45-75" aria-hidden="true" tabindex="-1"></a>plot_precision_recall_curve(y_test, y_pred_eec, <span class="st">"Easy Ensemble Classifier"</span>)</span>
<span id="cb45-76"><a href="#cb45-76" aria-hidden="true" tabindex="-1"></a>plot_precision_recall_curve(y_test, y_pred_brf_smote, <span class="st">"Balanced Random Forest with SMOTE"</span>)</span>
<span id="cb45-77"><a href="#cb45-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-78"><a href="#cb45-78" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Recall'</span>)</span>
<span id="cb45-79"><a href="#cb45-79" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Precision'</span>)</span>
<span id="cb45-80"><a href="#cb45-80" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Precision-Recall Curves'</span>)</span>
<span id="cb45-81"><a href="#cb45-81" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb45-82"><a href="#cb45-82" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb45-83"><a href="#cb45-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-84"><a href="#cb45-84" aria-hidden="true" tabindex="-1"></a><span class="co"># F1 scores for each model</span></span>
<span id="cb45-85"><a href="#cb45-85" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"F1 Score for Balanced Random Forest:"</span>, f1_score(y_test, y_pred_brf))</span>
<span id="cb45-86"><a href="#cb45-86" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"F1 Score for AdaBoost:"</span>, f1_score(y_test, y_pred_ada))</span>
<span id="cb45-87"><a href="#cb45-87" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"F1 Score for Gradient Boosting:"</span>, f1_score(y_test, y_pred_gb))</span>
<span id="cb45-88"><a href="#cb45-88" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"F1 Score for Balanced Bagging Classifier:"</span>, f1_score(y_test, y_pred_bbc))</span>
<span id="cb45-89"><a href="#cb45-89" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"F1 Score for Easy Ensemble Classifier:"</span>, f1_score(y_test, y_pred_eec))</span>
<span id="cb45-90"><a href="#cb45-90" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"F1 Score for Balanced Random Forest with SMOTE:"</span>, f1_score(y_test, y_pred_brf_smote))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Classification Report for Balanced Random Forest:

              precision    recall  f1-score   support

           0       0.99      0.99      0.99       290
           1       0.80      0.80      0.80        10

    accuracy                           0.99       300
   macro avg       0.90      0.90      0.90       300
weighted avg       0.99      0.99      0.99       300

Classification Report for AdaBoost:

              precision    recall  f1-score   support

           0       0.99      0.99      0.99       290
           1       0.78      0.70      0.74        10

    accuracy                           0.98       300
   macro avg       0.88      0.85      0.86       300
weighted avg       0.98      0.98      0.98       300
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/ravishankar/miniforge3/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:577: FutureWarning:

The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.

/Users/ravishankar/miniforge3/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:589: FutureWarning:

The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.

/Users/ravishankar/miniforge3/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:601: FutureWarning:

The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.
</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Classification Report for Gradient Boosting:

              precision    recall  f1-score   support

           0       1.00      0.99      0.99       290
           1       0.82      0.90      0.86        10

    accuracy                           0.99       300
   macro avg       0.91      0.95      0.93       300
weighted avg       0.99      0.99      0.99       300

Classification Report for Balanced Bagging Classifier:

              precision    recall  f1-score   support

           0       0.99      0.99      0.99       290
           1       0.78      0.70      0.74        10

    accuracy                           0.98       300
   macro avg       0.88      0.85      0.86       300
weighted avg       0.98      0.98      0.98       300

Classification Report for Easy Ensemble Classifier:

              precision    recall  f1-score   support

           0       0.99      0.99      0.99       290
           1       0.67      0.80      0.73        10

    accuracy                           0.98       300
   macro avg       0.83      0.89      0.86       300
weighted avg       0.98      0.98      0.98       300

Classification Report for Balanced Random Forest with SMOTE:

              precision    recall  f1-score   support

           0       0.99      1.00      0.99       290
           1       0.89      0.80      0.84        10

    accuracy                           0.99       300
   macro avg       0.94      0.90      0.92       300
weighted avg       0.99      0.99      0.99       300
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/ravishankar/miniforge3/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:577: FutureWarning:

The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.

/Users/ravishankar/miniforge3/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:589: FutureWarning:

The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.

/Users/ravishankar/miniforge3/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:601: FutureWarning:

The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-20-output-5.png" width="812" height="671" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>F1 Score for Balanced Random Forest: 0.8000000000000002
F1 Score for AdaBoost: 0.7368421052631577
F1 Score for Gradient Boosting: 0.8571428571428572
F1 Score for Balanced Bagging Classifier: 0.7368421052631577
F1 Score for Easy Ensemble Classifier: 0.7272727272727272
F1 Score for Balanced Random Forest with SMOTE: 0.8421052631578948</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="data-augmentation-techniques" class="level1">
<h1>2.5 Data Augmentation Techniques</h1>
<p>Data augmentation techniques are essential for enhancing the diversity of training data without collecting new data. These techniques help improve the robustness and generalizability of machine learning models. Below is a comprehensive guide from basic to advanced techniques.</p>
<section id="image-augmentation" class="level2">
<h2 class="anchored" data-anchor-id="image-augmentation">2.5.1 Image Augmentation</h2>
<section id="geometric-transformations" class="level4">
<h4 class="anchored" data-anchor-id="geometric-transformations">2.5.1.1 Geometric Transformations</h4>
<p>Geometric transformations alter the spatial structure of images while preserving their content. Common techniques include:</p>
<ul>
<li><p><strong>Rotation:</strong> Rotating images by a certain angle. Example: Rotating an image of a cat by 45 degrees.</p></li>
<li><p><strong>Translation:</strong> Shifting images horizontally or vertically. Example: Shifting an image of a dog 10 pixels to the right.</p></li>
<li><p><strong>Scaling:</strong> Resizing images while maintaining aspect ratio. Example: Scaling an image of a house by 0.8 times.</p></li>
<li><p><strong>Flipping:</strong> Horizontally or vertically flipping images. Example: Horizontally flipping an image of a car.</p></li>
<li><p><strong>Cropping:</strong> Randomly or systematically cropping parts of images. Example: Cropping the central 50% of an image of a landscape.</p></li>
</ul>
</section>
<section id="color-space-augmentations" class="level4">
<h4 class="anchored" data-anchor-id="color-space-augmentations">2.5.1.2 Color Space Augmentations</h4>
<p>Color space augmentations modify the color properties of images. Techniques include:</p>
<ul>
<li><p><strong>Brightness Adjustment:</strong> Increasing or decreasing the brightness of images. Example: Increasing the brightness of an image of a sunset by 20%.</p></li>
<li><p><strong>Contrast Adjustment:</strong> Modifying the contrast levels. Example: Decreasing the contrast of an image of a forest by 30%.</p></li>
<li><p><strong>Saturation Adjustment:</strong> Changing the intensity of colors. Example: Increasing the saturation of an image of a flower garden.</p></li>
<li><p><strong>Hue Adjustment:</strong> Shifting the hue values in images. Example: Shifting the hue of an image of the ocean by 15 degrees.</p></li>
</ul>
</section>
<section id="mixing-images" class="level4">
<h4 class="anchored" data-anchor-id="mixing-images">2.5.1.3 Mixing Images</h4>
<p>Mixing images involves combining multiple images to create new training samples. Techniques include:</p>
<ul>
<li><p><strong>Image Blending:</strong> Combining two images with a specific blending ratio. Example: Blending an image of a cat with an image of a dog with a 50:50 ratio.</p></li>
<li><p><strong>CutMix:</strong> Cutting and pasting patches from one image onto another. Example: Cutting a patch from an image of a tree and pasting it onto an image of a mountain.</p></li>
<li><p><strong>MixUp:</strong> Creating a new image by linearly interpolating between two images. Example: Interpolating between an image of a bird and an image of a plane.</p></li>
</ul>
<div id="80e68d09" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image, ImageEnhance</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to display images</span></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> display_image(image, title<span class="op">=</span><span class="st">"Image"</span>):</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>    plt.imshow(image)</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Load sample image</span></span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>image_path <span class="op">=</span> <span class="st">'../../../test_image.jpg'</span></span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> cv2.imread(image_path)</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> image <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">FileNotFoundError</span>(<span class="ss">f"Image file '</span><span class="sc">{</span>image_path<span class="sc">}</span><span class="ss">' not found."</span>)</span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> cv2.cvtColor(image, cv2.COLOR_BGR2RGB)</span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.5.1.1 Geometric Transformations</span></span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-22"><a href="#cb51-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Rotation</span></span>
<span id="cb51-23"><a href="#cb51-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rotate_image(image, angle):</span>
<span id="cb51-24"><a href="#cb51-24" aria-hidden="true" tabindex="-1"></a>    (h, w) <span class="op">=</span> image.shape[:<span class="dv">2</span>]</span>
<span id="cb51-25"><a href="#cb51-25" aria-hidden="true" tabindex="-1"></a>    center <span class="op">=</span> (w <span class="op">/</span> <span class="dv">2</span>, h <span class="op">/</span> <span class="dv">2</span>)</span>
<span id="cb51-26"><a href="#cb51-26" aria-hidden="true" tabindex="-1"></a>    M <span class="op">=</span> cv2.getRotationMatrix2D(center, angle, <span class="fl">1.0</span>)</span>
<span id="cb51-27"><a href="#cb51-27" aria-hidden="true" tabindex="-1"></a>    rotated <span class="op">=</span> cv2.warpAffine(image, M, (w, h))</span>
<span id="cb51-28"><a href="#cb51-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> rotated</span>
<span id="cb51-29"><a href="#cb51-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-30"><a href="#cb51-30" aria-hidden="true" tabindex="-1"></a>rotated_image <span class="op">=</span> rotate_image(image, <span class="dv">45</span>)</span>
<span id="cb51-31"><a href="#cb51-31" aria-hidden="true" tabindex="-1"></a>display_image(rotated_image, <span class="st">"Rotated Image (45 degrees)"</span>)</span>
<span id="cb51-32"><a href="#cb51-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-33"><a href="#cb51-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Translation</span></span>
<span id="cb51-34"><a href="#cb51-34" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> translate_image(image, x, y):</span>
<span id="cb51-35"><a href="#cb51-35" aria-hidden="true" tabindex="-1"></a>    M <span class="op">=</span> np.float32([[<span class="dv">1</span>, <span class="dv">0</span>, x], [<span class="dv">0</span>, <span class="dv">1</span>, y]])</span>
<span id="cb51-36"><a href="#cb51-36" aria-hidden="true" tabindex="-1"></a>    translated <span class="op">=</span> cv2.warpAffine(image, M, (image.shape[<span class="dv">1</span>], image.shape[<span class="dv">0</span>]))</span>
<span id="cb51-37"><a href="#cb51-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> translated</span>
<span id="cb51-38"><a href="#cb51-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-39"><a href="#cb51-39" aria-hidden="true" tabindex="-1"></a>translated_image <span class="op">=</span> translate_image(image, <span class="dv">10</span>, <span class="dv">20</span>)</span>
<span id="cb51-40"><a href="#cb51-40" aria-hidden="true" tabindex="-1"></a>display_image(translated_image, <span class="st">"Translated Image (10px right, 20px down)"</span>)</span>
<span id="cb51-41"><a href="#cb51-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-42"><a href="#cb51-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Scaling</span></span>
<span id="cb51-43"><a href="#cb51-43" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> scale_image(image, scale):</span>
<span id="cb51-44"><a href="#cb51-44" aria-hidden="true" tabindex="-1"></a>    width <span class="op">=</span> <span class="bu">int</span>(image.shape[<span class="dv">1</span>] <span class="op">*</span> scale)</span>
<span id="cb51-45"><a href="#cb51-45" aria-hidden="true" tabindex="-1"></a>    height <span class="op">=</span> <span class="bu">int</span>(image.shape[<span class="dv">0</span>] <span class="op">*</span> scale)</span>
<span id="cb51-46"><a href="#cb51-46" aria-hidden="true" tabindex="-1"></a>    dim <span class="op">=</span> (width, height)</span>
<span id="cb51-47"><a href="#cb51-47" aria-hidden="true" tabindex="-1"></a>    scaled <span class="op">=</span> cv2.resize(image, dim, interpolation<span class="op">=</span>cv2.INTER_AREA)</span>
<span id="cb51-48"><a href="#cb51-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> scaled</span>
<span id="cb51-49"><a href="#cb51-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-50"><a href="#cb51-50" aria-hidden="true" tabindex="-1"></a>scaled_image <span class="op">=</span> scale_image(image, <span class="fl">0.8</span>)</span>
<span id="cb51-51"><a href="#cb51-51" aria-hidden="true" tabindex="-1"></a>display_image(scaled_image, <span class="st">"Scaled Image (0.8 times)"</span>)</span>
<span id="cb51-52"><a href="#cb51-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-53"><a href="#cb51-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Flipping</span></span>
<span id="cb51-54"><a href="#cb51-54" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> flip_image(image, direction):</span>
<span id="cb51-55"><a href="#cb51-55" aria-hidden="true" tabindex="-1"></a>    flipped <span class="op">=</span> cv2.flip(image, direction)</span>
<span id="cb51-56"><a href="#cb51-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> flipped</span>
<span id="cb51-57"><a href="#cb51-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-58"><a href="#cb51-58" aria-hidden="true" tabindex="-1"></a>flipped_image <span class="op">=</span> flip_image(image, <span class="dv">1</span>)</span>
<span id="cb51-59"><a href="#cb51-59" aria-hidden="true" tabindex="-1"></a>display_image(flipped_image, <span class="st">"Horizontally Flipped Image"</span>)</span>
<span id="cb51-60"><a href="#cb51-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-61"><a href="#cb51-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Cropping</span></span>
<span id="cb51-62"><a href="#cb51-62" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> crop_image(image, start_x, start_y, width, height):</span>
<span id="cb51-63"><a href="#cb51-63" aria-hidden="true" tabindex="-1"></a>    cropped <span class="op">=</span> image[start_y:start_y <span class="op">+</span> height, start_x:start_x <span class="op">+</span> width]</span>
<span id="cb51-64"><a href="#cb51-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cropped</span>
<span id="cb51-65"><a href="#cb51-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-66"><a href="#cb51-66" aria-hidden="true" tabindex="-1"></a>cropped_image <span class="op">=</span> crop_image(image, <span class="dv">50</span>, <span class="dv">50</span>, <span class="dv">200</span>, <span class="dv">200</span>)</span>
<span id="cb51-67"><a href="#cb51-67" aria-hidden="true" tabindex="-1"></a>display_image(cropped_image, <span class="st">"Cropped Image (central 50%)"</span>)</span>
<span id="cb51-68"><a href="#cb51-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-69"><a href="#cb51-69" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.5.1.2 Color Space Augmentations</span></span>
<span id="cb51-70"><a href="#cb51-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-71"><a href="#cb51-71" aria-hidden="true" tabindex="-1"></a><span class="co"># Brightness Adjustment</span></span>
<span id="cb51-72"><a href="#cb51-72" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> adjust_brightness(image, factor):</span>
<span id="cb51-73"><a href="#cb51-73" aria-hidden="true" tabindex="-1"></a>    pil_image <span class="op">=</span> Image.fromarray(image)</span>
<span id="cb51-74"><a href="#cb51-74" aria-hidden="true" tabindex="-1"></a>    enhancer <span class="op">=</span> ImageEnhance.Brightness(pil_image)</span>
<span id="cb51-75"><a href="#cb51-75" aria-hidden="true" tabindex="-1"></a>    brightened <span class="op">=</span> enhancer.enhance(factor)</span>
<span id="cb51-76"><a href="#cb51-76" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(brightened)</span>
<span id="cb51-77"><a href="#cb51-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-78"><a href="#cb51-78" aria-hidden="true" tabindex="-1"></a>brightened_image <span class="op">=</span> adjust_brightness(image, <span class="fl">1.2</span>)</span>
<span id="cb51-79"><a href="#cb51-79" aria-hidden="true" tabindex="-1"></a>display_image(brightened_image, <span class="st">"Brightness Adjusted Image (1.2 times)"</span>)</span>
<span id="cb51-80"><a href="#cb51-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-81"><a href="#cb51-81" aria-hidden="true" tabindex="-1"></a><span class="co"># Contrast Adjustment</span></span>
<span id="cb51-82"><a href="#cb51-82" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> adjust_contrast(image, factor):</span>
<span id="cb51-83"><a href="#cb51-83" aria-hidden="true" tabindex="-1"></a>    pil_image <span class="op">=</span> Image.fromarray(image)</span>
<span id="cb51-84"><a href="#cb51-84" aria-hidden="true" tabindex="-1"></a>    enhancer <span class="op">=</span> ImageEnhance.Contrast(pil_image)</span>
<span id="cb51-85"><a href="#cb51-85" aria-hidden="true" tabindex="-1"></a>    contrasted <span class="op">=</span> enhancer.enhance(factor)</span>
<span id="cb51-86"><a href="#cb51-86" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(contrasted)</span>
<span id="cb51-87"><a href="#cb51-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-88"><a href="#cb51-88" aria-hidden="true" tabindex="-1"></a>contrasted_image <span class="op">=</span> adjust_contrast(image, <span class="fl">0.7</span>)</span>
<span id="cb51-89"><a href="#cb51-89" aria-hidden="true" tabindex="-1"></a>display_image(contrasted_image, <span class="st">"Contrast Adjusted Image (0.7 times)"</span>)</span>
<span id="cb51-90"><a href="#cb51-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-91"><a href="#cb51-91" aria-hidden="true" tabindex="-1"></a><span class="co"># Saturation Adjustment</span></span>
<span id="cb51-92"><a href="#cb51-92" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> adjust_saturation(image, factor):</span>
<span id="cb51-93"><a href="#cb51-93" aria-hidden="true" tabindex="-1"></a>    pil_image <span class="op">=</span> Image.fromarray(image)</span>
<span id="cb51-94"><a href="#cb51-94" aria-hidden="true" tabindex="-1"></a>    enhancer <span class="op">=</span> ImageEnhance.Color(pil_image)</span>
<span id="cb51-95"><a href="#cb51-95" aria-hidden="true" tabindex="-1"></a>    saturated <span class="op">=</span> enhancer.enhance(factor)</span>
<span id="cb51-96"><a href="#cb51-96" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(saturated)</span>
<span id="cb51-97"><a href="#cb51-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-98"><a href="#cb51-98" aria-hidden="true" tabindex="-1"></a>saturated_image <span class="op">=</span> adjust_saturation(image, <span class="fl">1.5</span>)</span>
<span id="cb51-99"><a href="#cb51-99" aria-hidden="true" tabindex="-1"></a>display_image(saturated_image, <span class="st">"Saturation Adjusted Image (1.5 times)"</span>)</span>
<span id="cb51-100"><a href="#cb51-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-101"><a href="#cb51-101" aria-hidden="true" tabindex="-1"></a><span class="co"># Hue Adjustment</span></span>
<span id="cb51-102"><a href="#cb51-102" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> adjust_hue(image, shift):</span>
<span id="cb51-103"><a href="#cb51-103" aria-hidden="true" tabindex="-1"></a>    hsv_image <span class="op">=</span> cv2.cvtColor(image, cv2.COLOR_RGB2HSV)</span>
<span id="cb51-104"><a href="#cb51-104" aria-hidden="true" tabindex="-1"></a>    hsv_image[:, :, <span class="dv">0</span>] <span class="op">=</span> (hsv_image[:, :, <span class="dv">0</span>] <span class="op">+</span> shift) <span class="op">%</span> <span class="dv">180</span></span>
<span id="cb51-105"><a href="#cb51-105" aria-hidden="true" tabindex="-1"></a>    hue_adjusted <span class="op">=</span> cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)</span>
<span id="cb51-106"><a href="#cb51-106" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> hue_adjusted</span>
<span id="cb51-107"><a href="#cb51-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-108"><a href="#cb51-108" aria-hidden="true" tabindex="-1"></a>hue_adjusted_image <span class="op">=</span> adjust_hue(image, <span class="dv">15</span>)</span>
<span id="cb51-109"><a href="#cb51-109" aria-hidden="true" tabindex="-1"></a>display_image(hue_adjusted_image, <span class="st">"Hue Adjusted Image (15 degrees)"</span>)</span>
<span id="cb51-110"><a href="#cb51-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-111"><a href="#cb51-111" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.5.1.3 Mixing Images</span></span>
<span id="cb51-112"><a href="#cb51-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-113"><a href="#cb51-113" aria-hidden="true" tabindex="-1"></a><span class="co"># Image Blending</span></span>
<span id="cb51-114"><a href="#cb51-114" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> blend_images(image1, image2, alpha):</span>
<span id="cb51-115"><a href="#cb51-115" aria-hidden="true" tabindex="-1"></a>    blended <span class="op">=</span> cv2.addWeighted(image1, alpha, image2, <span class="dv">1</span> <span class="op">-</span> alpha, <span class="dv">0</span>)</span>
<span id="cb51-116"><a href="#cb51-116" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> blended</span>
<span id="cb51-117"><a href="#cb51-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-118"><a href="#cb51-118" aria-hidden="true" tabindex="-1"></a><span class="co"># Load another sample image</span></span>
<span id="cb51-119"><a href="#cb51-119" aria-hidden="true" tabindex="-1"></a>image_path2 <span class="op">=</span> <span class="st">'../../../test_image.jpg'</span></span>
<span id="cb51-120"><a href="#cb51-120" aria-hidden="true" tabindex="-1"></a>image2 <span class="op">=</span> cv2.imread(image_path2)</span>
<span id="cb51-121"><a href="#cb51-121" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> image2 <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb51-122"><a href="#cb51-122" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">FileNotFoundError</span>(<span class="ss">f"Image file '</span><span class="sc">{</span>image_path2<span class="sc">}</span><span class="ss">' not found."</span>)</span>
<span id="cb51-123"><a href="#cb51-123" aria-hidden="true" tabindex="-1"></a>image2 <span class="op">=</span> cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)</span>
<span id="cb51-124"><a href="#cb51-124" aria-hidden="true" tabindex="-1"></a>image2 <span class="op">=</span> cv2.resize(image2, (image.shape[<span class="dv">1</span>], image.shape[<span class="dv">0</span>]))</span>
<span id="cb51-125"><a href="#cb51-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-126"><a href="#cb51-126" aria-hidden="true" tabindex="-1"></a>blended_image <span class="op">=</span> blend_images(image, image2, <span class="fl">0.5</span>)</span>
<span id="cb51-127"><a href="#cb51-127" aria-hidden="true" tabindex="-1"></a>display_image(blended_image, <span class="st">"Blended Image (50:50)"</span>)</span>
<span id="cb51-128"><a href="#cb51-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-129"><a href="#cb51-129" aria-hidden="true" tabindex="-1"></a><span class="co"># CutMix</span></span>
<span id="cb51-130"><a href="#cb51-130" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cutmix(image1, image2):</span>
<span id="cb51-131"><a href="#cb51-131" aria-hidden="true" tabindex="-1"></a>    height, width <span class="op">=</span> image1.shape[:<span class="dv">2</span>]</span>
<span id="cb51-132"><a href="#cb51-132" aria-hidden="true" tabindex="-1"></a>    cut_x <span class="op">=</span> np.random.randint(width <span class="op">//</span> <span class="dv">2</span>)</span>
<span id="cb51-133"><a href="#cb51-133" aria-hidden="true" tabindex="-1"></a>    cut_y <span class="op">=</span> np.random.randint(height <span class="op">//</span> <span class="dv">2</span>)</span>
<span id="cb51-134"><a href="#cb51-134" aria-hidden="true" tabindex="-1"></a>    cut_image <span class="op">=</span> image1.copy()</span>
<span id="cb51-135"><a href="#cb51-135" aria-hidden="true" tabindex="-1"></a>    cut_image[cut_y:, cut_x:] <span class="op">=</span> image2[cut_y:, cut_x:]</span>
<span id="cb51-136"><a href="#cb51-136" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cut_image</span>
<span id="cb51-137"><a href="#cb51-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-138"><a href="#cb51-138" aria-hidden="true" tabindex="-1"></a>cutmix_image <span class="op">=</span> cutmix(image, image2)</span>
<span id="cb51-139"><a href="#cb51-139" aria-hidden="true" tabindex="-1"></a>display_image(cutmix_image, <span class="st">"CutMix Image"</span>)</span>
<span id="cb51-140"><a href="#cb51-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-141"><a href="#cb51-141" aria-hidden="true" tabindex="-1"></a><span class="co"># MixUp</span></span>
<span id="cb51-142"><a href="#cb51-142" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mixup(image1, image2, alpha):</span>
<span id="cb51-143"><a href="#cb51-143" aria-hidden="true" tabindex="-1"></a>    mixed <span class="op">=</span> image1 <span class="op">*</span> alpha <span class="op">+</span> image2 <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> alpha)</span>
<span id="cb51-144"><a href="#cb51-144" aria-hidden="true" tabindex="-1"></a>    mixed <span class="op">=</span> mixed.astype(np.uint8)</span>
<span id="cb51-145"><a href="#cb51-145" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mixed</span>
<span id="cb51-146"><a href="#cb51-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-147"><a href="#cb51-147" aria-hidden="true" tabindex="-1"></a>mixup_image <span class="op">=</span> mixup(image, image2, <span class="fl">0.7</span>)</span>
<span id="cb51-148"><a href="#cb51-148" aria-hidden="true" tabindex="-1"></a>display_image(mixup_image, <span class="st">"MixUp Image (70:30)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-21-output-1.png" width="389" height="409" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-21-output-2.png" width="389" height="409" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-21-output-3.png" width="389" height="409" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-21-output-4.png" width="389" height="409" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-21-output-5.png" width="389" height="409" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-21-output-6.png" width="389" height="409" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-21-output-7.png" width="389" height="409" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-21-output-8.png" width="389" height="409" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-21-output-9.png" width="389" height="409" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-21-output-10.png" width="389" height="409" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-21-output-11.png" width="389" height="409" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-21-output-12.png" width="389" height="409" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="text-augmentation" class="level2">
<h2 class="anchored" data-anchor-id="text-augmentation">2.5.2 Text Augmentation</h2>
<section id="synonym-replacement" class="level4">
<h4 class="anchored" data-anchor-id="synonym-replacement">2.5.2.1 Synonym Replacement</h4>
<p>Synonym replacement involves replacing words in the text with their synonyms. This technique helps in generating diverse textual data while maintaining the original meaning. Example: Replacing “happy” with “joyful” in the sentence “The child was happy.”</p>
</section>
<section id="back-translation" class="level4">
<h4 class="anchored" data-anchor-id="back-translation">2.5.2.2 Back-translation</h4>
<p>Back-translation involves translating text to another language and then back to the original language. This process generates paraphrased versions of the original text, enhancing textual diversity. Example: Translating “The weather is nice today” to French and back to English might yield “The weather is pleasant today.”</p>
</section>
<section id="text-generation-with-language-models" class="level4">
<h4 class="anchored" data-anchor-id="text-generation-with-language-models">2.5.2.3 Text Generation with Language Models</h4>
<p>Text generation with language models uses pre-trained language models to generate new text data. Techniques include:</p>
<ul>
<li><p><strong>GPT-3:</strong> Using Generative Pre-trained Transformer models to create synthetic text data. Example: Generating new product reviews based on existing ones.</p></li>
<li><p><strong>BERT-based Augmentation:</strong> Using BERT models to replace words or phrases with contextually similar alternatives. Example: Replacing “He is going to school” with “He is heading to school.”</p></li>
</ul>
<div id="d0fbc53f" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> wordnet</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> deep_translator <span class="im">import</span> GoogleTranslator</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> markovify</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure necessary resources are downloaded</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'wordnet'</span>)</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'omw-1.4'</span>)</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample text</span></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"The child was happy because the weather is nice today."</span></span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.5.2.1 Synonym Replacement</span></span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> synonym_replacement(text):</span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> text.split()</span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a>    new_words <span class="op">=</span> words.copy()</span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a>    random_word_list <span class="op">=</span> <span class="bu">list</span>(<span class="bu">set</span>([word <span class="cf">for</span> word <span class="kw">in</span> words <span class="cf">if</span> wordnet.synsets(word)]))</span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> random_word_list:</span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> text</span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a>    random_word <span class="op">=</span> random.choice(random_word_list)</span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a>    synonyms <span class="op">=</span> wordnet.synsets(random_word)[<span class="dv">0</span>].lemma_names()</span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a>    synonym <span class="op">=</span> random.choice(synonyms)</span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a>    new_text <span class="op">=</span> text.replace(random_word, synonym, <span class="dv">1</span>)</span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> new_text</span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-27"><a href="#cb52-27" aria-hidden="true" tabindex="-1"></a>synonym_replaced_text <span class="op">=</span> synonym_replacement(text)</span>
<span id="cb52-28"><a href="#cb52-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original Text:</span><span class="ch">\n</span><span class="st">"</span>, text)</span>
<span id="cb52-29"><a href="#cb52-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Synonym Replaced Text:</span><span class="ch">\n</span><span class="st">"</span>, synonym_replaced_text)</span>
<span id="cb52-30"><a href="#cb52-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-31"><a href="#cb52-31" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.5.2.2 Back-translation</span></span>
<span id="cb52-32"><a href="#cb52-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> back_translation(text, src_lang<span class="op">=</span><span class="st">'en'</span>, mid_lang<span class="op">=</span><span class="st">'fr'</span>):</span>
<span id="cb52-33"><a href="#cb52-33" aria-hidden="true" tabindex="-1"></a>    translated <span class="op">=</span> GoogleTranslator(source<span class="op">=</span>src_lang, target<span class="op">=</span>mid_lang).translate(text)</span>
<span id="cb52-34"><a href="#cb52-34" aria-hidden="true" tabindex="-1"></a>    back_translated <span class="op">=</span> GoogleTranslator(source<span class="op">=</span>mid_lang, target<span class="op">=</span>src_lang).translate(translated)</span>
<span id="cb52-35"><a href="#cb52-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> back_translated</span>
<span id="cb52-36"><a href="#cb52-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-37"><a href="#cb52-37" aria-hidden="true" tabindex="-1"></a>back_translated_text <span class="op">=</span> back_translation(text)</span>
<span id="cb52-38"><a href="#cb52-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Back-translated Text:</span><span class="ch">\n</span><span class="st">"</span>, back_translated_text)</span>
<span id="cb52-39"><a href="#cb52-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-40"><a href="#cb52-40" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.5.2.3 Text Generation with Markov Chains</span></span>
<span id="cb52-41"><a href="#cb52-41" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MarkovTextGenerator:</span>
<span id="cb52-42"><a href="#cb52-42" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, text):</span>
<span id="cb52-43"><a href="#cb52-43" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_model <span class="op">=</span> markovify.Text(text)</span>
<span id="cb52-44"><a href="#cb52-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-45"><a href="#cb52-45" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate_text(<span class="va">self</span>, size<span class="op">=</span><span class="dv">50</span>):</span>
<span id="cb52-46"><a href="#cb52-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.text_model.make_short_sentence(size)</span>
<span id="cb52-47"><a href="#cb52-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-48"><a href="#cb52-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Example text for training Markov model</span></span>
<span id="cb52-49"><a href="#cb52-49" aria-hidden="true" tabindex="-1"></a>training_text <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb52-50"><a href="#cb52-50" aria-hidden="true" tabindex="-1"></a><span class="st">The child was happy because the weather is nice today.</span></span>
<span id="cb52-51"><a href="#cb52-51" aria-hidden="true" tabindex="-1"></a><span class="st">She enjoyed playing in the park with her friends.</span></span>
<span id="cb52-52"><a href="#cb52-52" aria-hidden="true" tabindex="-1"></a><span class="st">It was a beautiful day with clear skies.</span></span>
<span id="cb52-53"><a href="#cb52-53" aria-hidden="true" tabindex="-1"></a><span class="st">Everyone had a great time and felt very joyful.</span></span>
<span id="cb52-54"><a href="#cb52-54" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb52-55"><a href="#cb52-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-56"><a href="#cb52-56" aria-hidden="true" tabindex="-1"></a>markov_generator <span class="op">=</span> MarkovTextGenerator(training_text)</span>
<span id="cb52-57"><a href="#cb52-57" aria-hidden="true" tabindex="-1"></a>generated_text <span class="op">=</span> markov_generator.generate_text()</span>
<span id="cb52-58"><a href="#cb52-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Markov Chain Generated Text:</span><span class="ch">\n</span><span class="st">"</span>, generated_text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package wordnet to
[nltk_data]     /Users/ravishankar/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
[nltk_data] Downloading package omw-1.4 to
[nltk_data]     /Users/ravishankar/nltk_data...
[nltk_data]   Package omw-1.4 is already up-to-date!</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Original Text:
 The child was happy because the weather is nice today.
Synonym Replaced Text:
 The fry was happy because the weather is nice today.
Back-translated Text:
 The child was happy because the weather was nice today.
Markov Chain Generated Text:
 None</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="time-series-augmentation" class="level2">
<h2 class="anchored" data-anchor-id="time-series-augmentation">2.5.3 Time Series Augmentation</h2>
<section id="time-warping" class="level4">
<h4 class="anchored" data-anchor-id="time-warping">2.5.3.1 Time Warping</h4>
<p>Time warping involves stretching or compressing the time series data along the time axis. This technique helps in creating variations in the temporal patterns of the data. Example: Stretching a time series of stock prices to create a slower variation pattern.</p>
</section>
<section id="magnitude-warping" class="level4">
<h4 class="anchored" data-anchor-id="magnitude-warping">2.5.3.2 Magnitude Warping</h4>
<p>Magnitude warping modifies the amplitude of time series data. This technique involves stretching or compressing the data along the magnitude axis, creating variations in the amplitude patterns. Example: Increasing the amplitude of an electrocardiogram (ECG) signal to simulate higher heartbeats.</p>
</section>
<section id="frequency-warping" class="level4">
<h4 class="anchored" data-anchor-id="frequency-warping">2.5.3.3 Frequency Warping</h4>
<p>Frequency warping alters the frequency components of time series data. This technique involves modifying the frequency domain representation of the data to create new variations. Example: Changing the frequency of a time series of temperature readings to simulate different seasonal patterns.</p>
<p>Advanced considerations in data augmentation techniques include:</p>
<ul>
<li><p>Ensuring the augmented data retains the original characteristics and labels.</p></li>
<li><p>Combining multiple augmentation techniques for better performance.</p></li>
<li><p>Evaluating the impact of augmented data on model generalizability and robustness.</p></li>
</ul>
<div id="96024eb6" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.interpolate <span class="im">import</span> interp1d</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.fft <span class="im">import</span> fft, ifft</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a sample time series</span></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>time <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">500</span>)</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.sin(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> <span class="dv">5</span> <span class="op">*</span> time) <span class="op">+</span> np.random.normal(<span class="dv">0</span>, <span class="fl">0.1</span>, <span class="dv">500</span>)</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the original time series</span></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>plt.plot(time, data, label<span class="op">=</span><span class="st">'Original'</span>)</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Original Time Series'</span>)</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.5.3.1 Time Warping</span></span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> time_warping(data, factor<span class="op">=</span><span class="fl">1.5</span>):</span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a>    original_indices <span class="op">=</span> np.arange(<span class="bu">len</span>(data))</span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a>    stretched_indices <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="bu">len</span>(data)<span class="op">-</span><span class="dv">1</span>, <span class="bu">int</span>(<span class="bu">len</span>(data) <span class="op">*</span> factor))</span>
<span id="cb55-19"><a href="#cb55-19" aria-hidden="true" tabindex="-1"></a>    interpolator <span class="op">=</span> interp1d(stretched_indices, np.interp(stretched_indices, original_indices, data), kind<span class="op">=</span><span class="st">'linear'</span>)</span>
<span id="cb55-20"><a href="#cb55-20" aria-hidden="true" tabindex="-1"></a>    warped_data <span class="op">=</span> interpolator(original_indices)</span>
<span id="cb55-21"><a href="#cb55-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> warped_data</span>
<span id="cb55-22"><a href="#cb55-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-23"><a href="#cb55-23" aria-hidden="true" tabindex="-1"></a>warped_data <span class="op">=</span> time_warping(data, factor<span class="op">=</span><span class="fl">1.2</span>)</span>
<span id="cb55-24"><a href="#cb55-24" aria-hidden="true" tabindex="-1"></a>plt.plot(time, data, label<span class="op">=</span><span class="st">'Original'</span>)</span>
<span id="cb55-25"><a href="#cb55-25" aria-hidden="true" tabindex="-1"></a>plt.plot(time, warped_data, label<span class="op">=</span><span class="st">'Time Warped'</span>)</span>
<span id="cb55-26"><a href="#cb55-26" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Time Warping'</span>)</span>
<span id="cb55-27"><a href="#cb55-27" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb55-28"><a href="#cb55-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb55-29"><a href="#cb55-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-30"><a href="#cb55-30" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.5.3.2 Magnitude Warping</span></span>
<span id="cb55-31"><a href="#cb55-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> magnitude_warping(data, factor<span class="op">=</span><span class="fl">1.2</span>):</span>
<span id="cb55-32"><a href="#cb55-32" aria-hidden="true" tabindex="-1"></a>    warped_data <span class="op">=</span> data <span class="op">*</span> factor</span>
<span id="cb55-33"><a href="#cb55-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> warped_data</span>
<span id="cb55-34"><a href="#cb55-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-35"><a href="#cb55-35" aria-hidden="true" tabindex="-1"></a>magnitude_warped_data <span class="op">=</span> magnitude_warping(data, factor<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb55-36"><a href="#cb55-36" aria-hidden="true" tabindex="-1"></a>plt.plot(time, data, label<span class="op">=</span><span class="st">'Original'</span>)</span>
<span id="cb55-37"><a href="#cb55-37" aria-hidden="true" tabindex="-1"></a>plt.plot(time, magnitude_warped_data, label<span class="op">=</span><span class="st">'Magnitude Warped'</span>)</span>
<span id="cb55-38"><a href="#cb55-38" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Magnitude Warping'</span>)</span>
<span id="cb55-39"><a href="#cb55-39" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb55-40"><a href="#cb55-40" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb55-41"><a href="#cb55-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-42"><a href="#cb55-42" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.5.3.3 Frequency Warping</span></span>
<span id="cb55-43"><a href="#cb55-43" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> frequency_warping(data, factor<span class="op">=</span><span class="fl">1.2</span>):</span>
<span id="cb55-44"><a href="#cb55-44" aria-hidden="true" tabindex="-1"></a>    transformed_data <span class="op">=</span> fft(data)</span>
<span id="cb55-45"><a href="#cb55-45" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(transformed_data)</span>
<span id="cb55-46"><a href="#cb55-46" aria-hidden="true" tabindex="-1"></a>    frequencies <span class="op">=</span> np.fft.fftfreq(n)</span>
<span id="cb55-47"><a href="#cb55-47" aria-hidden="true" tabindex="-1"></a>    warped_frequencies <span class="op">=</span> frequencies <span class="op">*</span> factor</span>
<span id="cb55-48"><a href="#cb55-48" aria-hidden="true" tabindex="-1"></a>    warped_transformed_data <span class="op">=</span> np.interp(warped_frequencies, frequencies, transformed_data, period<span class="op">=</span>n)</span>
<span id="cb55-49"><a href="#cb55-49" aria-hidden="true" tabindex="-1"></a>    warped_data <span class="op">=</span> ifft(warped_transformed_data).real</span>
<span id="cb55-50"><a href="#cb55-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> warped_data</span>
<span id="cb55-51"><a href="#cb55-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-52"><a href="#cb55-52" aria-hidden="true" tabindex="-1"></a>frequency_warped_data <span class="op">=</span> frequency_warping(data, factor<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb55-53"><a href="#cb55-53" aria-hidden="true" tabindex="-1"></a>plt.plot(time, data, label<span class="op">=</span><span class="st">'Original'</span>)</span>
<span id="cb55-54"><a href="#cb55-54" aria-hidden="true" tabindex="-1"></a>plt.plot(time, frequency_warped_data, label<span class="op">=</span><span class="st">'Frequency Warped'</span>)</span>
<span id="cb55-55"><a href="#cb55-55" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Frequency Warping'</span>)</span>
<span id="cb55-56"><a href="#cb55-56" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb55-57"><a href="#cb55-57" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb55-58"><a href="#cb55-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-59"><a href="#cb55-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced considerations: Combining techniques</span></span>
<span id="cb55-60"><a href="#cb55-60" aria-hidden="true" tabindex="-1"></a>combined_warped_data <span class="op">=</span> magnitude_warping(time_warping(data, factor<span class="op">=</span><span class="fl">1.2</span>), factor<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb55-61"><a href="#cb55-61" aria-hidden="true" tabindex="-1"></a>plt.plot(time, data, label<span class="op">=</span><span class="st">'Original'</span>)</span>
<span id="cb55-62"><a href="#cb55-62" aria-hidden="true" tabindex="-1"></a>plt.plot(time, combined_warped_data, label<span class="op">=</span><span class="st">'Combined Warping'</span>)</span>
<span id="cb55-63"><a href="#cb55-63" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Combined Warping Techniques'</span>)</span>
<span id="cb55-64"><a href="#cb55-64" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb55-65"><a href="#cb55-65" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-23-output-1.png" width="582" height="431" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-23-output-2.png" width="582" height="431" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-23-output-3.png" width="582" height="431" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-23-output-4.png" width="582" height="431" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-23-output-5.png" width="582" height="431" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<hr>
</section>
</section>
</section>
<section id="handling-time-dependent-data" class="level1">
<h1>2.6 Handling Time-dependent Data</h1>
<p>Handling time-dependent data involves techniques that account for the temporal order and dependencies in the data. These methods ensure that models capture the sequential nature of time series data effectively. Below is a detailed guide from basic to advanced techniques.</p>
<section id="time-based-splitting" class="level2">
<h2 class="anchored" data-anchor-id="time-based-splitting">2.6.1 Time-based Splitting</h2>
<p>Time-based splitting involves dividing the dataset into training and testing sets based on time. This method ensures that future data is not used to predict past events, maintaining the temporal sequence.</p>
<section id="example" class="level4">
<h4 class="anchored" data-anchor-id="example">Example:</h4>
<ul>
<li><p>Training set: Data from January to September.</p></li>
<li><p>Testing set: Data from October to December.</p></li>
</ul>
</section>
<section id="advanced-considerations" class="level4">
<h4 class="anchored" data-anchor-id="advanced-considerations">Advanced Considerations:</h4>
<ul>
<li><p><strong>Validation:</strong> Use techniques like time series cross-validation where the model is validated on a rolling basis.</p></li>
<li><p><strong>Concept Drift:</strong> Monitor for changes in the underlying data distribution over time, which can impact model performance.</p></li>
</ul>
</section>
</section>
<section id="lag-features" class="level2">
<h2 class="anchored" data-anchor-id="lag-features">2.6.2 Lag Features</h2>
<p>Lag features use previous time steps as features to predict the current or future time steps. This technique helps capture temporal dependencies in the data.</p>
<section id="example-1" class="level4">
<h4 class="anchored" data-anchor-id="example-1">Example:</h4>
<ul>
<li>Predicting today’s sales using sales from the past 7 days.</li>
</ul>
</section>
<section id="advanced-considerations-1" class="level4">
<h4 class="anchored" data-anchor-id="advanced-considerations-1">Advanced Considerations:</h4>
<ul>
<li><p><strong>Multiple Lags:</strong> Use multiple lag features (e.g., sales from the past day, week, month) to capture different temporal patterns.</p></li>
<li><p><strong>Lag Interactions:</strong> Consider interactions between lag features to capture more complex temporal relationships.</p></li>
</ul>
</section>
</section>
<section id="rolling-statistics" class="level2">
<h2 class="anchored" data-anchor-id="rolling-statistics">2.6.3 Rolling Statistics</h2>
<p>Rolling statistics compute statistical measures over a moving window, capturing trends and patterns over time. Common rolling statistics include mean, standard deviation, and sum.</p>
<section id="example-2" class="level4">
<h4 class="anchored" data-anchor-id="example-2">Example:</h4>
<ul>
<li>Calculating the rolling average temperature over the past 7 days to smooth out daily fluctuations.</li>
</ul>
</section>
<section id="advanced-considerations-2" class="level4">
<h4 class="anchored" data-anchor-id="advanced-considerations-2">Advanced Considerations:</h4>
<ul>
<li><p><strong>Window Size:</strong> Choose appropriate window sizes based on the data’s periodicity and seasonality.</p></li>
<li><p><strong>Multiple Statistics:</strong> Use a combination of rolling statistics (e.g., rolling mean, rolling variance) to capture different aspects of the data’s temporal dynamics.</p></li>
</ul>
<p>Advanced considerations in handling time-dependent data include: - <strong>Temporal Consistency:</strong> Ensure that features and labels maintain temporal consistency, avoiding data leakage.</p>
<ul>
<li><p><strong>Feature Engineering:</strong> Combine multiple temporal features such as lags, rolling statistics, and date-based features (e.g., day of week, month) for better model performance.</p></li>
<li><p><strong>Model Evaluation:</strong> Use time-aware validation techniques like walk-forward validation to assess model performance on unseen data.</p></li>
</ul>
<div id="036a158c" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> TimeSeriesSplit</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a sample time series dataset</span></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>date_range <span class="op">=</span> pd.date_range(start<span class="op">=</span><span class="st">'2022-01-01'</span>, periods<span class="op">=</span><span class="dv">365</span>, freq<span class="op">=</span><span class="st">'D'</span>)</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame({<span class="st">'date'</span>: date_range, <span class="st">'value'</span>: np.random.randn(<span class="dv">365</span>).cumsum()})</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.6.1 Time-based Splitting</span></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Split data into training and testing sets based on time</span></span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> data[data[<span class="st">'date'</span>] <span class="op">&lt;</span> <span class="st">'2022-10-01'</span>]</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> data[data[<span class="st">'date'</span>] <span class="op">&gt;=</span> <span class="st">'2022-10-01'</span>]</span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training set:</span><span class="ch">\n</span><span class="st">"</span>, train_data.head())</span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testing set:</span><span class="ch">\n</span><span class="st">"</span>, test_data.head())</span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations: Time Series Cross-Validation</span></span>
<span id="cb56-20"><a href="#cb56-20" aria-hidden="true" tabindex="-1"></a>tscv <span class="op">=</span> TimeSeriesSplit(n_splits<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb56-21"><a href="#cb56-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> train_index, test_index <span class="kw">in</span> tscv.split(data):</span>
<span id="cb56-22"><a href="#cb56-22" aria-hidden="true" tabindex="-1"></a>    train, test <span class="op">=</span> data.iloc[train_index], data.iloc[test_index]</span>
<span id="cb56-23"><a href="#cb56-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"TRAIN: </span><span class="sc">{</span>train[<span class="st">'date'</span>]<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss"> to </span><span class="sc">{</span>train[<span class="st">'date'</span>]<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">, TEST: </span><span class="sc">{</span>test[<span class="st">'date'</span>]<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss"> to </span><span class="sc">{</span>test[<span class="st">'date'</span>]<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb56-24"><a href="#cb56-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-25"><a href="#cb56-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.6.2 Lag Features</span></span>
<span id="cb56-26"><a href="#cb56-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-27"><a href="#cb56-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Create lag features</span></span>
<span id="cb56-28"><a href="#cb56-28" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'lag_1'</span>] <span class="op">=</span> data[<span class="st">'value'</span>].shift(<span class="dv">1</span>)</span>
<span id="cb56-29"><a href="#cb56-29" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'lag_7'</span>] <span class="op">=</span> data[<span class="st">'value'</span>].shift(<span class="dv">7</span>)</span>
<span id="cb56-30"><a href="#cb56-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Data with lag features:</span><span class="ch">\n</span><span class="st">"</span>, data.head(<span class="dv">10</span>))</span>
<span id="cb56-31"><a href="#cb56-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-32"><a href="#cb56-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations: Multiple Lags and Lag Interactions</span></span>
<span id="cb56-33"><a href="#cb56-33" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'lag_14'</span>] <span class="op">=</span> data[<span class="st">'value'</span>].shift(<span class="dv">14</span>)</span>
<span id="cb56-34"><a href="#cb56-34" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'lag_30'</span>] <span class="op">=</span> data[<span class="st">'value'</span>].shift(<span class="dv">30</span>)</span>
<span id="cb56-35"><a href="#cb56-35" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'lag_7_14'</span>] <span class="op">=</span> data[<span class="st">'lag_7'</span>] <span class="op">*</span> data[<span class="st">'lag_14'</span>]</span>
<span id="cb56-36"><a href="#cb56-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Data with multiple lags and interactions:</span><span class="ch">\n</span><span class="st">"</span>, data.head(<span class="dv">20</span>))</span>
<span id="cb56-37"><a href="#cb56-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-38"><a href="#cb56-38" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.6.3 Rolling Statistics</span></span>
<span id="cb56-39"><a href="#cb56-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-40"><a href="#cb56-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate rolling statistics</span></span>
<span id="cb56-41"><a href="#cb56-41" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'rolling_mean_7'</span>] <span class="op">=</span> data[<span class="st">'value'</span>].rolling(window<span class="op">=</span><span class="dv">7</span>).mean()</span>
<span id="cb56-42"><a href="#cb56-42" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'rolling_std_7'</span>] <span class="op">=</span> data[<span class="st">'value'</span>].rolling(window<span class="op">=</span><span class="dv">7</span>).std()</span>
<span id="cb56-43"><a href="#cb56-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Data with rolling statistics:</span><span class="ch">\n</span><span class="st">"</span>, data.head(<span class="dv">20</span>))</span>
<span id="cb56-44"><a href="#cb56-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-45"><a href="#cb56-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations: Window Size and Multiple Statistics</span></span>
<span id="cb56-46"><a href="#cb56-46" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'rolling_mean_30'</span>] <span class="op">=</span> data[<span class="st">'value'</span>].rolling(window<span class="op">=</span><span class="dv">30</span>).mean()</span>
<span id="cb56-47"><a href="#cb56-47" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'rolling_std_30'</span>] <span class="op">=</span> data[<span class="st">'value'</span>].rolling(window<span class="op">=</span><span class="dv">30</span>).std()</span>
<span id="cb56-48"><a href="#cb56-48" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'rolling_var_30'</span>] <span class="op">=</span> data[<span class="st">'value'</span>].rolling(window<span class="op">=</span><span class="dv">30</span>).var()</span>
<span id="cb56-49"><a href="#cb56-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Data with additional rolling statistics:</span><span class="ch">\n</span><span class="st">"</span>, data.head(<span class="dv">40</span>))</span>
<span id="cb56-50"><a href="#cb56-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-51"><a href="#cb56-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the time series data with rolling statistics</span></span>
<span id="cb56-52"><a href="#cb56-52" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">7</span>))</span>
<span id="cb56-53"><a href="#cb56-53" aria-hidden="true" tabindex="-1"></a>plt.plot(data[<span class="st">'date'</span>], data[<span class="st">'value'</span>], label<span class="op">=</span><span class="st">'Original'</span>)</span>
<span id="cb56-54"><a href="#cb56-54" aria-hidden="true" tabindex="-1"></a>plt.plot(data[<span class="st">'date'</span>], data[<span class="st">'rolling_mean_7'</span>], label<span class="op">=</span><span class="st">'7-day Rolling Mean'</span>)</span>
<span id="cb56-55"><a href="#cb56-55" aria-hidden="true" tabindex="-1"></a>plt.plot(data[<span class="st">'date'</span>], data[<span class="st">'rolling_mean_30'</span>], label<span class="op">=</span><span class="st">'30-day Rolling Mean'</span>)</span>
<span id="cb56-56"><a href="#cb56-56" aria-hidden="true" tabindex="-1"></a>plt.fill_between(data[<span class="st">'date'</span>], data[<span class="st">'rolling_mean_7'</span>] <span class="op">-</span> data[<span class="st">'rolling_std_7'</span>], data[<span class="st">'rolling_mean_7'</span>] <span class="op">+</span> data[<span class="st">'rolling_std_7'</span>], color<span class="op">=</span><span class="st">'b'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>, label<span class="op">=</span><span class="st">'7-day Rolling Std Dev'</span>)</span>
<span id="cb56-57"><a href="#cb56-57" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Time Series with Rolling Statistics'</span>)</span>
<span id="cb56-58"><a href="#cb56-58" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb56-59"><a href="#cb56-59" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb56-60"><a href="#cb56-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-61"><a href="#cb56-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations: Temporal Consistency and Feature Engineering</span></span>
<span id="cb56-62"><a href="#cb56-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-63"><a href="#cb56-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure temporal consistency by shifting the target variable for prediction</span></span>
<span id="cb56-64"><a href="#cb56-64" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'target'</span>] <span class="op">=</span> data[<span class="st">'value'</span>].shift(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb56-65"><a href="#cb56-65" aria-hidden="true" tabindex="-1"></a>data.dropna(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb56-66"><a href="#cb56-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-67"><a href="#cb56-67" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine multiple temporal features</span></span>
<span id="cb56-68"><a href="#cb56-68" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'day_of_week'</span>] <span class="op">=</span> data[<span class="st">'date'</span>].dt.dayofweek</span>
<span id="cb56-69"><a href="#cb56-69" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'month'</span>] <span class="op">=</span> data[<span class="st">'date'</span>].dt.month</span>
<span id="cb56-70"><a href="#cb56-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-71"><a href="#cb56-71" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Data with temporal features and target:</span><span class="ch">\n</span><span class="st">"</span>, data.head(<span class="dv">20</span>))</span>
<span id="cb56-72"><a href="#cb56-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-73"><a href="#cb56-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Model Evaluation: Walk-Forward Validation</span></span>
<span id="cb56-74"><a href="#cb56-74" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> walk_forward_validation(data, n_test):</span>
<span id="cb56-75"><a href="#cb56-75" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> []</span>
<span id="cb56-76"><a href="#cb56-76" aria-hidden="true" tabindex="-1"></a>    train, test <span class="op">=</span> data[:<span class="op">-</span>n_test], data[<span class="op">-</span>n_test:]</span>
<span id="cb56-77"><a href="#cb56-77" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test)):</span>
<span id="cb56-78"><a href="#cb56-78" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> train[<span class="st">'value'</span>].mean()</span>
<span id="cb56-79"><a href="#cb56-79" aria-hidden="true" tabindex="-1"></a>        predictions.append(model)</span>
<span id="cb56-80"><a href="#cb56-80" aria-hidden="true" tabindex="-1"></a>        train <span class="op">=</span> pd.concat([train, test.iloc[[i]]])</span>
<span id="cb56-81"><a href="#cb56-81" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> predictions</span>
<span id="cb56-82"><a href="#cb56-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-83"><a href="#cb56-83" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> walk_forward_validation(data, n_test<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb56-84"><a href="#cb56-84" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Walk-Forward Validation Predictions:</span><span class="ch">\n</span><span class="st">"</span>, predictions)</span>
<span id="cb56-85"><a href="#cb56-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-86"><a href="#cb56-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting predictions vs actual values</span></span>
<span id="cb56-87"><a href="#cb56-87" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">7</span>))</span>
<span id="cb56-88"><a href="#cb56-88" aria-hidden="true" tabindex="-1"></a>plt.plot(data[<span class="st">'date'</span>][<span class="op">-</span><span class="dv">30</span>:], data[<span class="st">'target'</span>][<span class="op">-</span><span class="dv">30</span>:], marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Actual'</span>)</span>
<span id="cb56-89"><a href="#cb56-89" aria-hidden="true" tabindex="-1"></a>plt.plot(data[<span class="st">'date'</span>][<span class="op">-</span><span class="dv">30</span>:], predictions, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Predicted'</span>)</span>
<span id="cb56-90"><a href="#cb56-90" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Walk-Forward Validation Predictions'</span>)</span>
<span id="cb56-91"><a href="#cb56-91" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb56-92"><a href="#cb56-92" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Training set:
         date     value
0 2022-01-01  0.136943
1 2022-01-02 -2.131859
2 2022-01-03 -1.450331
3 2022-01-04 -3.087483
4 2022-01-05 -3.765088
Testing set:
           date     value
273 2022-10-01 -1.579901
274 2022-10-02 -0.147195
275 2022-10-03  0.144687
276 2022-10-04 -0.144333
277 2022-10-05  1.488064
TRAIN: 2022-01-01 00:00:00 to 2022-03-06 00:00:00, TEST: 2022-03-07 00:00:00 to 2022-05-05 00:00:00
TRAIN: 2022-01-01 00:00:00 to 2022-05-05 00:00:00, TEST: 2022-05-06 00:00:00 to 2022-07-04 00:00:00
TRAIN: 2022-01-01 00:00:00 to 2022-07-04 00:00:00, TEST: 2022-07-05 00:00:00 to 2022-09-02 00:00:00
TRAIN: 2022-01-01 00:00:00 to 2022-09-02 00:00:00, TEST: 2022-09-03 00:00:00 to 2022-11-01 00:00:00
TRAIN: 2022-01-01 00:00:00 to 2022-11-01 00:00:00, TEST: 2022-11-02 00:00:00 to 2022-12-31 00:00:00
Data with lag features:
         date     value     lag_1     lag_7
0 2022-01-01  0.136943       NaN       NaN
1 2022-01-02 -2.131859  0.136943       NaN
2 2022-01-03 -1.450331 -2.131859       NaN
3 2022-01-04 -3.087483 -1.450331       NaN
4 2022-01-05 -3.765088 -3.087483       NaN
5 2022-01-06 -4.213348 -3.765088       NaN
6 2022-01-07 -3.757684 -4.213348       NaN
7 2022-01-08 -2.903886 -3.757684  0.136943
8 2022-01-09 -2.969773 -2.903886 -2.131859
9 2022-01-10 -1.851813 -2.969773 -1.450331
Data with multiple lags and interactions:
          date     value     lag_1     lag_7    lag_14  lag_30  lag_7_14
0  2022-01-01  0.136943       NaN       NaN       NaN     NaN       NaN
1  2022-01-02 -2.131859  0.136943       NaN       NaN     NaN       NaN
2  2022-01-03 -1.450331 -2.131859       NaN       NaN     NaN       NaN
3  2022-01-04 -3.087483 -1.450331       NaN       NaN     NaN       NaN
4  2022-01-05 -3.765088 -3.087483       NaN       NaN     NaN       NaN
5  2022-01-06 -4.213348 -3.765088       NaN       NaN     NaN       NaN
6  2022-01-07 -3.757684 -4.213348       NaN       NaN     NaN       NaN
7  2022-01-08 -2.903886 -3.757684  0.136943       NaN     NaN       NaN
8  2022-01-09 -2.969773 -2.903886 -2.131859       NaN     NaN       NaN
9  2022-01-10 -1.851813 -2.969773 -1.450331       NaN     NaN       NaN
10 2022-01-11 -0.413119 -1.851813 -3.087483       NaN     NaN       NaN
11 2022-01-12 -0.915897 -0.413119 -3.765088       NaN     NaN       NaN
12 2022-01-13  0.940638 -0.915897 -4.213348       NaN     NaN       NaN
13 2022-01-14  1.452559  0.940638 -3.757684       NaN     NaN       NaN
14 2022-01-15  0.221116  1.452559 -2.903886  0.136943     NaN -0.397666
15 2022-01-16  1.860105  0.221116 -2.969773 -2.131859     NaN  6.331139
16 2022-01-17  2.751978  1.860105 -1.851813 -1.450331     NaN  2.685742
17 2022-01-18  2.504453  2.751978 -0.413119 -3.087483     NaN  1.275498
18 2022-01-19  3.627959  2.504453 -0.915897 -3.765088     NaN  3.448431
19 2022-01-20  2.917816  3.627959  0.940638 -4.213348     NaN -3.963235
Data with rolling statistics:
          date     value     lag_1     lag_7    lag_14  lag_30  lag_7_14  \
0  2022-01-01  0.136943       NaN       NaN       NaN     NaN       NaN   
1  2022-01-02 -2.131859  0.136943       NaN       NaN     NaN       NaN   
2  2022-01-03 -1.450331 -2.131859       NaN       NaN     NaN       NaN   
3  2022-01-04 -3.087483 -1.450331       NaN       NaN     NaN       NaN   
4  2022-01-05 -3.765088 -3.087483       NaN       NaN     NaN       NaN   
5  2022-01-06 -4.213348 -3.765088       NaN       NaN     NaN       NaN   
6  2022-01-07 -3.757684 -4.213348       NaN       NaN     NaN       NaN   
7  2022-01-08 -2.903886 -3.757684  0.136943       NaN     NaN       NaN   
8  2022-01-09 -2.969773 -2.903886 -2.131859       NaN     NaN       NaN   
9  2022-01-10 -1.851813 -2.969773 -1.450331       NaN     NaN       NaN   
10 2022-01-11 -0.413119 -1.851813 -3.087483       NaN     NaN       NaN   
11 2022-01-12 -0.915897 -0.413119 -3.765088       NaN     NaN       NaN   
12 2022-01-13  0.940638 -0.915897 -4.213348       NaN     NaN       NaN   
13 2022-01-14  1.452559  0.940638 -3.757684       NaN     NaN       NaN   
14 2022-01-15  0.221116  1.452559 -2.903886  0.136943     NaN -0.397666   
15 2022-01-16  1.860105  0.221116 -2.969773 -2.131859     NaN  6.331139   
16 2022-01-17  2.751978  1.860105 -1.851813 -1.450331     NaN  2.685742   
17 2022-01-18  2.504453  2.751978 -0.413119 -3.087483     NaN  1.275498   
18 2022-01-19  3.627959  2.504453 -0.915897 -3.765088     NaN  3.448431   
19 2022-01-20  2.917816  3.627959  0.940638 -4.213348     NaN -3.963235   

    rolling_mean_7  rolling_std_7  
0              NaN            NaN  
1              NaN            NaN  
2              NaN            NaN  
3              NaN            NaN  
4              NaN            NaN  
5              NaN            NaN  
6        -2.609836       1.558272  
7        -3.044240       0.982343  
8        -3.163942       0.900259  
9        -3.221296       0.777280  
10       -2.839244       1.321060  
11       -2.432217       1.423235  
12       -1.695934       1.661451  
13       -0.951613       1.748648  
14       -0.505184       1.555391  
15        0.184798       1.335621  
16        0.842483       1.298594  
17        1.259279       1.296641  
18        1.908401       1.155956  
19        2.190855       1.121108  
Data with additional rolling statistics:
          date     value     lag_1     lag_7    lag_14    lag_30   lag_7_14  \
0  2022-01-01  0.136943       NaN       NaN       NaN       NaN        NaN   
1  2022-01-02 -2.131859  0.136943       NaN       NaN       NaN        NaN   
2  2022-01-03 -1.450331 -2.131859       NaN       NaN       NaN        NaN   
3  2022-01-04 -3.087483 -1.450331       NaN       NaN       NaN        NaN   
4  2022-01-05 -3.765088 -3.087483       NaN       NaN       NaN        NaN   
5  2022-01-06 -4.213348 -3.765088       NaN       NaN       NaN        NaN   
6  2022-01-07 -3.757684 -4.213348       NaN       NaN       NaN        NaN   
7  2022-01-08 -2.903886 -3.757684  0.136943       NaN       NaN        NaN   
8  2022-01-09 -2.969773 -2.903886 -2.131859       NaN       NaN        NaN   
9  2022-01-10 -1.851813 -2.969773 -1.450331       NaN       NaN        NaN   
10 2022-01-11 -0.413119 -1.851813 -3.087483       NaN       NaN        NaN   
11 2022-01-12 -0.915897 -0.413119 -3.765088       NaN       NaN        NaN   
12 2022-01-13  0.940638 -0.915897 -4.213348       NaN       NaN        NaN   
13 2022-01-14  1.452559  0.940638 -3.757684       NaN       NaN        NaN   
14 2022-01-15  0.221116  1.452559 -2.903886  0.136943       NaN  -0.397666   
15 2022-01-16  1.860105  0.221116 -2.969773 -2.131859       NaN   6.331139   
16 2022-01-17  2.751978  1.860105 -1.851813 -1.450331       NaN   2.685742   
17 2022-01-18  2.504453  2.751978 -0.413119 -3.087483       NaN   1.275498   
18 2022-01-19  3.627959  2.504453 -0.915897 -3.765088       NaN   3.448431   
19 2022-01-20  2.917816  3.627959  0.940638 -4.213348       NaN  -3.963235   
20 2022-01-21  3.896292  2.917816  1.452559 -3.757684       NaN  -5.458256   
21 2022-01-22  2.654345  3.896292  0.221116 -2.903886       NaN  -0.642096   
22 2022-01-23  2.469352  2.654345  1.860105 -2.969773       NaN  -5.524090   
23 2022-01-24  3.124253  2.469352  2.751978 -1.851813       NaN  -5.096151   
24 2022-01-25  3.960273  3.124253  2.504453 -0.413119       NaN  -1.034637   
25 2022-01-26  3.410910  3.960273  3.627959 -0.915897       NaN  -3.322836   
26 2022-01-27  3.631825  3.410910  2.917816  0.940638       NaN   2.744609   
27 2022-01-28  3.901459  3.631825  3.896292  1.452559       NaN   5.659592   
28 2022-01-29  2.822913  3.901459  2.654345  0.221116       NaN   0.586919   
29 2022-01-30  2.774746  2.822913  2.469352  1.860105       NaN   4.593253   
30 2022-01-31  3.208042  2.774746  3.124253  2.751978  0.136943   8.597877   
31 2022-02-01  0.744189  3.208042  3.960273  2.504453 -2.131859   9.918317   
32 2022-02-02  0.867866  0.744189  3.410910  3.627959 -1.450331  12.374644   
33 2022-02-03  0.357657  0.867866  3.631825  2.917816 -3.087483  10.596999   
34 2022-02-04  0.377616  0.357657  3.901459  3.896292 -3.765088  15.201224   
35 2022-02-05  1.926789  0.377616  2.822913  2.654345 -4.213348   7.492986   
36 2022-02-06  3.469605  1.926789  2.774746  2.469352 -3.757684   6.851824   
37 2022-02-07  1.908919  3.469605  3.208042  3.124253 -2.903886  10.022737   
38 2022-02-08  0.301179  1.908919  0.744189  3.960273 -2.969773   2.947193   
39 2022-02-09 -0.380758  0.301179  0.867866  3.410910 -1.851813   2.960214   

    rolling_mean_7  rolling_std_7  rolling_mean_30  rolling_std_30  \
0              NaN            NaN              NaN             NaN   
1              NaN            NaN              NaN             NaN   
2              NaN            NaN              NaN             NaN   
3              NaN            NaN              NaN             NaN   
4              NaN            NaN              NaN             NaN   
5              NaN            NaN              NaN             NaN   
6        -2.609836       1.558272              NaN             NaN   
7        -3.044240       0.982343              NaN             NaN   
8        -3.163942       0.900259              NaN             NaN   
9        -3.221296       0.777280              NaN             NaN   
10       -2.839244       1.321060              NaN             NaN   
11       -2.432217       1.423235              NaN             NaN   
12       -1.695934       1.661451              NaN             NaN   
13       -0.951613       1.748648              NaN             NaN   
14       -0.505184       1.555391              NaN             NaN   
15        0.184798       1.335621              NaN             NaN   
16        0.842483       1.298594              NaN             NaN   
17        1.259279       1.296641              NaN             NaN   
18        1.908401       1.155956              NaN             NaN   
19        2.190855       1.121108              NaN             NaN   
20        2.539960       1.228251              NaN             NaN   
21        2.887564       0.688217              NaN             NaN   
22        2.974599       0.563923              NaN             NaN   
23        3.027782       0.556940              NaN             NaN   
24        3.235756       0.599164              NaN             NaN   
25        3.204749       0.580820              NaN             NaN   
26        3.306750       0.584715              NaN             NaN   
27        3.307488       0.585586              NaN             NaN   
28        3.331569       0.557019              NaN             NaN   
29        3.375197       0.485615         0.719989        2.753651   
30        3.387167       0.479391         0.822358        2.788099   
31        2.927726       1.045481         0.918227        2.731896   
32        2.564434       1.267798         0.995500        2.695128   
33        2.096696       1.404929         1.110338        2.586358   
34        1.593290       1.275872         1.248428        2.422475   
35        1.465272       1.172720         1.453099        2.193687   
36        1.564538       1.321948         1.694009        1.989009   
37        1.378949       1.130020         1.854436        1.789452   
38        1.315662       1.182674         1.963468        1.571788   
39        1.137287       1.344551         2.012503        1.468190   

    rolling_var_30  
0              NaN  
1              NaN  
2              NaN  
3              NaN  
4              NaN  
5              NaN  
6              NaN  
7              NaN  
8              NaN  
9              NaN  
10             NaN  
11             NaN  
12             NaN  
13             NaN  
14             NaN  
15             NaN  
16             NaN  
17             NaN  
18             NaN  
19             NaN  
20             NaN  
21             NaN  
22             NaN  
23             NaN  
24             NaN  
25             NaN  
26             NaN  
27             NaN  
28             NaN  
29        7.582596  
30        7.773496  
31        7.463254  
32        7.263714  
33        6.689247  
34        5.868386  
35        4.812264  
36        3.956158  
37        3.202138  
38        2.470517  
39        2.155582  </code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-24-output-2.png" width="1098" height="579" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Data with temporal features and target:
          date     value     lag_1     lag_7    lag_14    lag_30   lag_7_14  \
30 2022-01-31  3.208042  2.774746  3.124253  2.751978  0.136943   8.597877   
31 2022-02-01  0.744189  3.208042  3.960273  2.504453 -2.131859   9.918317   
32 2022-02-02  0.867866  0.744189  3.410910  3.627959 -1.450331  12.374644   
33 2022-02-03  0.357657  0.867866  3.631825  2.917816 -3.087483  10.596999   
34 2022-02-04  0.377616  0.357657  3.901459  3.896292 -3.765088  15.201224   
35 2022-02-05  1.926789  0.377616  2.822913  2.654345 -4.213348   7.492986   
36 2022-02-06  3.469605  1.926789  2.774746  2.469352 -3.757684   6.851824   
37 2022-02-07  1.908919  3.469605  3.208042  3.124253 -2.903886  10.022737   
38 2022-02-08  0.301179  1.908919  0.744189  3.960273 -2.969773   2.947193   
39 2022-02-09 -0.380758  0.301179  0.867866  3.410910 -1.851813   2.960214   
40 2022-02-10 -0.926414 -0.380758  0.357657  3.631825 -0.413119   1.298948   
41 2022-02-11 -0.012548 -0.926414  0.377616  3.901459 -0.915897   1.473254   
42 2022-02-12  0.965918 -0.012548  1.926789  2.822913  0.940638   5.439157   
43 2022-02-13  2.330713  0.965918  3.469605  2.774746  1.452559   9.627273   
44 2022-02-14  2.894219  2.330713  1.908919  3.208042  0.221116   6.123892   
45 2022-02-15  4.566709  2.894219  0.301179  0.744189  1.860105   0.224134   
46 2022-02-16  7.433799  4.566709 -0.380758  0.867866  2.751978  -0.330447   
47 2022-02-17  7.425239  7.433799 -0.926414  0.357657  2.504453  -0.331339   
48 2022-02-18  6.317755  7.425239 -0.012548  0.377616  3.627959  -0.004738   
49 2022-02-19  6.099069  6.317755  0.965918  1.926789  2.917816   1.861120   

    rolling_mean_7  rolling_std_7  rolling_mean_30  rolling_std_30  \
30        3.387167       0.479391         0.822358        2.788099   
31        2.927726       1.045481         0.918227        2.731896   
32        2.564434       1.267798         0.995500        2.695128   
33        2.096696       1.404929         1.110338        2.586358   
34        1.593290       1.275872         1.248428        2.422475   
35        1.465272       1.172720         1.453099        2.193687   
36        1.564538       1.321948         1.694009        1.989009   
37        1.378949       1.130020         1.854436        1.789452   
38        1.315662       1.182674         1.963468        1.571788   
39        1.137287       1.344551         2.012503        1.468190   
40        0.953848       1.541773         1.995393        1.500077   
41        0.898110       1.572817         2.025505        1.447777   
42        0.760843       1.508699         2.026347        1.447131   
43        0.598144       1.197138         2.055619        1.444003   
44        0.738901       1.415037         2.144722        1.408947   
45        1.348263       1.994795         2.234943        1.475193   
46        2.464628       2.863436         2.391003        1.753222   
47        3.657721       2.953523         2.555029        1.979754   
48        4.562050       2.589080         2.644689        2.087971   
49        5.295357       2.077101         2.750731        2.181030   

    rolling_var_30    target  day_of_week  month  
30        7.773496  0.744189            0      1  
31        7.463254  0.867866            1      2  
32        7.263714  0.357657            2      2  
33        6.689247  0.377616            3      2  
34        5.868386  1.926789            4      2  
35        4.812264  3.469605            5      2  
36        3.956158  1.908919            6      2  
37        3.202138  0.301179            0      2  
38        2.470517 -0.380758            1      2  
39        2.155582 -0.926414            2      2  
40        2.250231 -0.012548            3      2  
41        2.096059  0.965918            4      2  
42        2.094189  2.330713            5      2  
43        2.085144  2.894219            6      2  
44        1.985132  4.566709            0      2  
45        2.176195  7.433799            1      2  
46        3.073786  7.425239            2      2  
47        3.919425  6.317755            3      2  
48        4.359623  6.099069            4      2  
49        4.756892  6.672917            5      2  
Walk-Forward Validation Predictions:
 [-1.912115536527757, -1.9018775325747825, -1.893451112364349, -1.8847706285665258, -1.8807886773412112, -1.8776891378135212, -1.875445244713988, -1.8719862607178817, -1.8661337714545834, -1.8623932328230295, -1.8581994095647019, -1.8572424331041528, -1.86234768039255, -1.8697132622763664, -1.8716884625289532, -1.8711436520019469, -1.87161562648332, -1.8728099241079814, -1.8706442018887477, -1.8709492236994634, -1.868669700778208, -1.8667090572401006, -1.8661854487891523, -1.8618621761328265, -1.8582235332990518, -1.850666922215707, -1.8427035018488591, -1.835769354010099, -1.8264674234913616, -1.8164313214854966]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_data_preprocessing_files/figure-html/cell-24-output-4.png" width="1090" height="579" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<hr>
</section>
</section>
</section>
<section id="handling-geospatial-data" class="level1">
<h1>2.7 Handling Geospatial Data</h1>
<p>Handling geospatial data involves techniques that consider the spatial properties and relationships in the data. These methods ensure that models can effectively analyse and interpret spatial information. Below is a detailed guide from basic to advanced techniques.</p>
<section id="coordinate-systems-and-projections" class="level2">
<h2 class="anchored" data-anchor-id="coordinate-systems-and-projections">2.7.1 Coordinate Systems and Projections</h2>
<p>Coordinate systems and projections convert the spherical Earth to a flat map, enabling accurate spatial analysis. Common systems include latitude-longitude (geographic) and Universal Transverse Mercator (UTM) projections.</p>
<section id="example-3" class="level4">
<h4 class="anchored" data-anchor-id="example-3">Example:</h4>
<ul>
<li>Converting GPS coordinates to UTM for consistent distance measurements.</li>
</ul>
</section>
<section id="advanced-considerations-3" class="level4">
<h4 class="anchored" data-anchor-id="advanced-considerations-3">Advanced Considerations:</h4>
<ul>
<li><p><strong>Datum Transformation:</strong> Transform data between different datums (e.g., WGS84 to NAD83) for accuracy in different regions.</p></li>
<li><p><strong>Projection Selection:</strong> Choose appropriate projections based on the region of interest to minimize distortion (e.g., using Mercator for equatorial regions, UTM for small areas).</p></li>
</ul>
</section>
</section>
<section id="spatial-indexing" class="level2">
<h2 class="anchored" data-anchor-id="spatial-indexing">2.7.2 Spatial Indexing</h2>
<p>Spatial indexing improves the efficiency of spatial queries by organising spatial data for quick retrieval. Common indexing techniques include R-trees and Quad-trees.</p>
<section id="example-4" class="level4">
<h4 class="anchored" data-anchor-id="example-4">Example:</h4>
<ul>
<li>Using an R-tree to quickly find all restaurants within a 5 km radius of a location.</li>
</ul>
</section>
<section id="advanced-considerations-4" class="level4">
<h4 class="anchored" data-anchor-id="advanced-considerations-4">Advanced Considerations:</h4>
<ul>
<li><p><strong>Index Maintenance:</strong> Regularly update spatial indexes to reflect changes in the underlying data.</p></li>
<li><p><strong>Query Optimization:</strong> Use spatial indexes to optimize complex spatial queries involving joins and intersections.</p></li>
</ul>
</section>
</section>
<section id="geohashing" class="level2">
<h2 class="anchored" data-anchor-id="geohashing">2.7.3 Geohashing</h2>
<p>Geohashing encodes geographic coordinates into a short string of letters and digits, creating a hierarchical spatial data structure. It is useful for spatial clustering and indexing.</p>
<section id="example-5" class="level4">
<h4 class="anchored" data-anchor-id="example-5">Example:</h4>
<ul>
<li>Representing the coordinates (37.7749, -122.4194) as the geohash “9q8yy.”</li>
</ul>
</section>
<section id="advanced-considerations-5" class="level4">
<h4 class="anchored" data-anchor-id="advanced-considerations-5">Advanced Considerations:</h4>
<ul>
<li><p><strong>Precision Control:</strong> Adjust the length of the geohash string to control the precision of the spatial representation.</p></li>
<li><p><strong>Spatial Clustering:</strong> Use geohashing for efficient spatial clustering and proximity searches.</p></li>
</ul>
<p>Advanced considerations in handling geospatial data include:</p>
<ul>
<li><p><strong>Combining Techniques:</strong> Combine multiple coordinate systems and projections for comprehensive spatial analysis.</p></li>
<li><p><strong>Advanced Indexing:</strong> Use advanced spatial indexing techniques like k-d trees and geohashes for large-scale geospatial datasets.</p></li>
<li><p><strong>Integration:</strong> Integrate geohashing with other spatial data structures (e.g., spatial databases) for efficient data retrieval and analysis.</p></li>
</ul>
<div id="70ba53bf" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> geopandas <span class="im">as</span> gpd</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> shapely.geometry <span class="im">import</span> Point</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyproj <span class="im">import</span> Proj, transform</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> rtree <span class="im">import</span> index</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pygeohash <span class="im">as</span> pgh</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data: List of GPS coordinates</span></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>coordinates <span class="op">=</span> [(<span class="fl">37.7749</span>, <span class="op">-</span><span class="fl">122.4194</span>), (<span class="fl">34.0522</span>, <span class="op">-</span><span class="fl">118.2437</span>), (<span class="fl">40.7128</span>, <span class="op">-</span><span class="fl">74.0060</span>)]</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.7.1 Coordinate Systems and Projections</span></span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Create GeoDataFrame</span></span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a>gdf <span class="op">=</span> gpd.GeoDataFrame(geometry<span class="op">=</span>[Point(lon, lat) <span class="cf">for</span> lat, lon <span class="kw">in</span> coordinates], crs<span class="op">=</span><span class="st">"EPSG:4326"</span>)</span>
<span id="cb59-15"><a href="#cb59-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-16"><a href="#cb59-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert from GPS (WGS84) to UTM</span></span>
<span id="cb59-17"><a href="#cb59-17" aria-hidden="true" tabindex="-1"></a>utm_projection <span class="op">=</span> <span class="st">"EPSG:32610"</span></span>
<span id="cb59-18"><a href="#cb59-18" aria-hidden="true" tabindex="-1"></a>gdf_utm <span class="op">=</span> gdf.to_crs(utm_projection)</span>
<span id="cb59-19"><a href="#cb59-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-20"><a href="#cb59-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original GPS coordinates:</span><span class="ch">\n</span><span class="st">"</span>, gdf)</span>
<span id="cb59-21"><a href="#cb59-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Converted UTM coordinates:</span><span class="ch">\n</span><span class="st">"</span>, gdf_utm)</span>
<span id="cb59-22"><a href="#cb59-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-23"><a href="#cb59-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations: Datum Transformation</span></span>
<span id="cb59-24"><a href="#cb59-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> transform_coordinates(lat, lon, from_proj<span class="op">=</span><span class="st">'epsg:4326'</span>, to_proj<span class="op">=</span><span class="st">'epsg:4269'</span>):</span>
<span id="cb59-25"><a href="#cb59-25" aria-hidden="true" tabindex="-1"></a>    from_proj <span class="op">=</span> Proj(init<span class="op">=</span>from_proj)</span>
<span id="cb59-26"><a href="#cb59-26" aria-hidden="true" tabindex="-1"></a>    to_proj <span class="op">=</span> Proj(init<span class="op">=</span>to_proj)</span>
<span id="cb59-27"><a href="#cb59-27" aria-hidden="true" tabindex="-1"></a>    x, y <span class="op">=</span> transform(from_proj, to_proj, lon, lat)</span>
<span id="cb59-28"><a href="#cb59-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x, y</span>
<span id="cb59-29"><a href="#cb59-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-30"><a href="#cb59-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Transform WGS84 to NAD83</span></span>
<span id="cb59-31"><a href="#cb59-31" aria-hidden="true" tabindex="-1"></a>lat, lon <span class="op">=</span> <span class="fl">37.7749</span>, <span class="op">-</span><span class="fl">122.4194</span></span>
<span id="cb59-32"><a href="#cb59-32" aria-hidden="true" tabindex="-1"></a>x, y <span class="op">=</span> transform_coordinates(lat, lon)</span>
<span id="cb59-33"><a href="#cb59-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Transformed coordinates (WGS84 to NAD83): (</span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>y<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb59-34"><a href="#cb59-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-35"><a href="#cb59-35" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.7.2 Spatial Indexing</span></span>
<span id="cb59-36"><a href="#cb59-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-37"><a href="#cb59-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an R-tree spatial index</span></span>
<span id="cb59-38"><a href="#cb59-38" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> index.Index()</span>
<span id="cb59-39"><a href="#cb59-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (lat, lon) <span class="kw">in</span> <span class="bu">enumerate</span>(coordinates):</span>
<span id="cb59-40"><a href="#cb59-40" aria-hidden="true" tabindex="-1"></a>    idx.insert(i, (lon, lat, lon, lat))</span>
<span id="cb59-41"><a href="#cb59-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-42"><a href="#cb59-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Query: Find all points within a bounding box</span></span>
<span id="cb59-43"><a href="#cb59-43" aria-hidden="true" tabindex="-1"></a>bbox <span class="op">=</span> (<span class="op">-</span><span class="dv">123</span>, <span class="dv">37</span>, <span class="op">-</span><span class="dv">121</span>, <span class="dv">39</span>)</span>
<span id="cb59-44"><a href="#cb59-44" aria-hidden="true" tabindex="-1"></a>matches <span class="op">=</span> <span class="bu">list</span>(idx.intersection(bbox))</span>
<span id="cb59-45"><a href="#cb59-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Points within bounding box:"</span>, matches)</span>
<span id="cb59-46"><a href="#cb59-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-47"><a href="#cb59-47" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.7.3 Geohashing</span></span>
<span id="cb59-48"><a href="#cb59-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-49"><a href="#cb59-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate geohashes for the coordinates</span></span>
<span id="cb59-50"><a href="#cb59-50" aria-hidden="true" tabindex="-1"></a>geohashes <span class="op">=</span> [pgh.encode(lat, lon, precision<span class="op">=</span><span class="dv">6</span>) <span class="cf">for</span> lat, lon <span class="kw">in</span> coordinates]</span>
<span id="cb59-51"><a href="#cb59-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Geohashes:</span><span class="ch">\n</span><span class="st">"</span>, geohashes)</span>
<span id="cb59-52"><a href="#cb59-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-53"><a href="#cb59-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to get the bounding box of a geohash</span></span>
<span id="cb59-54"><a href="#cb59-54" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> geohash_bbox(geohash):</span>
<span id="cb59-55"><a href="#cb59-55" aria-hidden="true" tabindex="-1"></a>    lat, lon, lat_err, lon_err <span class="op">=</span> pgh.decode_exactly(geohash)</span>
<span id="cb59-56"><a href="#cb59-56" aria-hidden="true" tabindex="-1"></a>    lat_min <span class="op">=</span> lat <span class="op">-</span> lat_err</span>
<span id="cb59-57"><a href="#cb59-57" aria-hidden="true" tabindex="-1"></a>    lat_max <span class="op">=</span> lat <span class="op">+</span> lat_err</span>
<span id="cb59-58"><a href="#cb59-58" aria-hidden="true" tabindex="-1"></a>    lon_min <span class="op">=</span> lon <span class="op">-</span> lon_err</span>
<span id="cb59-59"><a href="#cb59-59" aria-hidden="true" tabindex="-1"></a>    lon_max <span class="op">=</span> lon <span class="op">+</span> lon_err</span>
<span id="cb59-60"><a href="#cb59-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">'w'</span>: lon_min, <span class="st">'s'</span>: lat_min, <span class="st">'e'</span>: lon_max, <span class="st">'n'</span>: lat_max}</span>
<span id="cb59-61"><a href="#cb59-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-62"><a href="#cb59-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations: Precision Control and Spatial Clustering</span></span>
<span id="cb59-63"><a href="#cb59-63" aria-hidden="true" tabindex="-1"></a>geohash_precisions <span class="op">=</span> [pgh.encode(lat, lon, precision<span class="op">=</span>p) <span class="cf">for</span> lat, lon <span class="kw">in</span> coordinates <span class="cf">for</span> p <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>, <span class="dv">8</span>)]</span>
<span id="cb59-64"><a href="#cb59-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Geohashes with varying precisions:</span><span class="ch">\n</span><span class="st">"</span>, geohash_precisions)</span>
<span id="cb59-65"><a href="#cb59-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-66"><a href="#cb59-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of geohash-based spatial clustering</span></span>
<span id="cb59-67"><a href="#cb59-67" aria-hidden="true" tabindex="-1"></a>geohash_dict <span class="op">=</span> {}</span>
<span id="cb59-68"><a href="#cb59-68" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> lat, lon <span class="kw">in</span> coordinates:</span>
<span id="cb59-69"><a href="#cb59-69" aria-hidden="true" tabindex="-1"></a>    ghash <span class="op">=</span> pgh.encode(lat, lon, precision<span class="op">=</span><span class="dv">6</span>)</span>
<span id="cb59-70"><a href="#cb59-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ghash <span class="kw">not</span> <span class="kw">in</span> geohash_dict:</span>
<span id="cb59-71"><a href="#cb59-71" aria-hidden="true" tabindex="-1"></a>        geohash_dict[ghash] <span class="op">=</span> []</span>
<span id="cb59-72"><a href="#cb59-72" aria-hidden="true" tabindex="-1"></a>    geohash_dict[ghash].append((lat, lon))</span>
<span id="cb59-73"><a href="#cb59-73" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Geohash-based clusters:</span><span class="ch">\n</span><span class="st">"</span>, geohash_dict)</span>
<span id="cb59-74"><a href="#cb59-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-75"><a href="#cb59-75" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced Considerations: Combining Techniques</span></span>
<span id="cb59-76"><a href="#cb59-76" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine projections and geohashing for comprehensive analysis</span></span>
<span id="cb59-77"><a href="#cb59-77" aria-hidden="true" tabindex="-1"></a>gdf[<span class="st">'geohash'</span>] <span class="op">=</span> gdf.<span class="bu">apply</span>(<span class="kw">lambda</span> row: pgh.encode(row.geometry.y, row.geometry.x, precision<span class="op">=</span><span class="dv">6</span>), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb59-78"><a href="#cb59-78" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"GeoDataFrame with geohashes:</span><span class="ch">\n</span><span class="st">"</span>, gdf)</span>
<span id="cb59-79"><a href="#cb59-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-80"><a href="#cb59-80" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced spatial indexing with R-tree and geohash integration</span></span>
<span id="cb59-81"><a href="#cb59-81" aria-hidden="true" tabindex="-1"></a>geohash_index <span class="op">=</span> index.Index()</span>
<span id="cb59-82"><a href="#cb59-82" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, geohash <span class="kw">in</span> <span class="bu">enumerate</span>(gdf[<span class="st">'geohash'</span>]):</span>
<span id="cb59-83"><a href="#cb59-83" aria-hidden="true" tabindex="-1"></a>    bbox <span class="op">=</span> geohash_bbox(geohash)</span>
<span id="cb59-84"><a href="#cb59-84" aria-hidden="true" tabindex="-1"></a>    geohash_index.insert(i, (bbox[<span class="st">'w'</span>], bbox[<span class="st">'s'</span>], bbox[<span class="st">'e'</span>], bbox[<span class="st">'n'</span>]))</span>
<span id="cb59-85"><a href="#cb59-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-86"><a href="#cb59-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Query example: Find all points within a geohash bounding box</span></span>
<span id="cb59-87"><a href="#cb59-87" aria-hidden="true" tabindex="-1"></a>query_geohash <span class="op">=</span> pgh.encode(<span class="fl">37.7749</span>, <span class="op">-</span><span class="fl">122.4194</span>, precision<span class="op">=</span><span class="dv">6</span>)</span>
<span id="cb59-88"><a href="#cb59-88" aria-hidden="true" tabindex="-1"></a>query_bbox <span class="op">=</span> geohash_bbox(query_geohash)</span>
<span id="cb59-89"><a href="#cb59-89" aria-hidden="true" tabindex="-1"></a>matches <span class="op">=</span> <span class="bu">list</span>(geohash_index.intersection((query_bbox[<span class="st">'w'</span>], query_bbox[<span class="st">'s'</span>], query_bbox[<span class="st">'e'</span>], query_bbox[<span class="st">'n'</span>])))</span>
<span id="cb59-90"><a href="#cb59-90" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Points within geohash bounding box:"</span>, matches)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Original GPS coordinates:
                     geometry
0  POINT (-122.4194 37.7749)
1  POINT (-118.2437 34.0522)
2    POINT (-74.006 40.7128)
Converted UTM coordinates:
                          geometry
0  POINT (551130.768 4180998.881)
1  POINT (939154.498 3778164.508)
2  POINT (4653450.51 5841148.971)
Transformed coordinates (WGS84 to NAD83): (-122.4194, 37.7749)
Points within bounding box: [0]
Geohashes:
 ['9q8yyk', '9q5ctr', 'dr5reg']
Geohashes with varying precisions:
 ['9q8yy', '9q8yyk', '9q8yyk8', '9q5ct', '9q5ctr', '9q5ctr1', 'dr5re', 'dr5reg', 'dr5regw']
Geohash-based clusters:
 {'9q8yyk': [(37.7749, -122.4194)], '9q5ctr': [(34.0522, -118.2437)], 'dr5reg': [(40.7128, -74.006)]}
GeoDataFrame with geohashes:
                     geometry geohash
0  POINT (-122.4194 37.7749)  9q8yyk
1  POINT (-118.2437 34.0522)  9q5ctr
2    POINT (-74.006 40.7128)  dr5reg
Points within geohash bounding box: [0]</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/ravishankar/miniforge3/lib/python3.10/site-packages/pyproj/crs/crs.py:141: FutureWarning:

'+init=&lt;authority&gt;:&lt;code&gt;' syntax is deprecated. '&lt;authority&gt;:&lt;code&gt;' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6

/Users/ravishankar/miniforge3/lib/python3.10/site-packages/pyproj/crs/crs.py:141: FutureWarning:

'+init=&lt;authority&gt;:&lt;code&gt;' syntax is deprecated. '&lt;authority&gt;:&lt;code&gt;' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6

/var/folders/v8/l5r44ftx4g5bx2y5fhdpcmmh0000gn/T/ipykernel_20299/3536010649.py:27: FutureWarning:

This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1
</code></pre>
</div>
</div>
<hr>
</section>
</section>
</section>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>