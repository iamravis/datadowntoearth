<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.47">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ravi Shankar">

<title>chapter13_time_series_analysis – Data Down To Earth</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../logo.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
<link rel="stylesheet" href="../../content.css">
<meta property="og:title" content="– Data Down To Earth">
<meta property="og:description" content="">
<meta property="og:site_name" content="Data Down To Earth">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Data Down To Earth</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projects" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Projects</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-projects">    
        <li>
    <a class="dropdown-item" href="../../../projects/dsml_projects.html">
 <span class="dropdown-text">Data Science and ML Projects</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../projects/genai_projects.html">
 <span class="dropdown-text">Generative AI Projects</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-tutorials" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Tutorials</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-tutorials">    
        <li>
    <a class="dropdown-item" href="../../../topics/statistics.html">
 <span class="dropdown-text">Statistics &amp; Probability</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/machine_learning.html">
 <span class="dropdown-text">Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/de.html">
 <span class="dropdown-text">Data Engineering</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/generative_ai.html">
 <span class="dropdown-text">Generative AI</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/public_health.html">
 <span class="dropdown-text">Public Health</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/product_sense.html">
 <span class="dropdown-text">Product Sense</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../blogs/blogs.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/iamrsps"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/iamravishankar/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content column-page" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
</div>



<div class="quarto-title-meta column-page">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ravi Shankar </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="chapter-13.-time-series-analysis" class="level1 text-content">
<h1>Chapter 13. Time Series Analysis</h1>
<p>Time series analysis involves techniques for analyzing time-ordered data points. It is used to understand underlying patterns, make forecasts, and derive meaningful insights. This chapter delves into the decomposition of time series data into its fundamental components.</p>
<section id="time-series-decomposition" class="level2">
<h2 class="anchored" data-anchor-id="time-series-decomposition">13.1. Time Series Decomposition</h2>
<p>Time series decomposition involves breaking down a time series into several distinct components, typically trend, seasonality, and residuals. This process helps in understanding the underlying patterns and structures within the data.</p>
<section id="trend" class="level3">
<h3 class="anchored" data-anchor-id="trend">13.1.1. Trend</h3>
<p>The trend component represents the long-term progression of the series. It shows the overall direction in which the data is moving over a period.</p>
<ul>
<li><strong>Definition:</strong> The trend is the underlying direction of the time series data over a long period.</li>
<li><strong>Identification:</strong> Identifying the trend often involves smoothing techniques such as moving averages or fitting polynomial curves.</li>
<li><strong>Examples:</strong>
<ul>
<li><strong>Economic Data:</strong> An increasing trend in GDP over several years.</li>
<li><strong>Stock Prices:</strong> A gradual upward or downward movement in stock prices over months or years.</li>
</ul></li>
</ul>
</section>
<section id="seasonality" class="level3">
<h3 class="anchored" data-anchor-id="seasonality">13.1.2. Seasonality</h3>
<p>The seasonality component captures periodic fluctuations in the data. These are regular patterns that repeat at fixed intervals, such as daily, monthly, or annually.</p>
<ul>
<li><strong>Definition:</strong> Seasonality refers to regular, predictable changes that recur at the same time each period.</li>
<li><strong>Identification:</strong> Seasonal patterns can be identified using methods like Fourier analysis or examining autocorrelation plots.</li>
<li><strong>Examples:</strong>
<ul>
<li><strong>Retail Sales:</strong> Higher sales during holiday seasons each year.</li>
<li><strong>Temperature Data:</strong> Seasonal temperature variations over the course of a year.</li>
</ul></li>
</ul>
</section>
<section id="residuals" class="level3">
<h3 class="anchored" data-anchor-id="residuals">13.1.3. Residuals</h3>
<p>The residual component, also known as the irregular or noise component, captures the random variations in the data that are not explained by the trend or seasonality.</p>
<ul>
<li><strong>Definition:</strong> Residuals are the random noise or irregular variations left after removing the trend and seasonal components.</li>
<li><strong>Identification:</strong> Residuals are obtained by subtracting the trend and seasonality from the original time series.</li>
<li><strong>Examples:</strong>
<ul>
<li><strong>Sales Data:</strong> Unexpected fluctuations due to promotions or one-time events.</li>
<li><strong>Weather Data:</strong> Unpredictable weather changes not accounted for by seasonal patterns.</li>
</ul></li>
</ul>
</section>
<section id="additive-and-multiplicative-models" class="level3">
<h3 class="anchored" data-anchor-id="additive-and-multiplicative-models">13.1.4. Additive and Multiplicative Models</h3>
<p>Time series decomposition can be performed using additive or multiplicative models, depending on how the components interact.</p>
<section id="additive-model" class="level4">
<h4 class="anchored" data-anchor-id="additive-model">Additive Model</h4>
<ul>
<li><strong>Definition:</strong> In an additive model, the time series is expressed as the sum of the trend, seasonal, and residual components. <span class="math display">\[
y_t = T_t + S_t + R_t
\]</span>
<ul>
<li>Here, (y_t) is the observed value at time (t), (T_t) is the trend component, (S_t) is the seasonal component, and (R_t) is the residual component.</li>
</ul></li>
<li><strong>Assumption:</strong> The components are assumed to be independent of each other.</li>
<li><strong>Usage:</strong> Suitable for time series where the magnitude of seasonal fluctuations does not vary with the level of the series.</li>
</ul>
</section>
<section id="multiplicative-model" class="level4">
<h4 class="anchored" data-anchor-id="multiplicative-model">Multiplicative Model</h4>
<ul>
<li><strong>Definition:</strong> In a multiplicative model, the time series is expressed as the product of the trend, seasonal, and residual components. <span class="math display">\[
y_t = T_t \times S_t \times R_t
\]</span>
<ul>
<li>Here, (y_t) is the observed value at time (t), (T_t) is the trend component, (S_t) is the seasonal component, and (R_t) is the residual component.</li>
</ul></li>
<li><strong>Assumption:</strong> The components interact with each other.</li>
<li><strong>Usage:</strong> Suitable for time series where the magnitude of seasonal fluctuations increases with the level of the series.</li>
</ul>
</section>
</section>
<section id="example-of-time-series-decomposition" class="level3">
<h3 class="anchored" data-anchor-id="example-of-time-series-decomposition">Example of Time Series Decomposition</h3>
<section id="additive-decomposition-of-monthly-sales-data" class="level4">
<h4 class="anchored" data-anchor-id="additive-decomposition-of-monthly-sales-data">Additive Decomposition of Monthly Sales Data</h4>
<ul>
<li><strong>Problem Statement:</strong> Decompose monthly sales data to identify the trend, seasonal, and residual components.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use monthly sales data over several years.</li>
<li><strong>Identify Trend:</strong> Apply a moving average to smooth the data and identify the trend component.</li>
<li><strong>Identify Seasonality:</strong> Calculate the average seasonal effect for each month over multiple years.</li>
<li><strong>Calculate Residuals:</strong> Subtract the trend and seasonal components from the original data to obtain the residuals.</li>
<li><strong>Model:</strong> Represent the series as an additive model: <span class="math display">\[
\text{Sales}_t = \text{Trend}_t + \text{Seasonality}_t + \text{Residual}_t
\]</span></li>
</ol></li>
</ul>
</section>
<section id="multiplicative-decomposition-of-quarterly-gdp-data" class="level4">
<h4 class="anchored" data-anchor-id="multiplicative-decomposition-of-quarterly-gdp-data">Multiplicative Decomposition of Quarterly GDP Data</h4>
<ul>
<li><strong>Problem Statement:</strong> Decompose quarterly GDP data to identify the trend, seasonal, and residual components.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use quarterly GDP data over several years.</li>
<li><strong>Identify Trend:</strong> Apply a smoothing technique to capture the long-term trend.</li>
<li><strong>Identify Seasonality:</strong> Determine the seasonal indices for each quarter.</li>
<li><strong>Calculate Residuals:</strong> Divide the original series by the trend and seasonal components to obtain the residuals.</li>
<li><strong>Model:</strong> Represent the series as a multiplicative model: <span class="math display">\[
\text{GDP}_t = \text{Trend}_t \times \text{Seasonality}_t \times \text{Residual}_t
\]</span></li>
</ol></li>
</ul>
<p>By understanding and applying time series decomposition, you can effectively analyze and interpret complex time series data, separating the underlying patterns from random noise.</p>
</section>
</section>
</section>
<section id="stationarity-and-differencing" class="level2">
<h2 class="anchored" data-anchor-id="stationarity-and-differencing">13.2. Stationarity and Differencing</h2>
<p>Stationarity is a fundamental concept in time series analysis. A stationary time series has statistical properties, such as mean and variance, that do not change over time. Many time series models, including ARIMA, require the data to be stationary. Differencing is a common method to achieve stationarity.</p>
<section id="augmented-dickey-fuller-test" class="level3">
<h3 class="anchored" data-anchor-id="augmented-dickey-fuller-test">13.2.1. Augmented Dickey-Fuller Test</h3>
<p>The Augmented Dickey-Fuller (ADF) test is a statistical test used to determine whether a time series is stationary. Specifically, it tests the null hypothesis that a unit root is present in the time series.</p>
<ul>
<li><strong>Objective:</strong> Test for the presence of a unit root in a time series, indicating non-stationarity.</li>
<li><strong>Null Hypothesis (<span class="math inline">\(H_0\)</span>):</strong> The time series has a unit root (non-stationary).</li>
<li><strong>Alternative Hypothesis (<span class="math inline">\(H_1\)</span>):</strong> The time series does not have a unit root (stationary).</li>
</ul>
<section id="mathematical-formulation" class="level4">
<h4 class="anchored" data-anchor-id="mathematical-formulation">Mathematical Formulation</h4>
<p>The ADF test extends the Dickey-Fuller test by including lagged differences of the time series to account for higher-order autoregressive processes.</p>
<ul>
<li><strong>Model:</strong> <span class="math display">\[
\Delta y_t = \alpha + \beta t + \gamma y_{t-1} + \delta_1 \Delta y_{t-1} + \cdots + \delta_p \Delta y_{t-p} + \epsilon_t
\]</span>
<ul>
<li><span class="math inline">\(\Delta y_t\)</span>: First difference of the series at time <span class="math inline">\(t\)</span>.</li>
<li><span class="math inline">\(\alpha\)</span>: Constant term.</li>
<li><span class="math inline">\(\beta\)</span>: Coefficient on a time trend.</li>
<li><span class="math inline">\(\gamma\)</span>: Coefficient to be tested (unit root indicator).</li>
<li><span class="math inline">\(\delta_i\)</span>: Coefficients of lagged differences.</li>
<li><span class="math inline">\(\epsilon_t\)</span>: Error term.</li>
</ul></li>
<li><strong>Test Statistic:</strong> The test statistic for <span class="math inline">\(\gamma\)</span> is used to determine if the time series is stationary. If the test statistic is significantly negative, the null hypothesis of a unit root is rejected.</li>
</ul>
</section>
<section id="steps-for-the-adf-test" class="level4">
<h4 class="anchored" data-anchor-id="steps-for-the-adf-test">Steps for the ADF Test</h4>
<ol type="1">
<li><strong>Formulate the Hypotheses:</strong>
<ul>
<li><span class="math inline">\(H_0\)</span>: The time series has a unit root (non-stationary).</li>
<li><span class="math inline">\(H_1\)</span>: The time series does not have a unit root (stationary).</li>
</ul></li>
<li><strong>Estimate the Model:</strong> Fit the ADF regression model to the time series data.</li>
<li><strong>Compute the Test Statistic:</strong> Calculate the test statistic for <span class="math inline">\(\gamma\)</span>.</li>
<li><strong>Determine the Critical Values:</strong> Compare the test statistic to critical values from the Dickey-Fuller distribution.</li>
<li><strong>Make a Decision:</strong> Reject <span class="math inline">\(H_0\)</span> if the test statistic is less than the critical value, indicating that the time series is stationary.</li>
</ol>
</section>
<section id="applications-of-adf-test" class="level4">
<h4 class="anchored" data-anchor-id="applications-of-adf-test">Applications of ADF Test</h4>
<ul>
<li><strong>Economics:</strong> Testing the stationarity of GDP, inflation, or interest rates.</li>
<li><strong>Finance:</strong> Checking the stationarity of stock prices or exchange rates.</li>
<li><strong>Environmental Science:</strong> Analyzing temperature or precipitation data for stationarity.</li>
</ul>
</section>
</section>
<section id="kpss-test" class="level3">
<h3 class="anchored" data-anchor-id="kpss-test">13.2.2. KPSS Test</h3>
<p>The Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test is another statistical test used to assess the stationarity of a time series. Unlike the ADF test, the KPSS test has a different null hypothesis.</p>
<ul>
<li><strong>Objective:</strong> Test for the presence of stationarity in a time series.</li>
<li><strong>Null Hypothesis (<span class="math inline">\(H_0\)</span>):</strong> The time series is stationary.</li>
<li><strong>Alternative Hypothesis (<span class="math inline">\(H_1\)</span>):</strong> The time series is non-stationary.</li>
</ul>
<section id="mathematical-formulation-1" class="level4">
<h4 class="anchored" data-anchor-id="mathematical-formulation-1">Mathematical Formulation</h4>
<p>The KPSS test decomposes a time series into a deterministic trend, a random walk, and a stationary error.</p>
<ul>
<li><strong>Model:</strong> <span class="math display">\[
y_t = \mu_t + \epsilon_t
\]</span>
<ul>
<li><span class="math inline">\(\mu_t = \mu_{t-1} + \nu_t\)</span></li>
<li><span class="math inline">\(y_t\)</span>: Observed time series.</li>
<li><span class="math inline">\(\mu_t\)</span>: Deterministic trend.</li>
<li><span class="math inline">\(\epsilon_t\)</span>: Stationary error term.</li>
<li><span class="math inline">\(\nu_t\)</span>: Error term of the random walk.</li>
</ul></li>
<li><strong>Test Statistic:</strong> The KPSS statistic is based on the residuals from the ordinary least squares (OLS) regression of <span class="math inline">\(y_t\)</span> on the deterministic trend.</li>
</ul>
</section>
<section id="steps-for-the-kpss-test" class="level4">
<h4 class="anchored" data-anchor-id="steps-for-the-kpss-test">Steps for the KPSS Test</h4>
<ol type="1">
<li><strong>Formulate the Hypotheses:</strong>
<ul>
<li><span class="math inline">\(H_0\)</span>: The time series is stationary.</li>
<li><span class="math inline">\(H_1\)</span>: The time series is non-stationary.</li>
</ul></li>
<li><strong>Estimate the Model:</strong> Fit the KPSS model to the time series data.</li>
<li><strong>Compute the Test Statistic:</strong> Calculate the KPSS test statistic from the residuals.</li>
<li><strong>Determine the Critical Values:</strong> Compare the test statistic to critical values from the KPSS distribution.</li>
<li><strong>Make a Decision:</strong> Reject <span class="math inline">\(H_0\)</span> if the test statistic is greater than the critical value, indicating that the time series is non-stationary.</li>
</ol>
</section>
<section id="applications-of-kpss-test" class="level4">
<h4 class="anchored" data-anchor-id="applications-of-kpss-test">Applications of KPSS Test</h4>
<ul>
<li><strong>Economics:</strong> Verifying the stationarity of macroeconomic indicators.</li>
<li><strong>Finance:</strong> Analyzing the stationarity of financial time series.</li>
<li><strong>Climate Science:</strong> Checking the stationarity of climate variables such as temperature or CO2 levels.</li>
</ul>
</section>
</section>
<section id="differencing" class="level3">
<h3 class="anchored" data-anchor-id="differencing">Differencing</h3>
<p>Differencing is a common technique used to transform a non-stationary time series into a stationary one. It involves subtracting the previous observation from the current observation.</p>
<ul>
<li><strong>First Differencing:</strong> The first difference of a time series <span class="math inline">\(y_t\)</span> is defined as: <span class="math display">\[
\Delta y_t = y_t - y_{t-1}
\]</span></li>
<li><strong>Second Differencing:</strong> If the first difference is not sufficient to achieve stationarity, the second difference can be used: <span class="math display">\[
\Delta^2 y_t = \Delta y_t - \Delta y_{t-1} = (y_t - y_{t-1}) - (y_{t-1} - y_{t-2})
\]</span></li>
</ul>
<section id="steps-for-differencing" class="level4">
<h4 class="anchored" data-anchor-id="steps-for-differencing">Steps for Differencing</h4>
<ol type="1">
<li><strong>Plot the Time Series:</strong> Visualize the original time series to identify trends or seasonality.</li>
<li><strong>Apply First Differencing:</strong> Subtract the previous observation from the current observation.</li>
<li><strong>Check for Stationarity:</strong> Use the ADF or KPSS test to check if the differenced series is stationary.</li>
<li><strong>Repeat if Necessary:</strong> If the series is still not stationary, apply second differencing or higher orders until stationarity is achieved.</li>
</ol>
</section>
<section id="example-of-differencing" class="level4">
<h4 class="anchored" data-anchor-id="example-of-differencing">Example of Differencing</h4>
<ul>
<li><strong>Problem Statement:</strong> Transform a non-stationary monthly sales data series into a stationary series.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use monthly sales data over several years.</li>
<li><strong>Plot the Data:</strong> Visualize the original sales data to identify any trends or seasonality.</li>
<li><strong>Apply First Differencing:</strong> Calculate the first difference of the sales data.</li>
<li><strong>Check Stationarity:</strong> Perform the ADF and KPSS tests on the differenced series.</li>
<li><strong>Apply Second Differencing:</strong> If necessary, apply second differencing and re-test for stationarity.</li>
</ol></li>
</ul>
<p>By understanding and applying stationarity tests and differencing techniques, you can effectively prepare time series data for further analysis and modeling, ensuring that the assumptions of many time series models are met.</p>
</section>
</section>
</section>
<section id="autocorrelation-and-partial-autocorrelation" class="level2">
<h2 class="anchored" data-anchor-id="autocorrelation-and-partial-autocorrelation">13.3. Autocorrelation and Partial Autocorrelation</h2>
<p>Autocorrelation and partial autocorrelation are essential concepts in time series analysis. They help in identifying patterns and relationships in time series data, which is crucial for building and understanding time series models.</p>
<section id="autocorrelation" class="level3">
<h3 class="anchored" data-anchor-id="autocorrelation">13.3.1. Autocorrelation</h3>
<p>Autocorrelation, also known as serial correlation, measures the correlation of a time series with its own past values. It indicates the degree to which current values of the series are related to its past values.</p>
<ul>
<li><strong>Definition:</strong> Autocorrelation at lag <span class="math inline">\(k\)</span> is the correlation between <span class="math inline">\(y_t\)</span> and <span class="math inline">\(y_{t-k}\)</span>. <span class="math display">\[
\rho_k = \frac{\text{Cov}(y_t, y_{t-k})}{\sqrt{\text{Var}(y_t) \text{Var}(y_{t-k})}}
\]</span>
<ul>
<li>Here, <span class="math inline">\(\text{Cov}(y_t, y_{t-k})\)</span> is the covariance between <span class="math inline">\(y_t\)</span> and <span class="math inline">\(y_{t-k}\)</span>, and <span class="math inline">\(\text{Var}(y_t)\)</span> and <span class="math inline">\(\text{Var}(y_{t-k})\)</span> are their variances.</li>
</ul></li>
<li><strong>Autocorrelation Function (ACF):</strong> The ACF is a plot of autocorrelation coefficients <span class="math inline">\(\rho_k\)</span> for different lags <span class="math inline">\(k\)</span>. It helps in identifying the extent and nature of temporal dependencies in the time series.</li>
</ul>
<section id="steps-to-compute-and-interpret-acf" class="level4">
<h4 class="anchored" data-anchor-id="steps-to-compute-and-interpret-acf">Steps to Compute and Interpret ACF</h4>
<ol type="1">
<li><strong>Compute Autocorrelation:</strong> Calculate the autocorrelation coefficients for various lags.</li>
<li><strong>Plot ACF:</strong> Create an ACF plot with lags on the x-axis and autocorrelation coefficients on the y-axis.</li>
<li><strong>Interpret ACF:</strong>
<ul>
<li><strong>Significant Peaks:</strong> Significant autocorrelation at certain lags indicates a repeating pattern.</li>
<li><strong>Decay Pattern:</strong> A slow decay in the ACF suggests a trend in the series, while a quick drop to zero indicates a lack of trend.</li>
</ul></li>
</ol>
</section>
<section id="applications-of-autocorrelation" class="level4">
<h4 class="anchored" data-anchor-id="applications-of-autocorrelation">Applications of Autocorrelation</h4>
<ul>
<li><strong>Identifying Seasonality:</strong> Detecting seasonal patterns by observing significant peaks at regular intervals.</li>
<li><strong>Model Identification:</strong> Choosing appropriate lags for ARIMA models.</li>
<li><strong>Detecting Trends:</strong> Observing autocorrelation to identify the presence of trends in the data.</li>
</ul>
</section>
</section>
<section id="partial-autocorrelation" class="level3">
<h3 class="anchored" data-anchor-id="partial-autocorrelation">13.3.2. Partial Autocorrelation</h3>
<p>Partial autocorrelation measures the correlation between <span class="math inline">\(y_t\)</span> and <span class="math inline">\(y_{t-k}\)</span> after removing the effects of intermediate lags. It helps in identifying the direct relationship between values separated by <span class="math inline">\(k\)</span> periods.</p>
<ul>
<li><strong>Definition:</strong> Partial autocorrelation at lag <span class="math inline">\(k\)</span> is the correlation between <span class="math inline">\(y_t\)</span> and <span class="math inline">\(y_{t-k}\)</span>, controlling for the values of the time series at all shorter lags. <span class="math display">\[
\phi_k = \text{Correlation}(y_t - \hat{y}_t, y_{t-k} - \hat{y}_{t-k})
\]</span>
<ul>
<li>Here, <span class="math inline">\(\hat{y}_t\)</span> is the value of <span class="math inline">\(y_t\)</span> predicted from all intermediate lags <span class="math inline">\(1, 2, \ldots, k-1\)</span>.</li>
</ul></li>
<li><strong>Partial Autocorrelation Function (PACF):</strong> The PACF is a plot of partial autocorrelation coefficients <span class="math inline">\(\phi_k\)</span> for different lags <span class="math inline">\(k\)</span>. It helps in understanding the direct effects of past values on the current value.</li>
</ul>
<section id="steps-to-compute-and-interpret-pacf" class="level4">
<h4 class="anchored" data-anchor-id="steps-to-compute-and-interpret-pacf">Steps to Compute and Interpret PACF</h4>
<ol type="1">
<li><strong>Compute Partial Autocorrelation:</strong> Calculate the partial autocorrelation coefficients for various lags.</li>
<li><strong>Plot PACF:</strong> Create a PACF plot with lags on the x-axis and partial autocorrelation coefficients on the y-axis.</li>
<li><strong>Interpret PACF:</strong>
<ul>
<li><strong>Significant Peaks:</strong> Significant partial autocorrelation at a specific lag suggests a direct influence of that lag on the current value.</li>
<li><strong>Cut-off Pattern:</strong> A sharp cut-off after a few lags indicates an AR process, while a gradual decline suggests an MA process.</li>
</ul></li>
</ol>
</section>
<section id="applications-of-partial-autocorrelation" class="level4">
<h4 class="anchored" data-anchor-id="applications-of-partial-autocorrelation">Applications of Partial Autocorrelation</h4>
<ul>
<li><strong>Identifying AR and MA Components:</strong> Determining the order of autoregressive (AR) and moving average (MA) components in ARIMA models.</li>
<li><strong>Detecting Direct Relationships:</strong> Understanding the direct impact of past values on the current value in a time series.</li>
</ul>
</section>
</section>
<section id="example-of-autocorrelation-and-partial-autocorrelation" class="level3">
<h3 class="anchored" data-anchor-id="example-of-autocorrelation-and-partial-autocorrelation">Example of Autocorrelation and Partial Autocorrelation</h3>
<section id="identifying-patterns-in-monthly-sales-data" class="level4">
<h4 class="anchored" data-anchor-id="identifying-patterns-in-monthly-sales-data">Identifying Patterns in Monthly Sales Data</h4>
<ul>
<li><strong>Problem Statement:</strong> Analyze monthly sales data to identify autocorrelation and partial autocorrelation patterns.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use a dataset of monthly sales over several years.</li>
<li><strong>Compute ACF:</strong> Calculate and plot the autocorrelation coefficients for various lags.</li>
<li><strong>Compute PACF:</strong> Calculate and plot the partial autocorrelation coefficients for various lags.</li>
<li><strong>Interpret Results:</strong>
<ul>
<li><strong>ACF:</strong> Look for significant peaks to identify repeating patterns or seasonality.</li>
<li><strong>PACF:</strong> Examine significant partial autocorrelations to determine the direct effects of past sales on current sales.</li>
</ul></li>
<li><strong>Model Selection:</strong> Use the insights from ACF and PACF to select appropriate lags for ARIMA or other time series models.</li>
</ol></li>
</ul>
<p>By understanding and applying autocorrelation and partial autocorrelation analysis, you can effectively identify patterns and relationships in time series data, which is crucial for accurate modeling and forecasting.</p>
</section>
</section>
</section>
<section id="arima-and-sarima-models" class="level2">
<h2 class="anchored" data-anchor-id="arima-and-sarima-models">13.4. ARIMA and SARIMA Models</h2>
<p>ARIMA (AutoRegressive Integrated Moving Average) and SARIMA (Seasonal ARIMA) models are widely used for analyzing and forecasting time series data. These models combine autoregressive, differencing, and moving average components to capture different aspects of the data.</p>
<section id="autoregressive-ar-models" class="level3">
<h3 class="anchored" data-anchor-id="autoregressive-ar-models">13.4.1. Autoregressive (AR) Models</h3>
<p>An autoregressive (AR) model uses the dependency between an observation and a number of lagged observations. It predicts future values based on past values of the same time series.</p>
<ul>
<li><strong>Definition:</strong> An AR model of order <span class="math inline">\(p\)</span> (AR(<span class="math inline">\(p\)</span>)) is defined as: <span class="math display">\[
y_t = \phi_1 y_{t-1} + \phi_2 y_{t-2} + \cdots + \phi_p y_{t-p} + \epsilon_t
\]</span>
<ul>
<li>Here, <span class="math inline">\(y_t\)</span> is the current value, <span class="math inline">\(\phi_i\)</span> are the coefficients, and <span class="math inline">\(\epsilon_t\)</span> is white noise.</li>
</ul></li>
<li><strong>Characteristics:</strong>
<ul>
<li><strong>Stationarity:</strong> AR models require the time series to be stationary.</li>
<li><strong>Lag Selection:</strong> The number of lags (<span class="math inline">\(p\)</span>) is determined using criteria like AIC (Akaike Information Criterion) or BIC (Bayesian Information Criterion).</li>
<li><strong>ACF and PACF:</strong> In an AR(<span class="math inline">\(p\)</span>) model, the ACF tails off, and the PACF cuts off after <span class="math inline">\(p\)</span> lags.</li>
</ul></li>
</ul>
<section id="example-ar2-model" class="level4">
<h4 class="anchored" data-anchor-id="example-ar2-model">Example: AR(2) Model</h4>
<p>Suppose we have a time series where <span class="math inline">\(y_t\)</span> depends on <span class="math inline">\(y_{t-1}\)</span> and <span class="math inline">\(y_{t-2}\)</span>.</p>
<ul>
<li><strong>Model:</strong> <span class="math display">\[
y_t = \phi_1 y_{t-1} + \phi_2 y_{t-2} + \epsilon_t
\]</span></li>
<li><strong>Interpretation:</strong> The current value <span class="math inline">\(y_t\)</span> is influenced by the values at one and two time periods back, with coefficients <span class="math inline">\(\phi_1\)</span> and <span class="math inline">\(\phi_2\)</span> representing the strengths of these influences.</li>
</ul>
</section>
</section>
<section id="moving-average-ma-models" class="level3">
<h3 class="anchored" data-anchor-id="moving-average-ma-models">13.4.2. Moving Average (MA) Models</h3>
<p>A moving average (MA) model uses past forecast errors in a regression-like model. It predicts future values based on past forecast errors.</p>
<ul>
<li><strong>Definition:</strong> An MA model of order <span class="math inline">\(q\)</span> (MA(<span class="math inline">\(q\)</span>)) is defined as: <span class="math display">\[
y_t = \mu + \epsilon_t + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \cdots + \theta_q \epsilon_{t-q}
\]</span>
<ul>
<li>Here, <span class="math inline">\(y_t\)</span> is the current value, <span class="math inline">\(\mu\)</span> is the mean of the series, <span class="math inline">\(\theta_i\)</span> are the coefficients, and <span class="math inline">\(\epsilon_t\)</span> is white noise.</li>
</ul></li>
<li><strong>Characteristics:</strong>
<ul>
<li><strong>Stationarity:</strong> MA models can be used on non-stationary series but often require differencing.</li>
<li><strong>Lag Selection:</strong> The number of lags (<span class="math inline">\(q\)</span>) is chosen using criteria like AIC or BIC.</li>
<li><strong>ACF and PACF:</strong> In an MA(<span class="math inline">\(q\)</span>) model, the ACF cuts off after <span class="math inline">\(q\)</span> lags, and the PACF tails off.</li>
</ul></li>
</ul>
<section id="example-ma1-model" class="level4">
<h4 class="anchored" data-anchor-id="example-ma1-model">Example: MA(1) Model</h4>
<p>Suppose we have a time series where <span class="math inline">\(y_t\)</span> depends on the previous error term <span class="math inline">\(\epsilon_{t-1}\)</span>.</p>
<ul>
<li><strong>Model:</strong> <span class="math display">\[
y_t = \mu + \epsilon_t + \theta_1 \epsilon_{t-1}
\]</span></li>
<li><strong>Interpretation:</strong> The current value <span class="math inline">\(y_t\)</span> is influenced by the previous error term <span class="math inline">\(\epsilon_{t-1}\)</span>, with coefficient <span class="math inline">\(\theta_1\)</span> representing the strength of this influence.</li>
</ul>
</section>
</section>
<section id="integrated-i-component" class="level3">
<h3 class="anchored" data-anchor-id="integrated-i-component">13.4.3. Integrated (I) Component</h3>
<p>The integrated (I) component represents the differencing required to make a time series stationary. This component is crucial in handling non-stationary data.</p>
<ul>
<li><strong>Definition:</strong> Differencing is applied to remove trends and seasonality in the data.
<ul>
<li><strong>First Differencing:</strong> <span class="math display">\[
\Delta y_t = y_t - y_{t-1}
\]</span></li>
<li><strong>Second Differencing:</strong> <span class="math display">\[
\Delta^2 y_t = \Delta y_t - \Delta y_{t-1} = (y_t - y_{t-1}) - (y_{t-1} - y_{t-2})
\]</span></li>
</ul></li>
<li><strong>Order of Differencing (<span class="math inline">\(d\)</span>):</strong> The number of times differencing is applied to achieve stationarity. Commonly, <span class="math inline">\(d\)</span> is 0, 1, or 2.</li>
</ul>
<section id="example-differencing" class="level4">
<h4 class="anchored" data-anchor-id="example-differencing">Example: Differencing</h4>
<p>Suppose we have a non-stationary time series <span class="math inline">\(y_t\)</span> with a trend.</p>
<ul>
<li><strong>First Differencing:</strong> <span class="math display">\[
\Delta y_t = y_t - y_{t-1}
\]</span>
<ul>
<li>This removes the linear trend and can help achieve stationarity.</li>
</ul></li>
</ul>
</section>
</section>
<section id="seasonal-components" class="level3">
<h3 class="anchored" data-anchor-id="seasonal-components">13.4.4. Seasonal Components</h3>
<p>SARIMA models extend ARIMA models by explicitly modeling seasonal effects. They include seasonal autoregressive, differencing, and moving average components.</p>
<ul>
<li><strong>Definition:</strong> A SARIMA model is denoted as ARIMA(<span class="math inline">\(p, d, q\)</span>)(<span class="math inline">\(P, D, Q\)</span>)<span class="math inline">\(_s\)</span>, where:
<ul>
<li><span class="math inline">\(p, d, q\)</span> are the non-seasonal parameters.</li>
<li><span class="math inline">\(P, D, Q\)</span> are the seasonal parameters.</li>
<li><span class="math inline">\(s\)</span> is the length of the seasonal cycle.</li>
</ul></li>
<li><strong>Seasonal AR Component (SAR):</strong> <span class="math display">\[
y_t = \phi_{P, s} y_{t-s} + \epsilon_t
\]</span></li>
<li><strong>Seasonal MA Component (SMA):</strong> <span class="math display">\[
y_t = \mu + \epsilon_t + \theta_{Q, s} \epsilon_{t-s}
\]</span></li>
</ul>
<section id="example-sarima-model" class="level4">
<h4 class="anchored" data-anchor-id="example-sarima-model">Example: SARIMA Model</h4>
<p>Suppose we have monthly sales data with a yearly seasonal pattern.</p>
<ul>
<li><strong>Model:</strong> ARIMA(<span class="math inline">\(p, d, q\)</span>)(<span class="math inline">\(P, D, Q\)</span>)<span class="math inline">\(_{12}\)</span> where <span class="math inline">\(s = 12\)</span> for monthly data.</li>
</ul>
</section>
</section>
<section id="box-jenkins-methodology" class="level3">
<h3 class="anchored" data-anchor-id="box-jenkins-methodology">13.4.5. Box-Jenkins Methodology</h3>
<p>The Box-Jenkins methodology provides a systematic approach to identifying, estimating, and checking ARIMA and SARIMA models.</p>
<section id="steps-in-the-box-jenkins-methodology" class="level4">
<h4 class="anchored" data-anchor-id="steps-in-the-box-jenkins-methodology">Steps in the Box-Jenkins Methodology</h4>
<ol type="1">
<li><strong>Model Identification:</strong>
<ul>
<li><strong>Plot Data:</strong> Visualize the time series to identify patterns.</li>
<li><strong>Check Stationarity:</strong> Use ADF or KPSS tests to check stationarity.</li>
<li><strong>ACF and PACF:</strong> Use ACF and PACF plots to identify the order of AR and MA components.</li>
</ul></li>
<li><strong>Model Estimation:</strong>
<ul>
<li><strong>Parameter Estimation:</strong> Estimate the parameters (<span class="math inline">\(p, d, q, P, D, Q\)</span>) using maximum likelihood or other methods.</li>
<li><strong>Fit Model:</strong> Fit the ARIMA or SARIMA model to the data.</li>
</ul></li>
<li><strong>Model Checking:</strong>
<ul>
<li><strong>Residual Analysis:</strong> Analyze the residuals to check for white noise using ACF, PACF, and statistical tests (e.g., Ljung-Box test).</li>
<li><strong>Diagnostic Plots:</strong> Use diagnostic plots to assess model adequacy.</li>
</ul></li>
<li><strong>Model Forecasting:</strong>
<ul>
<li><strong>Generate Forecasts:</strong> Use the fitted model to make future predictions.</li>
<li><strong>Evaluate Forecast Accuracy:</strong> Compare forecasts with actual data using metrics like RMSE, MAE, or MAPE.</li>
</ul></li>
</ol>
</section>
</section>
<section id="example-of-arima-model-application" class="level3">
<h3 class="anchored" data-anchor-id="example-of-arima-model-application">Example of ARIMA Model Application</h3>
<section id="forecasting-monthly-sales-data" class="level4">
<h4 class="anchored" data-anchor-id="forecasting-monthly-sales-data">Forecasting Monthly Sales Data</h4>
<ul>
<li><strong>Problem Statement:</strong> Forecast future sales based on historical monthly sales data.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use monthly sales data over several years.</li>
<li><strong>Plot Data:</strong> Visualize the sales data to identify trends and seasonality.</li>
<li><strong>Check Stationarity:</strong> Apply the ADF test to check for stationarity. If non-stationary, apply differencing.</li>
<li><strong>Identify Model:</strong> Use ACF and PACF plots to determine appropriate values for <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span>.</li>
<li><strong>Estimate Parameters:</strong> Fit the ARIMA(<span class="math inline">\(p, d, q\)</span>) model to the data.</li>
<li><strong>Check Residuals:</strong> Analyze residuals to ensure they are white noise.</li>
<li><strong>Generate Forecasts:</strong> Use the model to forecast future sales.</li>
</ol></li>
</ul>
<p>By understanding and applying ARIMA and SARIMA models, you can effectively analyze and forecast time series data, capturing both non-seasonal and seasonal patterns.</p>
</section>
</section>
</section>
<section id="prophet" class="level2">
<h2 class="anchored" data-anchor-id="prophet">13.5. Prophet</h2>
<p>Prophet is an open-source tool developed by Facebook for forecasting time series data. It is designed to handle the common challenges in time series forecasting, such as missing data, large outliers, and seasonal trends. Prophet decomposes time series into trend, seasonality, and holiday effects, and it is particularly useful for business forecasting.</p>
<section id="trend-modeling" class="level3">
<h3 class="anchored" data-anchor-id="trend-modeling">13.5.1. Trend Modeling</h3>
<p>Prophet models the trend component of a time series using a piecewise linear or logistic growth model, which allows for capturing changes in trends over time.</p>
<ul>
<li><strong>Piecewise Linear Trend:</strong>
<ul>
<li><strong>Model:</strong> <span class="math display">\[
g(t) = (k + a(t)^T\delta)t + (m + a(t)^T\gamma)
\]</span>
<ul>
<li>Here, <span class="math inline">\(k\)</span> is the growth rate, <span class="math inline">\(m\)</span> is the offset, <span class="math inline">\(a(t)\)</span> is an indicator function for the changepoints, <span class="math inline">\(\delta\)</span> and <span class="math inline">\(\gamma\)</span> are the rate and offset adjustments at changepoints.</li>
</ul></li>
<li><strong>Changepoints:</strong> Prophet automatically detects points in time where the trend changes significantly and incorporates these into the model.</li>
</ul></li>
<li><strong>Logistic Growth Trend:</strong>
<ul>
<li><strong>Model:</strong> <span class="math display">\[
g(t) = \frac{C}{1 + \exp(-k(t - m))}
\]</span>
<ul>
<li>Here, <span class="math inline">\(C\)</span> is the carrying capacity, <span class="math inline">\(k\)</span> is the growth rate, and <span class="math inline">\(m\)</span> is the midpoint of the growth.</li>
</ul></li>
</ul></li>
<li><strong>Applications:</strong>
<ul>
<li><strong>Business Forecasting:</strong> Modeling sales or user growth.</li>
<li><strong>Finance:</strong> Projecting stock prices or economic indicators.</li>
</ul></li>
</ul>
</section>
<section id="seasonality-modeling" class="level3">
<h3 class="anchored" data-anchor-id="seasonality-modeling">13.5.2. Seasonality Modeling</h3>
<p>Prophet captures seasonality using Fourier series, which allows for flexible modeling of various seasonal effects such as daily, weekly, and yearly cycles.</p>
<ul>
<li><strong>Seasonal Component:</strong>
<ul>
<li><strong>Model:</strong> <span class="math display">\[
s(t) = \sum_{n=1}^{N} \left( a_n \cos\left(\frac{2\pi nt}{P}\right) + b_n \sin\left(\frac{2\pi nt}{P}\right) \right)
\]</span>
<ul>
<li>Here, <span class="math inline">\(P\)</span> is the period of the seasonality (e.g., 365.25 for yearly seasonality), <span class="math inline">\(a_n\)</span> and <span class="math inline">\(b_n\)</span> are the coefficients of the Fourier series.</li>
</ul></li>
</ul></li>
<li><strong>Multiple Seasonalities:</strong>
<ul>
<li>Prophet can handle multiple seasonalities simultaneously (e.g., weekly and yearly seasonality).</li>
</ul></li>
<li><strong>Applications:</strong>
<ul>
<li><strong>Retail:</strong> Capturing seasonal sales patterns.</li>
<li><strong>Web Traffic:</strong> Modeling weekly and yearly traffic patterns.</li>
</ul></li>
</ul>
</section>
<section id="holiday-effects" class="level3">
<h3 class="anchored" data-anchor-id="holiday-effects">13.5.3. Holiday Effects</h3>
<p>Prophet includes the ability to model the effects of holidays on time series data. Holidays can have significant impacts on time series, especially in business and retail contexts.</p>
<ul>
<li><strong>Holiday Effects:</strong>
<ul>
<li><strong>Model:</strong> <span class="math display">\[
h(t) = \sum_{i} \left( a_i \text{holiday}_i(t) \right)
\]</span>
<ul>
<li>Here, <span class="math inline">\(\text{holiday}_i(t)\)</span> is an indicator function for the <span class="math inline">\(i\)</span>-th holiday, and <span class="math inline">\(a_i\)</span> is the effect of that holiday.</li>
</ul></li>
</ul></li>
<li><strong>Custom Holidays:</strong>
<ul>
<li>Users can define custom holidays and their respective effects on the time series.</li>
</ul></li>
<li><strong>Applications:</strong>
<ul>
<li><strong>E-commerce:</strong> Modeling the impact of Black Friday, Christmas, and other major holidays on sales.</li>
<li><strong>Tourism:</strong> Analyzing the effects of holidays on tourist numbers.</li>
</ul></li>
</ul>
</section>
<section id="changepoint-detection" class="level3">
<h3 class="anchored" data-anchor-id="changepoint-detection">13.5.4. Changepoint Detection</h3>
<p>Prophet automatically detects changepoints, which are points in time where the time series undergoes a significant change in trend.</p>
<ul>
<li><strong>Changepoint Detection:</strong>
<ul>
<li><strong>Automatic Detection:</strong> Prophet identifies potential changepoints based on the data and incorporates them into the trend model.</li>
<li><strong>Manual Specification:</strong> Users can specify custom changepoints if they have domain knowledge about when significant changes occur.</li>
</ul></li>
<li><strong>Adjustments at Changepoints:</strong>
<ul>
<li>The model adjusts the growth rate and offset at each detected changepoint to better fit the data.</li>
</ul></li>
<li><strong>Applications:</strong>
<ul>
<li><strong>Business:</strong> Identifying when a significant shift occurs in sales or user growth trends.</li>
<li><strong>Economic Data:</strong> Detecting structural breaks in economic indicators.</li>
</ul></li>
</ul>
</section>
<section id="example-of-prophet-application" class="level3">
<h3 class="anchored" data-anchor-id="example-of-prophet-application">Example of Prophet Application</h3>
<section id="forecasting-sales-data-with-prophet" class="level4">
<h4 class="anchored" data-anchor-id="forecasting-sales-data-with-prophet">Forecasting Sales Data with Prophet</h4>
<ul>
<li><strong>Problem Statement:</strong> Forecast future sales based on historical sales data, accounting for trends, seasonality, and holiday effects.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use historical sales data over several years.</li>
<li><strong>Initialize Prophet Model:</strong> Create a Prophet model instance.</li>
<li><strong>Fit Model:</strong> Fit the Prophet model to the historical sales data.</li>
<li><strong>Incorporate Holidays:</strong> Define important holidays and their potential effects on sales.</li>
<li><strong>Detect Changepoints:</strong> Allow Prophet to automatically detect changepoints in the data.</li>
<li><strong>Generate Forecasts:</strong> Use the fitted model to forecast future sales.</li>
<li><strong>Visualize Results:</strong> Plot the forecasted sales along with the trend, seasonality, and holiday effects.</li>
</ol></li>
</ul>
<p>By understanding and applying the Prophet model, you can effectively forecast time series data, capturing important components like trend, seasonality, holiday effects, and changepoints.</p>
</section>
</section>
</section>
<section id="lstm-for-time-series" class="level2">
<h2 class="anchored" data-anchor-id="lstm-for-time-series">13.6. LSTM for Time Series</h2>
<p>Long Short-Term Memory (LSTM) networks are a type of recurrent neural network (RNN) that are particularly well-suited for modeling sequential data, such as time series. LSTM networks are capable of learning long-term dependencies, which makes them effective for time series forecasting.</p>
<section id="lstm-architecture-for-sequential-data" class="level3">
<h3 class="anchored" data-anchor-id="lstm-architecture-for-sequential-data">13.6.1. LSTM Architecture for Sequential Data</h3>
<p>LSTM networks are designed to overcome the limitations of traditional RNNs, particularly the issue of long-term dependency and vanishing gradient problems. An LSTM cell contains gates that regulate the flow of information.</p>
<ul>
<li><strong>Components of an LSTM Cell:</strong>
<ul>
<li><strong>Cell State (<span class="math inline">\(C_t\)</span>):</strong> The cell state is the memory of the network, which carries information across different time steps.</li>
<li><strong>Forget Gate (<span class="math inline">\(f_t\)</span>):</strong> Decides what information to discard from the cell state. <span class="math display">\[
f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)
\]</span></li>
<li><strong>Input Gate (<span class="math inline">\(i_t\)</span>):</strong> Decides what new information to add to the cell state. <span class="math display">\[
i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i)
\]</span></li>
<li><strong>Candidate State (<span class="math inline">\(\tilde{C}_t\)</span>):</strong> Creates a vector of new candidate values that could be added to the cell state. <span class="math display">\[
\tilde{C}_t = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C)
\]</span></li>
<li><strong>Output Gate (<span class="math inline">\(o_t\)</span>):</strong> Decides what part of the cell state to output. <span class="math display">\[
o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o)
\]</span></li>
<li><strong>Hidden State (<span class="math inline">\(h_t\)</span>):</strong> The hidden state is the output of the LSTM cell at time <span class="math inline">\(t\)</span>. <span class="math display">\[
h_t = o_t \cdot \tanh(C_t)
\]</span></li>
</ul></li>
</ul>
</section>
<section id="time-series-forecasting-with-lstm" class="level3">
<h3 class="anchored" data-anchor-id="time-series-forecasting-with-lstm">13.6.2. Time Series Forecasting with LSTM</h3>
<p>LSTMs are used in time series forecasting to predict future values based on past sequences. The architecture of an LSTM network for time series forecasting typically involves stacking multiple LSTM layers followed by dense layers.</p>
<section id="steps-for-time-series-forecasting-with-lstm" class="level4">
<h4 class="anchored" data-anchor-id="steps-for-time-series-forecasting-with-lstm">Steps for Time Series Forecasting with LSTM</h4>
<ol type="1">
<li><strong>Data Preparation:</strong>
<ul>
<li><strong>Normalize Data:</strong> Scale the data to a suitable range, such as [0, 1].</li>
<li><strong>Create Sequences:</strong> Divide the time series data into sequences of fixed length (e.g., 30 time steps).</li>
</ul></li>
<li><strong>Model Design:</strong>
<ul>
<li><strong>Input Layer:</strong> Input shape is the length of the sequence and the number of features.</li>
<li><strong>LSTM Layers:</strong> One or more LSTM layers to capture temporal dependencies.</li>
<li><strong>Dense Layers:</strong> Fully connected layers to map the LSTM outputs to the desired forecast.</li>
</ul></li>
<li><strong>Model Training:</strong>
<ul>
<li><strong>Loss Function:</strong> Use a loss function like mean squared error (MSE) for regression tasks.</li>
<li><strong>Optimizer:</strong> Common choices include Adam or RMSprop.</li>
<li><strong>Training:</strong> Train the model using the prepared sequences.</li>
</ul></li>
<li><strong>Model Evaluation and Forecasting:</strong>
<ul>
<li><strong>Evaluate Performance:</strong> Use metrics like RMSE or MAE to evaluate the model on a validation set.</li>
<li><strong>Generate Forecasts:</strong> Use the trained model to predict future values.</li>
</ul></li>
</ol>
</section>
<section id="example-forecasting-stock-prices" class="level4">
<h4 class="anchored" data-anchor-id="example-forecasting-stock-prices">Example: Forecasting Stock Prices</h4>
<ul>
<li><strong>Problem Statement:</strong> Forecast future stock prices based on historical price data.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use historical stock price data.</li>
<li><strong>Normalize Data:</strong> Scale the stock prices to the [0, 1] range.</li>
<li><strong>Create Sequences:</strong> Generate sequences of past stock prices (e.g., 30 days) to predict the next day’s price.</li>
<li><strong>Design Model:</strong> Create an LSTM model with input, LSTM, and dense layers.</li>
<li><strong>Train Model:</strong> Train the model on the prepared sequences.</li>
<li><strong>Evaluate Model:</strong> Assess the model’s performance on a validation set.</li>
<li><strong>Forecast Prices:</strong> Use the model to forecast future stock prices.</li>
</ol></li>
</ul>
</section>
</section>
<section id="sequence-to-sequence-models" class="level3">
<h3 class="anchored" data-anchor-id="sequence-to-sequence-models">13.6.3. Sequence-to-Sequence Models</h3>
<p>Sequence-to-sequence (seq2seq) models are a type of architecture that is useful for tasks where the input and output sequences can vary in length. They are commonly used in applications such as language translation and time series forecasting.</p>
<section id="components-of-seq2seq-models" class="level4">
<h4 class="anchored" data-anchor-id="components-of-seq2seq-models">Components of Seq2Seq Models</h4>
<ol type="1">
<li><strong>Encoder:</strong>
<ul>
<li>Encodes the input sequence into a fixed-length context vector.</li>
<li>Consists of LSTM layers that process the input sequence and produce the context vector.</li>
</ul></li>
<li><strong>Decoder:</strong>
<ul>
<li>Decodes the context vector to produce the output sequence.</li>
<li>Consists of LSTM layers that generate the output sequence based on the context vector.</li>
</ul></li>
<li><strong>Attention Mechanism (optional):</strong>
<ul>
<li>Enhances the seq2seq model by allowing the decoder to focus on different parts of the input sequence at each time step.</li>
<li>Computes a weighted sum of the encoder outputs, enabling the model to handle long sequences more effectively.</li>
</ul></li>
</ol>
</section>
<section id="example-multi-step-time-series-forecasting" class="level4">
<h4 class="anchored" data-anchor-id="example-multi-step-time-series-forecasting">Example: Multi-step Time Series Forecasting</h4>
<ul>
<li><strong>Problem Statement:</strong> Forecast multiple future values of a time series (e.g., predict the next 7 days of stock prices).</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use historical stock price data.</li>
<li><strong>Normalize Data:</strong> Scale the stock prices to the [0, 1] range.</li>
<li><strong>Create Sequences:</strong> Generate sequences of past stock prices (e.g., 30 days) to predict the next 7 days’ prices.</li>
<li><strong>Design Seq2Seq Model:</strong>
<ul>
<li><strong>Encoder:</strong> LSTM layers to encode the input sequence.</li>
<li><strong>Decoder:</strong> LSTM layers to decode the context vector and generate the forecast.</li>
<li><strong>Attention Mechanism:</strong> Optionally, add attention to improve performance.</li>
</ul></li>
<li><strong>Train Model:</strong> Train the model on the prepared sequences.</li>
<li><strong>Evaluate Model:</strong> Assess the model’s performance on a validation set.</li>
<li><strong>Forecast Prices:</strong> Use the model to forecast multiple future stock prices.</li>
</ol></li>
</ul>
<p>By understanding and applying LSTM and seq2seq models, you can effectively handle complex time series forecasting tasks, capturing long-term dependencies and producing accurate predictions.</p>
</section>
</section>
</section>
<section id="dynamic-time-warping" class="level2">
<h2 class="anchored" data-anchor-id="dynamic-time-warping">13.7. Dynamic Time Warping</h2>
<p>Dynamic Time Warping (DTW) is a technique used to measure similarity between two temporal sequences that may vary in speed. It is widely used in time series analysis, speech recognition, and other fields where the temporal alignment of sequences is crucial.</p>
<section id="overview-and-objective" class="level3">
<h3 class="anchored" data-anchor-id="overview-and-objective">13.7.1. Overview and Objective</h3>
<ul>
<li><strong>Objective:</strong> Align two time series sequences by warping the time axis to minimize the distance between them.</li>
<li><strong>Key Idea:</strong> DTW allows for stretching and compressing of the time axis, enabling comparison of sequences that may be out of sync.</li>
</ul>
</section>
<section id="mathematical-formulation-2" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-formulation-2">13.7.2. Mathematical Formulation</h3>
<p>Given two time series sequences <span class="math inline">\(A = (a_1, a_2, \ldots, a_n)\)</span> and <span class="math inline">\(B = (b_1, b_2, \ldots, b_m)\)</span>, the goal is to find a mapping between these sequences that minimizes the cumulative distance.</p>
<section id="steps-to-compute-dtw" class="level4">
<h4 class="anchored" data-anchor-id="steps-to-compute-dtw">Steps to Compute DTW</h4>
<ol type="1">
<li><p><strong>Distance Matrix:</strong> Compute a distance matrix <span class="math inline">\(D\)</span> where each element <span class="math inline">\(D(i, j)\)</span> represents the distance between <span class="math inline">\(a_i\)</span> and <span class="math inline">\(b_j\)</span>. <span class="math display">\[
D(i, j) = |a_i - b_j|
\]</span></p></li>
<li><p><strong>Cumulative Distance Matrix:</strong> Construct a cumulative distance matrix <span class="math inline">\(C\)</span> where each element <span class="math inline">\(C(i, j)\)</span> represents the minimum cumulative distance to align <span class="math inline">\(a_i\)</span> with <span class="math inline">\(b_j\)</span>. <span class="math display">\[
C(i, j) = D(i, j) + \min(C(i-1, j), C(i, j-1), C(i-1, j-1))
\]</span></p>
<ul>
<li>Initialize <span class="math inline">\(C(0, 0) = 0\)</span>, and set <span class="math inline">\(C(i, 0) = C(0, j) = \infty\)</span> for <span class="math inline">\(i, j &gt; 0\)</span>.</li>
</ul></li>
<li><p><strong>Optimal Path:</strong> Trace back from <span class="math inline">\(C(n, m)\)</span> to <span class="math inline">\(C(0, 0)\)</span> to find the optimal alignment path that minimizes the cumulative distance.</p></li>
</ol>
</section>
<section id="example-of-dtw-calculation" class="level4">
<h4 class="anchored" data-anchor-id="example-of-dtw-calculation">Example of DTW Calculation</h4>
<p>Consider two time series sequences: - <span class="math inline">\(A = (1, 2, 3)\)</span> - <span class="math inline">\(B = (2, 2, 4, 4)\)</span></p>
<ol type="1">
<li><p><strong>Distance Matrix:</strong> <span class="math display">\[
D = \begin{bmatrix}
|1-2| &amp; |1-2| &amp; |1-4| &amp; |1-4| \\
|2-2| &amp; |2-2| &amp; |2-4| &amp; |2-4| \\
|3-2| &amp; |3-2| &amp; |3-4| &amp; |3-4|
\end{bmatrix}
= \begin{bmatrix}
1 &amp; 1 &amp; 3 &amp; 3 \\
0 &amp; 0 &amp; 2 &amp; 2 \\
1 &amp; 1 &amp; 1 &amp; 1
\end{bmatrix}
\]</span></p></li>
<li><p><strong>Cumulative Distance Matrix:</strong> <span class="math display">\[
C = \begin{bmatrix}
1 &amp; 2 &amp; 5 &amp; 8 \\
1 &amp; 1 &amp; 3 &amp; 5 \\
2 &amp; 2 &amp; 2 &amp; 3
\end{bmatrix}
\]</span></p></li>
<li><p><strong>Optimal Path:</strong> Trace back from <span class="math inline">\(C(3, 4)\)</span> to <span class="math inline">\(C(0, 0)\)</span> to find the optimal alignment path.</p></li>
</ol>
</section>
</section>
<section id="applications-of-dtw" class="level3">
<h3 class="anchored" data-anchor-id="applications-of-dtw">13.7.3. Applications of DTW</h3>
<ul>
<li><strong>Speech Recognition:</strong> Aligning spoken words to reference patterns despite variations in speaking speed.
<ul>
<li><strong>Example:</strong> Matching a spoken digit “three” to a reference recording of “three” even if the duration varies.</li>
</ul></li>
<li><strong>Time Series Clustering:</strong> Grouping similar time series sequences together based on their DTW distance.
<ul>
<li><strong>Example:</strong> Clustering different stock price movements to identify similar trends.</li>
</ul></li>
<li><strong>Gesture Recognition:</strong> Recognizing gestures by aligning motion sequences.
<ul>
<li><strong>Example:</strong> Matching a hand gesture to a reference gesture for a sign language interpreter.</li>
</ul></li>
</ul>
</section>
<section id="advantages-and-disadvantages" class="level3">
<h3 class="anchored" data-anchor-id="advantages-and-disadvantages">13.7.4. Advantages and Disadvantages</h3>
<ul>
<li><strong>Advantages:</strong>
<ul>
<li><strong>Flexibility:</strong> Can align sequences of different lengths and handle variations in speed.</li>
<li><strong>Robustness:</strong> Effective for noisy and unaligned data.</li>
</ul></li>
<li><strong>Disadvantages:</strong>
<ul>
<li><strong>Computational Complexity:</strong> DTW can be computationally expensive for long sequences.</li>
<li><strong>Parameter Sensitivity:</strong> Performance can be affected by the choice of distance metric and warping window size.</li>
</ul></li>
</ul>
</section>
<section id="example-of-dtw-application" class="level3">
<h3 class="anchored" data-anchor-id="example-of-dtw-application">Example of DTW Application</h3>
<section id="aligning-sensor-data-for-activity-recognition" class="level4">
<h4 class="anchored" data-anchor-id="aligning-sensor-data-for-activity-recognition">Aligning Sensor Data for Activity Recognition</h4>
<ul>
<li><strong>Problem Statement:</strong> Align sensor data from two different activities to identify similarities and differences.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use time series data from sensors tracking different activities (e.g., walking and running).</li>
<li><strong>Compute DTW:</strong> Calculate the DTW distance between the sensor data sequences.</li>
<li><strong>Analyze Results:</strong> Identify the alignment path to understand how the activities compare over time.</li>
<li><strong>Classify Activities:</strong> Use the DTW distance to classify the type of activity.</li>
</ol></li>
</ul>
<p>By understanding and applying Dynamic Time Warping, you can effectively measure similarities between time series sequences, even when they are misaligned or vary in speed, enabling robust time series analysis and pattern recognition.</p>
</section>
</section>
</section>
<section id="exponential-smoothing-methods" class="level2">
<h2 class="anchored" data-anchor-id="exponential-smoothing-methods">13.8. Exponential Smoothing Methods</h2>
<p>Exponential smoothing methods are a family of forecasting techniques that apply weighted averages of past observations to predict future values. The weights decrease exponentially as the observations get older, giving more importance to recent observations.</p>
<section id="simple-exponential-smoothing" class="level3">
<h3 class="anchored" data-anchor-id="simple-exponential-smoothing">13.8.1. Simple Exponential Smoothing</h3>
<p>Simple exponential smoothing is used for forecasting time series data that do not exhibit any trend or seasonality.</p>
<ul>
<li><strong>Model:</strong> <span class="math display">\[
\hat{y}_{t+1} = \alpha y_t + (1 - \alpha) \hat{y}_t
\]</span>
<ul>
<li>Here, <span class="math inline">\(\hat{y}_{t+1}\)</span> is the forecast for the next period, <span class="math inline">\(y_t\)</span> is the actual value at time <span class="math inline">\(t\)</span>, <span class="math inline">\(\hat{y}_t\)</span> is the forecast at time <span class="math inline">\(t\)</span>, and <span class="math inline">\(\alpha\)</span> is the smoothing parameter (0 &lt; <span class="math inline">\(\alpha\)</span> &lt; 1).</li>
</ul></li>
<li><strong>Steps:</strong>
<ol type="1">
<li><strong>Initialize:</strong> Set the initial forecast <span class="math inline">\(\hat{y}_1\)</span> to <span class="math inline">\(y_1\)</span> or the mean of the first few observations.</li>
<li><strong>Update:</strong> For each subsequent period, update the forecast using the formula above.</li>
</ol></li>
<li><strong>Applications:</strong>
<ul>
<li><strong>Inventory Management:</strong> Forecasting demand for items with no trend or seasonality.</li>
<li><strong>Basic Time Series:</strong> Suitable for data with no systematic pattern.</li>
</ul></li>
</ul>
<section id="example-forecasting-daily-demand" class="level4">
<h4 class="anchored" data-anchor-id="example-forecasting-daily-demand">Example: Forecasting Daily Demand</h4>
<ul>
<li><strong>Problem Statement:</strong> Forecast the daily demand for a product with no apparent trend or seasonality.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use historical daily demand data.</li>
<li><strong>Choose <span class="math inline">\(\alpha\)</span>:</strong> Select a smoothing parameter (e.g., <span class="math inline">\(\alpha = 0.2\)</span>).</li>
<li><strong>Apply Model:</strong> Use the simple exponential smoothing formula to generate forecasts.</li>
<li><strong>Evaluate Forecasts:</strong> Compare forecasts with actual data to assess accuracy.</li>
</ol></li>
</ul>
</section>
</section>
<section id="double-exponential-smoothing-holts-method" class="level3">
<h3 class="anchored" data-anchor-id="double-exponential-smoothing-holts-method">13.8.2. Double Exponential Smoothing (Holt’s Method)</h3>
<p>Double exponential smoothing, also known as Holt’s method, is used for forecasting time series data with a trend.</p>
<ul>
<li><strong>Model:</strong>
<ul>
<li><p><strong>Level:</strong> <span class="math inline">\(l_t = \alpha y_t + (1 - \alpha)(l_{t-1} + b_{t-1})\)</span></p></li>
<li><p><strong>Trend:</strong> <span class="math inline">\(b_t = \beta (l_t - l_{t-1}) + (1 - \beta) b_{t-1}\)</span></p></li>
<li><p><strong>Forecast:</strong> <span class="math inline">\(\hat{y}_{t+k} = l_t + kb_t\)</span></p></li>
<li><p>Here, <span class="math inline">\(l_t\)</span> is the level at time <span class="math inline">\(t\)</span>, <span class="math inline">\(b_t\)</span> is the trend at time <span class="math inline">\(t\)</span>, <span class="math inline">\(\alpha\)</span> is the level smoothing parameter, and <span class="math inline">\(\beta\)</span> is the trend smoothing parameter.</p></li>
</ul></li>
<li><strong>Steps:</strong>
<ol type="1">
<li><strong>Initialize:</strong> Set initial values for level <span class="math inline">\(l_1\)</span> and trend <span class="math inline">\(b_1\)</span>.</li>
<li><strong>Update:</strong> For each subsequent period, update the level and trend using the formulas above.</li>
<li><strong>Forecast:</strong> Generate forecasts for future periods using the level and trend components.</li>
</ol></li>
<li><strong>Applications:</strong>
<ul>
<li><strong>Sales Forecasting:</strong> Predicting sales with an upward or downward trend.</li>
<li><strong>Financial Data:</strong> Forecasting stock prices or other financial indicators with a trend.</li>
</ul></li>
</ul>
<section id="example-forecasting-monthly-sales" class="level4">
<h4 class="anchored" data-anchor-id="example-forecasting-monthly-sales">Example: Forecasting Monthly Sales</h4>
<ul>
<li><strong>Problem Statement:</strong> Forecast monthly sales data exhibiting a trend.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use historical monthly sales data.</li>
<li><strong>Initialize:</strong> Set initial values for level and trend (e.g., <span class="math inline">\(l_1\)</span> = first observation, <span class="math inline">\(b_1\)</span> = difference between first two observations).</li>
<li><strong>Choose <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>:</strong> Select smoothing parameters (e.g., <span class="math inline">\(\alpha = 0.2\)</span>, <span class="math inline">\(\beta = 0.1\)</span>).</li>
<li><strong>Apply Model:</strong> Use Holt’s method to generate forecasts.</li>
<li><strong>Evaluate Forecasts:</strong> Compare forecasts with actual sales data to assess accuracy.</li>
</ol></li>
</ul>
</section>
</section>
<section id="triple-exponential-smoothing-holt-winters-method" class="level3">
<h3 class="anchored" data-anchor-id="triple-exponential-smoothing-holt-winters-method">13.8.3. Triple Exponential Smoothing (Holt-Winters’ Method)</h3>
<p>Triple exponential smoothing, also known as Holt-Winters’ method, is used for forecasting time series data with both trend and seasonality.</p>
<ul>
<li><strong>Model:</strong>
<ul>
<li><p><strong>Level:</strong> <span class="math inline">\(l_t = \alpha \frac{y_t}{s_{t-L}} + (1 - \alpha)(l_{t-1} + b_{t-1})\)</span></p></li>
<li><p><strong>Trend:</strong> <span class="math inline">\(b_t = \beta (l_t - l_{t-1}) + (1 - \beta) b_{t-1}\)</span></p></li>
<li><p><strong>Seasonality:</strong> <span class="math inline">\(s_t = \gamma \frac{y_t}{l_t} + (1 - \gamma)s_{t-L}\)</span></p></li>
<li><p><strong>Forecast:</strong> <span class="math inline">\(\hat{y}_{t+k} = (l_t + kb_t)s_{t-L+k \mod L}\)</span></p></li>
<li><p>Here, <span class="math inline">\(l_t\)</span> is the level at time <span class="math inline">\(t\)</span>, <span class="math inline">\(b_t\)</span> is the trend at time <span class="math inline">\(t\)</span>, <span class="math inline">\(s_t\)</span> is the seasonal component at time <span class="math inline">\(t\)</span>, <span class="math inline">\(\alpha\)</span> is the level smoothing parameter, <span class="math inline">\(\beta\)</span> is the trend smoothing parameter, <span class="math inline">\(\gamma\)</span> is the seasonality smoothing parameter, and <span class="math inline">\(L\)</span> is the length of the seasonal cycle.</p></li>
</ul></li>
<li><strong>Steps:</strong>
<ol type="1">
<li><strong>Initialize:</strong> Set initial values for level, trend, and seasonality.</li>
<li><strong>Update:</strong> For each subsequent period, update the level, trend, and seasonality using the formulas above.</li>
<li><strong>Forecast:</strong> Generate forecasts for future periods using the level, trend, and seasonal components.</li>
</ol></li>
<li><strong>Applications:</strong>
<ul>
<li><strong>Retail Sales:</strong> Forecasting sales with seasonal patterns (e.g., holiday season).</li>
<li><strong>Tourism:</strong> Predicting tourist numbers with yearly seasonality.</li>
</ul></li>
</ul>
<section id="example-forecasting-seasonal-sales-data" class="level4">
<h4 class="anchored" data-anchor-id="example-forecasting-seasonal-sales-data">Example: Forecasting Seasonal Sales Data</h4>
<ul>
<li><strong>Problem Statement:</strong> Forecast monthly sales data with a yearly seasonal pattern.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use historical monthly sales data.</li>
<li><strong>Initialize:</strong> Set initial values for level, trend, and seasonality (e.g., average of first year’s data for level, difference between years for trend, and initial seasonality indices).</li>
<li><strong>Choose <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(\gamma\)</span>:</strong> Select smoothing parameters (e.g., <span class="math inline">\(\alpha = 0.2\)</span>, <span class="math inline">\(\beta = 0.1\)</span>, <span class="math inline">\(\gamma = 0.3\)</span>).</li>
<li><strong>Apply Model:</strong> Use Holt-Winters’ method to generate forecasts.</li>
<li><strong>Evaluate Forecasts:</strong> Compare forecasts with actual sales data to assess accuracy.</li>
</ol></li>
</ul>
<p>By understanding and applying exponential smoothing methods, you can effectively forecast time series data with varying patterns, whether they exhibit no trend, trend, or both trend and seasonality.</p>
</section>
</section>
</section>
<section id="state-space-models" class="level2">
<h2 class="anchored" data-anchor-id="state-space-models">13.9. State Space Models</h2>
<p>State space models are a powerful framework for modeling time series data. They provide a structured way to represent time series as dynamic systems, capturing the relationships between observed data and underlying latent states. Two widely used state space models are Kalman filters and Hidden Markov Models (HMMs).</p>
<section id="kalman-filters" class="level3">
<h3 class="anchored" data-anchor-id="kalman-filters">13.9.1. Kalman Filters</h3>
<p>Kalman filters are used for estimating the hidden state of a dynamic system from a series of noisy measurements. They are optimal for linear systems with Gaussian noise.</p>
<ul>
<li><strong>Model Components:</strong>
<ul>
<li><strong>State Equation:</strong> Describes the evolution of the hidden state over time. <span class="math display">\[
\mathbf{x}_t = \mathbf{F}\mathbf{x}_{t-1} + \mathbf{B}\mathbf{u}_t + \mathbf{w}_t
\]</span>
<ul>
<li>Here, <span class="math inline">\(\mathbf{x}_t\)</span> is the state vector at time <span class="math inline">\(t\)</span>, <span class="math inline">\(\mathbf{F}\)</span> is the state transition matrix, <span class="math inline">\(\mathbf{u}_t\)</span> is the control input, <span class="math inline">\(\mathbf{B}\)</span> is the control matrix, and <span class="math inline">\(\mathbf{w}_t\)</span> is the process noise.</li>
</ul></li>
<li><strong>Observation Equation:</strong> Relates the observed measurements to the hidden state. <span class="math display">\[
\mathbf{z}_t = \mathbf{H}\mathbf{x}_t + \mathbf{v}_t
\]</span>
<ul>
<li>Here, <span class="math inline">\(\mathbf{z}_t\)</span> is the observation vector at time <span class="math inline">\(t\)</span>, <span class="math inline">\(\mathbf{H}\)</span> is the observation matrix, and <span class="math inline">\(\mathbf{v}_t\)</span> is the measurement noise.</li>
</ul></li>
</ul></li>
<li><strong>Kalman Filter Algorithm:</strong>
<ol type="1">
<li><strong>Prediction Step:</strong> Predict the next state and its uncertainty.
<ul>
<li>Predicted state: <span class="math inline">\(\hat{\mathbf{x}}_{t|t-1} = \mathbf{F}\hat{\mathbf{x}}_{t-1|t-1} + \mathbf{B}\mathbf{u}_t\)</span></li>
<li>Predicted covariance: <span class="math inline">\(\mathbf{P}_{t|t-1} = \mathbf{F}\mathbf{P}_{t-1|t-1}\mathbf{F}^T + \mathbf{Q}\)</span></li>
</ul></li>
<li><strong>Update Step:</strong> Update the prediction using the new observation.
<ul>
<li>Kalman gain: <span class="math inline">\(\mathbf{K}_t = \mathbf{P}_{t|t-1}\mathbf{H}^T(\mathbf{H}\mathbf{P}_{t|t-1}\mathbf{H}^T + \mathbf{R})^{-1}\)</span></li>
<li>Updated state: <span class="math inline">\(\hat{\mathbf{x}}_{t|t} = \hat{\mathbf{x}}_{t|t-1} + \mathbf{K}_t(\mathbf{z}_t - \mathbf{H}\hat{\mathbf{x}}_{t|t-1})\)</span></li>
<li>Updated covariance: <span class="math inline">\(\mathbf{P}_{t|t} = (\mathbf{I} - \mathbf{K}_t\mathbf{H})\mathbf{P}_{t|t-1}\)</span></li>
</ul></li>
</ol></li>
<li><strong>Applications:</strong>
<ul>
<li><strong>Navigation Systems:</strong> Estimating the position and velocity of moving objects.</li>
<li><strong>Financial Modeling:</strong> Filtering noise from financial time series data.</li>
<li><strong>Control Systems:</strong> Tracking the state of dynamic systems in engineering.</li>
</ul></li>
</ul>
<section id="example-tracking-a-moving-object" class="level4">
<h4 class="anchored" data-anchor-id="example-tracking-a-moving-object">Example: Tracking a Moving Object</h4>
<ul>
<li><strong>Problem Statement:</strong> Estimate the position and velocity of a moving object from noisy measurements.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Define State and Observation:</strong> <span class="math inline">\(\mathbf{x}_t = [\text{position}, \text{velocity}]^T\)</span>, <span class="math inline">\(\mathbf{z}_t = [\text{measured position}]\)</span>.</li>
<li><strong>Initialize:</strong> Set initial estimates for state and covariance.</li>
<li><strong>Prediction and Update:</strong> Apply the Kalman filter algorithm to iteratively update the state estimates.</li>
</ol></li>
</ul>
</section>
</section>
<section id="hidden-markov-models" class="level3">
<h3 class="anchored" data-anchor-id="hidden-markov-models">13.9.2. Hidden Markov Models</h3>
<p>Hidden Markov Models (HMMs) are used to model systems that transition between a finite set of states in a probabilistic manner. Each state generates observations according to a probability distribution.</p>
<ul>
<li><strong>Model Components:</strong>
<ul>
<li><strong>States (<span class="math inline">\(S\)</span>):</strong> The hidden states of the system, which are not directly observable.</li>
<li><strong>Observations (<span class="math inline">\(O\)</span>):</strong> The observed data generated by the states.</li>
<li><strong>Transition Probabilities (<span class="math inline">\(A\)</span>):</strong> The probabilities of transitioning from one state to another. <span class="math display">\[
A = \{a_{ij} = P(S_{t+1} = j | S_t = i)\}
\]</span></li>
<li><strong>Emission Probabilities (<span class="math inline">\(B\)</span>):</strong> The probabilities of observing a particular symbol from a state. <span class="math display">\[
B = \{b_j(o_t) = P(O_t = o_t | S_t = j)\}
\]</span></li>
<li><strong>Initial Probabilities (<span class="math inline">\(\pi\)</span>):</strong> The initial state distribution. <span class="math display">\[
\pi = \{\pi_i = P(S_1 = i)\}
\]</span></li>
</ul></li>
<li><strong>HMM Algorithms:</strong>
<ol type="1">
<li><strong>Forward Algorithm:</strong> Computes the probability of observing a sequence given the model.</li>
<li><strong>Viterbi Algorithm:</strong> Finds the most likely sequence of hidden states given the observations.</li>
<li><strong>Baum-Welch Algorithm:</strong> An iterative algorithm to estimate the parameters of the HMM.</li>
</ol></li>
<li><strong>Applications:</strong>
<ul>
<li><strong>Speech Recognition:</strong> Modeling phonemes and words in speech.</li>
<li><strong>Bioinformatics:</strong> Predicting protein structures and gene sequences.</li>
<li><strong>Finance:</strong> Modeling market regimes and economic cycles.</li>
</ul></li>
</ul>
<section id="example-speech-recognition" class="level4">
<h4 class="anchored" data-anchor-id="example-speech-recognition">Example: Speech Recognition</h4>
<ul>
<li><strong>Problem Statement:</strong> Recognize spoken words using a sequence of audio features.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Define States and Observations:</strong> States represent phonemes, observations are audio features.</li>
<li><strong>Initialize Model Parameters:</strong> Set initial estimates for transition and emission probabilities.</li>
<li><strong>Training:</strong> Use the Baum-Welch algorithm to train the HMM on labeled audio data.</li>
<li><strong>Recognition:</strong> Apply the Viterbi algorithm to find the most likely sequence of phonemes for a given audio input.</li>
</ol></li>
</ul>
<p>By understanding and applying Kalman filters and Hidden Markov Models, you can effectively model and analyze time series data, capturing underlying states and dynamic processes.</p>
</section>
</section>
</section>
<section id="vector-autoregression-var" class="level2">
<h2 class="anchored" data-anchor-id="vector-autoregression-var">13.10. Vector Autoregression (VAR)</h2>
<p>Vector Autoregression (VAR) is a statistical model used to capture the linear interdependencies among multiple time series. It generalizes the univariate autoregressive model by allowing for more than one evolving variable.</p>
<section id="model-definition" class="level3">
<h3 class="anchored" data-anchor-id="model-definition">Model Definition</h3>
<ul>
<li><strong>Model:</strong> <span class="math display">\[
\mathbf{y}_t = \mathbf{A}_1 \mathbf{y}_{t-1} + \mathbf{A}_2 \mathbf{y}_{t-2} + \cdots + \mathbf{A}_p \mathbf{y}_{t-p} + \mathbf{u}_t
\]</span>
<ul>
<li>Here, <span class="math inline">\(\mathbf{y}_t\)</span> is a vector of time series variables at time <span class="math inline">\(t\)</span>, <span class="math inline">\(\mathbf{A}_i\)</span> are coefficient matrices, <span class="math inline">\(p\)</span> is the lag order, and <span class="math inline">\(\mathbf{u}_t\)</span> is a vector of error terms.</li>
</ul></li>
</ul>
</section>
<section id="steps-for-var-modeling" class="level3">
<h3 class="anchored" data-anchor-id="steps-for-var-modeling">Steps for VAR Modeling</h3>
<ol type="1">
<li><strong>Stationarity Check:</strong> Ensure that all time series are stationary. Use differencing if necessary.</li>
<li><strong>Lag Order Selection:</strong> Determine the optimal lag length using criteria like AIC, BIC, or HQIC.</li>
<li><strong>Model Estimation:</strong> Estimate the VAR model parameters using methods such as Ordinary Least Squares (OLS).</li>
<li><strong>Model Diagnostics:</strong> Check for residual autocorrelation and stability.</li>
<li><strong>Impulse Response Function:</strong> Analyze the response of the system to shocks in one variable using impulse response functions.</li>
<li><strong>Forecast Error Variance Decomposition:</strong> Understand the proportion of the forecast error variance of each variable explained by shocks to the other variables.</li>
<li><strong>Forecasting:</strong> Use the fitted model to generate forecasts.</li>
</ol>
</section>
<section id="applications" class="level3">
<h3 class="anchored" data-anchor-id="applications">Applications</h3>
<ul>
<li><strong>Economics:</strong> Analyzing the interdependencies among GDP, inflation, and interest rates.</li>
<li><strong>Finance:</strong> Modeling the relationships between multiple financial assets.</li>
<li><strong>Environmental Science:</strong> Studying the interactions between different climate variables.</li>
</ul>
<section id="example-economic-indicators" class="level4">
<h4 class="anchored" data-anchor-id="example-economic-indicators">Example: Economic Indicators</h4>
<ul>
<li><strong>Problem Statement:</strong> Analyze the interdependencies among GDP, inflation, and interest rates.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use historical data for GDP, inflation, and interest rates.</li>
<li><strong>Check Stationarity:</strong> Apply unit root tests and difference the series if necessary.</li>
<li><strong>Select Lag Order:</strong> Use AIC to determine the optimal lag length.</li>
<li><strong>Estimate Model:</strong> Fit the VAR model to the data.</li>
<li><strong>Impulse Response Analysis:</strong> Assess how GDP reacts to shocks in inflation and interest rates.</li>
<li><strong>Forecast Error Variance Decomposition:</strong> Determine the extent to which each variable’s forecast error variance is explained by the others.</li>
<li><strong>Forecast:</strong> Generate forecasts for the economic indicators.</li>
</ol></li>
</ul>
</section>
</section>
</section>
<section id="granger-causality" class="level2">
<h2 class="anchored" data-anchor-id="granger-causality">13.11. Granger Causality</h2>
<p>Granger causality is a statistical hypothesis test to determine whether one time series can predict another time series. It does not imply true causality but shows predictive ability.</p>
<section id="test-definition" class="level3">
<h3 class="anchored" data-anchor-id="test-definition">Test Definition</h3>
<ul>
<li><strong>Hypothesis:</strong>
<ul>
<li>Null Hypothesis (<span class="math inline">\(H_0\)</span>): Time series <span class="math inline">\(X\)</span> does not Granger-cause time series <span class="math inline">\(Y\)</span>.</li>
<li>Alternative Hypothesis (<span class="math inline">\(H_1\)</span>): Time series <span class="math inline">\(X\)</span> Granger-causes time series <span class="math inline">\(Y\)</span>.</li>
</ul></li>
</ul>
</section>
<section id="test-steps" class="level3">
<h3 class="anchored" data-anchor-id="test-steps">Test Steps</h3>
<ol type="1">
<li><strong>Lag Selection:</strong> Choose the appropriate lag length for the test.</li>
<li><strong>Model Estimation:</strong> Fit a VAR model including the lags of both time series.</li>
<li><strong>F-test:</strong> Perform an F-test to compare the model including <span class="math inline">\(X\)</span>’s lags to a model excluding <span class="math inline">\(X\)</span>’s lags.</li>
</ol>
</section>
<section id="applications-1" class="level3">
<h3 class="anchored" data-anchor-id="applications-1">Applications</h3>
<ul>
<li><strong>Economics:</strong> Determining if consumer spending can predict economic growth.</li>
<li><strong>Finance:</strong> Testing if stock market returns can predict economic indicators.</li>
<li><strong>Climate Science:</strong> Investigating if temperature changes can predict sea level changes.</li>
</ul>
<section id="example-stock-returns-and-economic-growth" class="level4">
<h4 class="anchored" data-anchor-id="example-stock-returns-and-economic-growth">Example: Stock Returns and Economic Growth</h4>
<ul>
<li><strong>Problem Statement:</strong> Test if stock market returns can predict economic growth.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use historical data for stock returns and GDP.</li>
<li><strong>Select Lags:</strong> Determine the optimal lag length using AIC.</li>
<li><strong>Estimate Models:</strong> Fit the VAR model with and without stock returns.</li>
<li><strong>Perform F-test:</strong> Conduct the Granger causality test to determine if stock returns can predict GDP.</li>
</ol></li>
</ul>
</section>
</section>
</section>
<section id="spectral-analysis" class="level2">
<h2 class="anchored" data-anchor-id="spectral-analysis">13.12. Spectral Analysis</h2>
<p>Spectral analysis is a method used to examine the frequency domain characteristics of a time series. It identifies the dominant cycles and periodicities in the data.</p>
<section id="fourier-transform" class="level3">
<h3 class="anchored" data-anchor-id="fourier-transform">13.12.1. Fourier Transform</h3>
<p>Fourier Transform (FT) decomposes a time series into its constituent frequencies, revealing the periodic structure.</p>
<ul>
<li><strong>Model:</strong> <span class="math display">\[
X(f) = \sum_{t=0}^{N-1} x(t) e^{-i 2 \pi f t / N}
\]</span>
<ul>
<li>Here, <span class="math inline">\(X(f)\)</span> is the Fourier transform of the time series <span class="math inline">\(x(t)\)</span> at frequency <span class="math inline">\(f\)</span>, and <span class="math inline">\(N\)</span> is the number of data points.</li>
</ul></li>
</ul>
</section>
<section id="steps-for-fourier-transform" class="level3">
<h3 class="anchored" data-anchor-id="steps-for-fourier-transform">Steps for Fourier Transform</h3>
<ol type="1">
<li><strong>Compute FT:</strong> Apply the Fourier transform to the time series.</li>
<li><strong>Analyze Spectrum:</strong> Examine the amplitude and phase of the resulting frequencies.</li>
<li><strong>Identify Dominant Frequencies:</strong> Determine the significant periodic components.</li>
</ol>
</section>
<section id="applications-2" class="level3">
<h3 class="anchored" data-anchor-id="applications-2">Applications</h3>
<ul>
<li><strong>Signal Processing:</strong> Analyzing audio signals.</li>
<li><strong>Economics:</strong> Identifying business cycles.</li>
<li><strong>Climate Science:</strong> Detecting periodic climate patterns.</li>
</ul>
<section id="example-seasonal-sales-analysis" class="level4">
<h4 class="anchored" data-anchor-id="example-seasonal-sales-analysis">Example: Seasonal Sales Analysis</h4>
<ul>
<li><strong>Problem Statement:</strong> Identify seasonal patterns in monthly sales data.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use historical monthly sales data.</li>
<li><strong>Compute FT:</strong> Apply the Fourier transform to the sales data.</li>
<li><strong>Analyze Spectrum:</strong> Identify significant seasonal frequencies and their amplitudes.</li>
</ol></li>
</ul>
</section>
</section>
<section id="wavelet-analysis" class="level3">
<h3 class="anchored" data-anchor-id="wavelet-analysis">13.12.2. Wavelet Analysis</h3>
<p>Wavelet analysis provides a time-frequency representation of a time series, allowing for the detection of both stationary and non-stationary signals.</p>
<ul>
<li><strong>Model:</strong> <span class="math display">\[
W_x(a, b) = \frac{1}{\sqrt{a}} \int_{-\infty}^{\infty} x(t) \psi\left( \frac{t - b}{a} \right) dt
\]</span>
<ul>
<li>Here, <span class="math inline">\(W_x(a, b)\)</span> is the wavelet transform of <span class="math inline">\(x(t)\)</span>, <span class="math inline">\(\psi\)</span> is the wavelet function, <span class="math inline">\(a\)</span> is the scale parameter, and <span class="math inline">\(b\)</span> is the translation parameter.</li>
</ul></li>
</ul>
</section>
<section id="steps-for-wavelet-analysis" class="level3">
<h3 class="anchored" data-anchor-id="steps-for-wavelet-analysis">Steps for Wavelet Analysis</h3>
<ol type="1">
<li><strong>Choose Wavelet:</strong> Select an appropriate wavelet function (e.g., Morlet, Haar).</li>
<li><strong>Compute Transform:</strong> Apply the wavelet transform to the time series.</li>
<li><strong>Analyze Time-Frequency Representation:</strong> Examine the wavelet coefficients to identify significant features.</li>
</ol>
</section>
<section id="applications-3" class="level3">
<h3 class="anchored" data-anchor-id="applications-3">Applications</h3>
<ul>
<li><strong>Seismology:</strong> Analyzing earthquake signals.</li>
<li><strong>Finance:</strong> Detecting volatility patterns in financial markets.</li>
<li><strong>Biomedical Signals:</strong> Processing EEG and ECG signals.</li>
</ul>
<section id="example-analyzing-financial-market-volatility" class="level4">
<h4 class="anchored" data-anchor-id="example-analyzing-financial-market-volatility">Example: Analyzing Financial Market Volatility</h4>
<ul>
<li><strong>Problem Statement:</strong> Detect volatility patterns in stock market data.</li>
<li><strong>Approach:</strong>
<ol type="1">
<li><strong>Collect Data:</strong> Use historical stock price data.</li>
<li><strong>Choose Wavelet:</strong> Select a suitable wavelet function.</li>
<li><strong>Compute Transform:</strong> Apply the wavelet transform to the stock price data.</li>
<li><strong>Analyze Coefficients:</strong> Identify periods of high and low volatility.</li>
</ol></li>
</ul>
<p>By understanding and applying VAR, Granger causality, and spectral analysis techniques such as Fourier transform and wavelet analysis, you can gain deeper insights into the dynamic and periodic characteristics of time series data.</p>
</section>
</section>
</section>
</section>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>