<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.47">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ravi Shankar">

<title>chapter15_introduction_to_neural_networks – Data Down To Earth</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../logo.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
<link rel="stylesheet" href="../../content.css">
<meta property="og:title" content="– Data Down To Earth">
<meta property="og:site_name" content="Data Down To Earth">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Data Down To Earth</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projects" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Projects</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-projects">    
        <li>
    <a class="dropdown-item" href="../../../projects/dsml_projects.html">
 <span class="dropdown-text">Data Science and ML Projects</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../projects/genai_projects.html">
 <span class="dropdown-text">Generative AI Projects</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-tutorials" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Tutorials</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-tutorials">    
        <li>
    <a class="dropdown-item" href="../../../topics/statistics.html">
 <span class="dropdown-text">Statistics &amp; Probability</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/machine_learning.html">
 <span class="dropdown-text">Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/de.html">
 <span class="dropdown-text">Data Engineering</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/generative_ai.html">
 <span class="dropdown-text">Generative AI</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/public_health.html">
 <span class="dropdown-text">Public Health</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../topics/product_sense.html">
 <span class="dropdown-text">Product Sense</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../blogs/blogs.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/iamrsps"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/iamravishankar/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content column-page" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
</div>



<div class="quarto-title-meta column-page">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ravi Shankar </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<div class="text-content">
<section id="chapter-15.-introduction-to-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="chapter-15.-introduction-to-neural-networks">Chapter 15. Introduction to Neural Networks</h2>
<p>Neural networks are a fundamental component of modern machine learning, inspired by the structure and function of the human brain. They consist of interconnected neurons that process data and learn to make predictions. This chapter provides an introduction to neural networks, focusing on perceptrons and multi-layer perceptrons (MLPs).</p>
<section id="perceptrons-and-multi-layer-perceptrons" class="level3">
<h3 class="anchored" data-anchor-id="perceptrons-and-multi-layer-perceptrons">15.1. Perceptrons and Multi-layer Perceptrons</h3>
<p>A perceptron is the simplest type of artificial neural network, which can be used for binary classification tasks. Multi-layer perceptrons (MLPs) extend this concept by stacking multiple layers of perceptrons, allowing the network to learn more complex functions.</p>
<section id="single-layer-perceptron" class="level4">
<h4 class="anchored" data-anchor-id="single-layer-perceptron">15.1.1. Single Layer Perceptron</h4>
<p>A single layer perceptron consists of a single neuron that takes a set of input features, applies weights and a bias, and produces an output using an activation function.</p>
<ul>
<li><p><strong>Architecture:</strong></p>
<ul>
<li><strong>Inputs:</strong> <span class="math inline">\(x_1, x_2, \ldots, x_n\)</span></li>
<li><strong>Weights:</strong> <span class="math inline">\(w_1, w_2, \ldots, w_n\)</span></li>
<li><strong>Bias:</strong> <span class="math inline">\(b\)</span></li>
<li><strong>Output:</strong> <span class="math inline">\(y\)</span></li>
</ul></li>
<li><p><strong>Mathematical Formulation:</strong> <span class="math display">\[
y = f\left(\sum_{i=1}^{n} w_i x_i + b\right)
\]</span> where <span class="math inline">\(f\)</span> is the activation function, commonly a step function or a sigmoid function.</p></li>
<li><p><strong>Learning Rule:</strong></p>
<ul>
<li>Adjust weights based on the error between the predicted output and the actual output. <span class="math display">\[
w_i \leftarrow w_i + \Delta w_i
\]</span> <span class="math display">\[
\Delta w_i = \eta (d - y) x_i
\]</span> where <span class="math inline">\(\eta\)</span> is the learning rate, <span class="math inline">\(d\)</span> is the desired output, and <span class="math inline">\(y\)</span> is the predicted output.</li>
</ul></li>
</ul>
</section>
<section id="multi-layer-perceptron-architecture" class="level4">
<h4 class="anchored" data-anchor-id="multi-layer-perceptron-architecture">15.1.2. Multi-layer Perceptron Architecture</h4>
<p>A multi-layer perceptron (MLP) consists of an input layer, one or more hidden layers, and an output layer. Each layer contains multiple neurons, and the neurons in one layer are fully connected to the neurons in the next layer.</p>
<ul>
<li><strong>Architecture:</strong>
<ul>
<li><strong>Input Layer:</strong> Takes the input features.</li>
<li><strong>Hidden Layers:</strong> Perform intermediate computations.</li>
<li><strong>Output Layer:</strong> Produces the final prediction.</li>
</ul></li>
<li><strong>Forward Propagation:</strong>
<ul>
<li>Compute the output of each layer and pass it to the next layer. <span class="math display">\[
a^{(l)} = f\left(W^{(l)} a^{(l-1)} + b^{(l)}\right)
\]</span> where <span class="math inline">\(a^{(l)}\)</span> is the activation of layer <span class="math inline">\(l\)</span>, <span class="math inline">\(W^{(l)}\)</span> is the weight matrix of layer <span class="math inline">\(l\)</span>, <span class="math inline">\(b^{(l)}\)</span> is the bias vector of layer <span class="math inline">\(l\)</span>, and <span class="math inline">\(f\)</span> is the activation function.</li>
</ul></li>
<li><strong>Backward Propagation:</strong>
<ul>
<li>Calculate the gradient of the loss function with respect to each weight and bias using the chain rule. <span class="math display">\[
\frac{\partial L}{\partial W^{(l)}} = \delta^{(l)} a^{(l-1)^T}
\]</span> <span class="math display">\[
\frac{\partial L}{\partial b^{(l)}} = \delta^{(l)}
\]</span> where <span class="math inline">\(L\)</span> is the loss function and <span class="math inline">\(\delta^{(l)}\)</span> is the error term for layer <span class="math inline">\(l\)</span>.</li>
</ul></li>
<li><strong>Weight Update:</strong>
<ul>
<li>Adjust weights and biases to minimize the loss function. <span class="math display">\[
W^{(l)} \leftarrow W^{(l)} - \eta \frac{\partial L}{\partial W^{(l)}}
\]</span> <span class="math display">\[
b^{(l)} \leftarrow b^{(l)} - \eta \frac{\partial L}{\partial b^{(l)}}
\]</span></li>
</ul></li>
</ul>
</section>
<section id="universal-approximation-theorem" class="level4">
<h4 class="anchored" data-anchor-id="universal-approximation-theorem">15.1.3. Universal Approximation Theorem</h4>
<p>The Universal Approximation Theorem states that a multi-layer perceptron with at least one hidden layer and a finite number of neurons can approximate any continuous function to any desired degree of accuracy, given appropriate weights and activation functions.</p>
<ul>
<li><strong>Theorem Statement:</strong>
<ul>
<li>For any continuous function <span class="math inline">\(f: \mathbb{R}^n \to \mathbb{R}\)</span> and any <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a neural network with a single hidden layer and a finite number of neurons that can approximate <span class="math inline">\(f\)</span> within <span class="math inline">\(\epsilon\)</span>.</li>
</ul></li>
<li><strong>Implications:</strong>
<ul>
<li>MLPs are powerful and flexible models capable of learning complex relationships in data.</li>
<li>The theorem does not specify the number of neurons required or how to find the optimal weights.</li>
</ul></li>
<li><strong>Practical Considerations:</strong>
<ul>
<li>While MLPs can theoretically approximate any function, in practice, finding the right architecture and training it effectively can be challenging.</li>
<li>Overfitting and computational complexity are common issues that need to be addressed through techniques like regularization, dropout, and efficient optimization algorithms.</li>
</ul></li>
</ul>
</section>
</section>
<section id="example-implementing-a-simple-mlp" class="level3">
<h3 class="anchored" data-anchor-id="example-implementing-a-simple-mlp">Example: Implementing a Simple MLP</h3>
<p>Suppose we have a dataset with two features and we want to classify the data into two classes using a simple MLP.</p>
<ul>
<li><p><strong>Dataset:</strong></p>
<ul>
<li>Features: <span class="math inline">\(x_1, x_2\)</span></li>
<li>Labels: <span class="math inline">\(y \in \{0, 1\}\)</span></li>
</ul></li>
<li><p><strong>MLP Architecture:</strong></p>
<ul>
<li>Input Layer: 2 neurons</li>
<li>Hidden Layer: 3 neurons with ReLU activation</li>
<li>Output Layer: 1 neuron with sigmoid activation</li>
</ul></li>
<li><p><strong>Forward Propagation:</strong> <span class="math display">\[
\text{Hidden layer output:} \ a^{(1)} = \text{ReLU}(W^{(1)} \mathbf{x} + b^{(1)})
\]</span> <span class="math display">\[
\text{Output layer:} \ \hat{y} = \sigma(W^{(2)} a^{(1)} + b^{(2)})
\]</span></p></li>
<li><p><strong>Backward Propagation:</strong></p>
<ul>
<li>Calculate gradients and update weights and biases using the backpropagation algorithm.</li>
</ul></li>
<li><p><strong>Training:</strong></p>
<ul>
<li>Use a loss function such as binary cross-entropy and an optimization algorithm like gradient descent.</li>
</ul></li>
</ul>
<p>By understanding the fundamental concepts of perceptrons and multi-layer perceptrons, we can build and train neural networks to solve a wide range of machine learning problems.</p>
</section>
<section id="activation-functions" class="level3">
<h3 class="anchored" data-anchor-id="activation-functions">15.2. Activation Functions</h3>
<p>Activation functions are crucial components in neural networks that introduce non-linearity into the model, allowing it to learn complex patterns. They determine whether a neuron should be activated or not based on the input it receives. Different activation functions have different properties and are suitable for various types of tasks.</p>
<section id="sigmoid" class="level4">
<h4 class="anchored" data-anchor-id="sigmoid">15.2.1. Sigmoid</h4>
<p>The sigmoid activation function maps the input to a value between 0 and 1, making it useful for binary classification tasks.</p>
<ul>
<li><p><strong>Mathematical Formulation:</strong> <span class="math display">\[
\sigma(x) = \frac{1}{1 + e^{-x}}
\]</span></p></li>
<li><p><strong>Properties:</strong></p>
<ul>
<li>Output range: (0, 1)</li>
<li>Smooth gradient</li>
<li>Non-linear</li>
<li>Saturates and kills gradients for very high or very low inputs</li>
</ul></li>
<li><p><strong>Advantages:</strong></p>
<ul>
<li>Good for binary classification</li>
<li>Output can be interpreted as a probability</li>
</ul></li>
<li><p><strong>Disadvantages:</strong></p>
<ul>
<li>Prone to vanishing gradient problem</li>
<li>Sigmoid outputs are not zero-centered, leading to slower convergence</li>
</ul></li>
</ul>
</section>
<section id="tanh" class="level4">
<h4 class="anchored" data-anchor-id="tanh">15.2.2. Tanh</h4>
<p>The tanh activation function maps the input to a value between -1 and 1, providing zero-centered outputs which can help in the training process.</p>
<ul>
<li><p><strong>Mathematical Formulation:</strong> <span class="math display">\[
\text{tanh}(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}
\]</span></p></li>
<li><p><strong>Properties:</strong></p>
<ul>
<li>Output range: (-1, 1)</li>
<li>Zero-centered</li>
<li>Smooth gradient</li>
<li>Non-linear</li>
</ul></li>
<li><p><strong>Advantages:</strong></p>
<ul>
<li>Helps in centering the data, leading to faster convergence</li>
<li>Stronger gradients than sigmoid</li>
</ul></li>
<li><p><strong>Disadvantages:</strong></p>
<ul>
<li>Prone to vanishing gradient problem for large input values</li>
</ul></li>
</ul>
</section>
<section id="relu-and-variants" class="level4">
<h4 class="anchored" data-anchor-id="relu-and-variants">15.2.3. ReLU and Variants</h4>
<p>ReLU (Rectified Linear Unit) and its variants are widely used activation functions due to their simplicity and effectiveness in mitigating the vanishing gradient problem.</p>
<section id="relu" class="level5">
<h5 class="anchored" data-anchor-id="relu">ReLU</h5>
<ul>
<li><p><strong>Mathematical Formulation:</strong> <span class="math display">\[
\text{ReLU}(x) = \max(0, x)
\]</span></p></li>
<li><p><strong>Properties:</strong></p>
<ul>
<li>Output range: [0, ∞)</li>
<li>Non-linear</li>
<li>Does not saturate for positive inputs</li>
</ul></li>
<li><p><strong>Advantages:</strong></p>
<ul>
<li>Efficient computation</li>
<li>Mitigates vanishing gradient problem</li>
</ul></li>
<li><p><strong>Disadvantages:</strong></p>
<ul>
<li>Prone to dying ReLU problem (neurons can get stuck during training and always output zero)</li>
</ul></li>
</ul>
</section>
<section id="leaky-relu" class="level5">
<h5 class="anchored" data-anchor-id="leaky-relu">Leaky ReLU</h5>
<p>Leaky ReLU addresses the dying ReLU problem by allowing a small gradient when the input is negative.</p>
<ul>
<li><p><strong>Mathematical Formulation:</strong> <span class="math display">\[
\text{Leaky ReLU}(x) =
\begin{cases}
x &amp; \text{if } x \ge 0 \\
\alpha x &amp; \text{if } x &lt; 0
\end{cases}
\]</span> where <span class="math inline">\(\alpha\)</span> is a small constant (e.g., 0.01).</p></li>
<li><p><strong>Properties:</strong></p>
<ul>
<li>Output range: (-∞, ∞)</li>
<li>Non-linear</li>
<li>Small positive gradient for negative inputs</li>
</ul></li>
<li><p><strong>Advantages:</strong></p>
<ul>
<li>Mitigates dying ReLU problem</li>
</ul></li>
<li><p><strong>Disadvantages:</strong></p>
<ul>
<li>Introduces an additional hyperparameter (<span class="math inline">\(\alpha\)</span>)</li>
</ul></li>
</ul>
</section>
<section id="elu-exponential-linear-unit" class="level5">
<h5 class="anchored" data-anchor-id="elu-exponential-linear-unit">ELU (Exponential Linear Unit)</h5>
<p>ELU aims to bring the mean activation close to zero, which speeds up learning.</p>
<ul>
<li><p><strong>Mathematical Formulation:</strong> <span class="math display">\[
\text{ELU}(x) =
\begin{cases}
x &amp; \text{if } x \ge 0 \\
\alpha (e^x - 1) &amp; \text{if } x &lt; 0
\end{cases}
\]</span></p></li>
<li><p><strong>Properties:</strong></p>
<ul>
<li>Output range: (-<span class="math inline">\(\alpha\)</span>, ∞)</li>
<li>Non-linear</li>
<li>Smooth gradient for negative inputs</li>
</ul></li>
<li><p><strong>Advantages:</strong></p>
<ul>
<li>Reduces computational complexity</li>
<li>Helps mitigate the vanishing gradient problem</li>
</ul></li>
<li><p><strong>Disadvantages:</strong></p>
<ul>
<li>Introduces an additional hyperparameter (<span class="math inline">\(\alpha\)</span>)</li>
</ul></li>
</ul>
</section>
<section id="selu-scaled-exponential-linear-unit" class="level5">
<h5 class="anchored" data-anchor-id="selu-scaled-exponential-linear-unit">SELU (Scaled Exponential Linear Unit)</h5>
<p>SELU is a self-normalizing activation function that automatically scales the output to maintain zero mean and unit variance.</p>
<ul>
<li><p><strong>Mathematical Formulation:</strong> <span class="math display">\[
\text{SELU}(x) = \lambda \begin{cases}
x &amp; \text{if } x \ge 0 \\
\alpha (e^x - 1) &amp; \text{if } x &lt; 0
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\alpha\)</span> are constants.</p></li>
<li><p><strong>Properties:</strong></p>
<ul>
<li>Output range: (-<span class="math inline">\(\lambda \alpha\)</span>, ∞)</li>
<li>Non-linear</li>
<li>Self-normalizing</li>
</ul></li>
<li><p><strong>Advantages:</strong></p>
<ul>
<li>Helps networks converge faster</li>
<li>Reduces the need for batch normalization</li>
</ul></li>
<li><p><strong>Disadvantages:</strong></p>
<ul>
<li>Computationally more expensive than ReLU</li>
</ul></li>
</ul>
</section>
</section>
<section id="softmax" class="level4">
<h4 class="anchored" data-anchor-id="softmax">15.2.4. Softmax</h4>
<p>The softmax activation function is typically used in the output layer of a neural network for multi-class classification problems. It converts raw scores (logits) into probabilities.</p>
<ul>
<li><p><strong>Mathematical Formulation:</strong> <span class="math display">\[
\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_{j} e^{z_j}}
\]</span> where <span class="math inline">\(z_i\)</span> is the <span class="math inline">\(i\)</span>-th element of the input vector <span class="math inline">\(z\)</span>.</p></li>
<li><p><strong>Properties:</strong></p>
<ul>
<li>Output range: (0, 1)</li>
<li>Sum of outputs: 1</li>
<li>Non-linear</li>
</ul></li>
<li><p><strong>Advantages:</strong></p>
<ul>
<li>Provides a probabilistic interpretation</li>
<li>Suitable for multi-class classification</li>
</ul></li>
<li><p><strong>Disadvantages:</strong></p>
<ul>
<li>Can be computationally expensive due to exponentiation</li>
</ul></li>
</ul>
</section>
</section>
<section id="example-using-activation-functions-in-a-neural-network" class="level3">
<h3 class="anchored" data-anchor-id="example-using-activation-functions-in-a-neural-network">Example: Using Activation Functions in a Neural Network</h3>
<p>Suppose we have a neural network for classifying handwritten digits (0-9) from the MNIST dataset. The network architecture includes an input layer, hidden layers with ReLU activation, and an output layer with softmax activation.</p>
<ul>
<li><strong>Input Layer:</strong> 784 neurons (28x28 pixel images)</li>
<li><strong>Hidden Layer 1:</strong> 128 neurons with ReLU activation <span class="math display">\[
a^{(1)} = \text{ReLU}(W^{(1)} \mathbf{x} + b^{(1)})
\]</span></li>
<li><strong>Hidden Layer 2:</strong> 64 neurons with ReLU activation <span class="math display">\[
a^{(2)} = \text{ReLU}(W^{(2)} a^{(1)} + b^{(2)})
\]</span></li>
<li><strong>Output Layer:</strong> 10 neurons with softmax activation <span class="math display">\[
\hat{y} = \text{softmax}(W^{(3)} a^{(2)} + b^{(3)})
\]</span></li>
</ul>
<p>By selecting appropriate activation functions, we can ensure that our neural network effectively learns and generalizes from the training data, achieving high performance on the classification task.</p>
</section>
</section>
<section id="loss-functions" class="level2">
<h2 class="anchored" data-anchor-id="loss-functions">15.3. Loss Functions</h2>
<p>Loss functions, also known as cost functions or objective functions, measure the discrepancy between the predicted output of the neural network and the actual target values. They guide the optimization process by providing a measure of “how well” the network is performing.</p>
<section id="mean-squared-error" class="level3">
<h3 class="anchored" data-anchor-id="mean-squared-error">15.3.1. Mean Squared Error</h3>
<p>Mean Squared Error (MSE) is commonly used for regression tasks. It calculates the average of the squares of the errors, where the error is the difference between the predicted value and the actual value.</p>
<ul>
<li><p><strong>Mathematical Formulation:</strong> <span class="math display">\[
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\]</span> where <span class="math inline">\(y_i\)</span> is the actual value, <span class="math inline">\(\hat{y}_i\)</span> is the predicted value, and <span class="math inline">\(n\)</span> is the number of samples.</p></li>
<li><p><strong>Properties:</strong></p>
<ul>
<li>Sensitive to outliers due to squaring the errors.</li>
<li>Provides a clear measure of the average magnitude of errors.</li>
</ul></li>
<li><p><strong>Applications:</strong></p>
<ul>
<li>Regression problems</li>
<li>Neural networks for continuous output prediction</li>
</ul></li>
</ul>
</section>
<section id="cross-entropy" class="level3">
<h3 class="anchored" data-anchor-id="cross-entropy">15.3.2. Cross-entropy</h3>
<p>Cross-entropy loss is used for classification tasks, particularly when dealing with probabilities. It measures the performance of a classification model whose output is a probability value between 0 and 1.</p>
<ul>
<li><p><strong>Binary Cross-entropy:</strong> <span class="math display">\[
\text{Binary Cross-entropy} = - \frac{1}{n} \sum_{i=1}^{n} \left[ y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right]
\]</span> where <span class="math inline">\(y_i\)</span> is the actual binary label and <span class="math inline">\(\hat{y}_i\)</span> is the predicted probability.</p></li>
<li><p><strong>Categorical Cross-entropy:</strong> <span class="math display">\[
\text{Categorical Cross-entropy} = - \sum_{i=1}^{n} \sum_{j=1}^{k} y_{ij} \log(\hat{y}_{ij})
\]</span> where <span class="math inline">\(y_{ij}\)</span> is the actual binary indicator (0 or 1) if class label <span class="math inline">\(j\)</span> is the correct classification for observation <span class="math inline">\(i\)</span>, and <span class="math inline">\(\hat{y}_{ij}\)</span> is the predicted probability.</p></li>
<li><p><strong>Properties:</strong></p>
<ul>
<li>Suitable for probabilistic outputs.</li>
<li>More robust to outliers compared to MSE.</li>
</ul></li>
<li><p><strong>Applications:</strong></p>
<ul>
<li>Binary classification</li>
<li>Multi-class classification</li>
</ul></li>
</ul>
</section>
<section id="hinge-loss" class="level3">
<h3 class="anchored" data-anchor-id="hinge-loss">15.3.3. Hinge Loss</h3>
<p>Hinge loss is primarily used for training classifiers such as Support Vector Machines (SVMs). It is designed for maximum-margin classification.</p>
<ul>
<li><p><strong>Mathematical Formulation:</strong> <span class="math display">\[
\text{Hinge Loss} = \sum_{i=1}^{n} \max(0, 1 - y_i \hat{y}_i)
\]</span> where <span class="math inline">\(y_i\)</span> is the actual label (typically -1 or 1), and <span class="math inline">\(\hat{y}_i\)</span> is the predicted output.</p></li>
<li><p><strong>Properties:</strong></p>
<ul>
<li>Encourages the correct classification with a margin.</li>
<li>Only penalizes predictions that are on the wrong side of the margin.</li>
</ul></li>
<li><p><strong>Applications:</strong></p>
<ul>
<li>Support Vector Machines</li>
<li>Binary classification with margin</li>
</ul></li>
</ul>
</section>
</section>
<section id="backpropagation" class="level2">
<h2 class="anchored" data-anchor-id="backpropagation">15.4. Backpropagation</h2>
<p>Backpropagation is the core algorithm used for training neural networks. It involves computing the gradient of the loss function with respect to each weight by the chain rule, then updating the weights to minimize the loss.</p>
<section id="chain-rule" class="level3">
<h3 class="anchored" data-anchor-id="chain-rule">15.4.1. Chain Rule</h3>
<p>The chain rule is a fundamental concept in calculus used to compute the derivative of the composition of two or more functions. In the context of neural networks, it allows us to propagate the error backward through the network.</p>
<ul>
<li><p><strong>Mathematical Formulation:</strong> If <span class="math inline">\(z = f(y)\)</span> and <span class="math inline">\(y = g(x)\)</span>, then the derivative of <span class="math inline">\(z\)</span> with respect to <span class="math inline">\(x\)</span> is: <span class="math display">\[
\frac{dz}{dx} = \frac{dz}{dy} \cdot \frac{dy}{dx}
\]</span></p></li>
<li><p><strong>Application in Neural Networks:</strong></p>
<ul>
<li>The chain rule is applied to calculate the gradient of the loss function with respect to each weight in the network, layer by layer, from the output layer back to the input layer.</li>
</ul></li>
</ul>
</section>
<section id="gradient-descent-in-neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="gradient-descent-in-neural-networks">15.4.2. Gradient Descent in Neural Networks</h3>
<p>Gradient descent is an optimization algorithm used to minimize the loss function by iteratively updating the network’s weights in the direction of the negative gradient.</p>
<ul>
<li><p><strong>Mathematical Formulation:</strong> <span class="math display">\[
w \leftarrow w - \eta \frac{\partial L}{\partial w}
\]</span> where <span class="math inline">\(w\)</span> represents the weights, <span class="math inline">\(\eta\)</span> is the learning rate, and <span class="math inline">\(\frac{\partial L}{\partial w}\)</span> is the gradient of the loss function with respect to the weights.</p></li>
<li><p><strong>Variants:</strong></p>
<ul>
<li><strong>Stochastic Gradient Descent (SGD):</strong> Updates weights using a single training example at a time.</li>
<li><strong>Mini-batch Gradient Descent:</strong> Updates weights using a small batch of training examples.</li>
<li><strong>Batch Gradient Descent:</strong> Updates weights using the entire training dataset.</li>
</ul></li>
</ul>
</section>
<section id="vanishing-and-exploding-gradients" class="level3">
<h3 class="anchored" data-anchor-id="vanishing-and-exploding-gradients">15.4.3. Vanishing and Exploding Gradients</h3>
<p>Vanishing and exploding gradients are problems that can occur during the training of deep neural networks.</p>
<section id="vanishing-gradients" class="level4">
<h4 class="anchored" data-anchor-id="vanishing-gradients">Vanishing Gradients</h4>
<ul>
<li><strong>Definition:</strong>
<ul>
<li>Occurs when gradients become very small during backpropagation, causing the weights to update very slowly and the network to learn very slowly or not at all.</li>
</ul></li>
<li><strong>Causes:</strong>
<ul>
<li>Activation functions like sigmoid and tanh that squash input into small ranges.</li>
<li>Deep networks with many layers.</li>
</ul></li>
<li><strong>Solutions:</strong>
<ul>
<li>Use activation functions like ReLU that do not saturate for positive values.</li>
<li>Use techniques like batch normalization.</li>
<li>Implement careful weight initialization methods.</li>
</ul></li>
</ul>
</section>
<section id="exploding-gradients" class="level4">
<h4 class="anchored" data-anchor-id="exploding-gradients">Exploding Gradients</h4>
<ul>
<li><strong>Definition:</strong>
<ul>
<li>Occurs when gradients become very large during backpropagation, causing the weights to update too much and the network parameters to become unstable.</li>
</ul></li>
<li><strong>Causes:</strong>
<ul>
<li>Large weight values.</li>
<li>Deep networks with many layers.</li>
</ul></li>
<li><strong>Solutions:</strong>
<ul>
<li>Gradient clipping to limit the size of the gradients.</li>
<li>Use smaller learning rates.</li>
<li>Implement careful weight initialization methods.</li>
</ul></li>
</ul>
</section>
</section>
<section id="example-training-a-neural-network" class="level3">
<h3 class="anchored" data-anchor-id="example-training-a-neural-network">Example: Training a Neural Network</h3>
<p>Suppose we have a neural network for binary classification with the following architecture:</p>
<ul>
<li><p><strong>Input Layer:</strong> 10 neurons</p></li>
<li><p><strong>Hidden Layer 1:</strong> 5 neurons with ReLU activation</p></li>
<li><p><strong>Hidden Layer 2:</strong> 3 neurons with ReLU activation</p></li>
<li><p><strong>Output Layer:</strong> 1 neuron with sigmoid activation</p></li>
<li><p><strong>Loss Function:</strong></p>
<ul>
<li>Binary cross-entropy</li>
</ul></li>
<li><p><strong>Training Process:</strong></p>
<ol type="1">
<li><strong>Forward Pass:</strong>
<ul>
<li>Compute activations for each layer.</li>
</ul></li>
<li><strong>Loss Calculation:</strong>
<ul>
<li>Compute the binary cross-entropy loss.</li>
</ul></li>
<li><strong>Backward Pass:</strong>
<ul>
<li>Use backpropagation to calculate gradients.</li>
<li>Apply the chain rule to propagate the error backward.</li>
</ul></li>
<li><strong>Weight Update:</strong>
<ul>
<li>Use gradient descent to update the weights.</li>
</ul></li>
</ol></li>
</ul>
<p>By understanding loss functions, backpropagation, and the challenges of vanishing and exploding gradients, we can effectively train neural networks to achieve high performance on a variety of tasks.</p>
</section>
</section>
<section id="optimization-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="optimization-algorithms">15.5. Optimization Algorithms</h2>
<p>Optimization algorithms are critical for training neural networks. They adjust the weights of the network to minimize the loss function. Different optimization algorithms have different strategies for updating weights, each with its advantages and challenges.</p>
<section id="stochastic-gradient-descent-sgd" class="level3">
<h3 class="anchored" data-anchor-id="stochastic-gradient-descent-sgd">15.5.1. Stochastic Gradient Descent (SGD)</h3>
<p>Stochastic Gradient Descent (SGD) is an optimization algorithm that updates the weights using the gradient of the loss function evaluated on a single training example.</p>
<section id="methodology" class="level4">
<h4 class="anchored" data-anchor-id="methodology">Methodology</h4>
<ol type="1">
<li><strong>Initialize Weights:</strong> Start with random values for the weights.</li>
<li><strong>Iterate over Training Examples:</strong>
<ul>
<li>For each training example <span class="math inline">\((x_i, y_i)\)</span>:
<ol type="1">
<li>Compute the gradient of the loss function with respect to the weights: <span class="math inline">\(\nabla L(w; x_i, y_i)\)</span>.</li>
<li>Update the weights: <span class="math inline">\(w \leftarrow w - \eta \nabla L(w; x_i, y_i)\)</span>, where <span class="math inline">\(\eta\)</span> is the learning rate.</li>
</ol></li>
</ul></li>
</ol>
</section>
<section id="advantages-and-disadvantages" class="level4">
<h4 class="anchored" data-anchor-id="advantages-and-disadvantages">Advantages and Disadvantages</h4>
<ul>
<li><strong>Advantages:</strong>
<ul>
<li>Faster iterations since it processes one example at a time.</li>
<li>Introduces noise that can help escape local minima.</li>
</ul></li>
<li><strong>Disadvantages:</strong>
<ul>
<li>High variance in updates can lead to convergence issues.</li>
<li>Requires careful tuning of the learning rate.</li>
</ul></li>
</ul>
</section>
</section>
<section id="mini-batch-gradient-descent" class="level3">
<h3 class="anchored" data-anchor-id="mini-batch-gradient-descent">15.5.2. Mini-batch Gradient Descent</h3>
<p>Mini-batch Gradient Descent combines the advantages of both SGD and Batch Gradient Descent. It updates the weights using the gradient computed on a small batch of training examples.</p>
<section id="methodology-1" class="level4">
<h4 class="anchored" data-anchor-id="methodology-1">Methodology</h4>
<ol type="1">
<li><strong>Initialize Weights:</strong> Start with random values for the weights.</li>
<li><strong>Iterate over Mini-batches:</strong>
<ul>
<li>For each mini-batch of training examples <span class="math inline">\((x_i, y_i)_{i=1}^{m}\)</span>:
<ol type="1">
<li>Compute the gradient of the loss function with respect to the weights: <span class="math inline">\(\nabla L(w; (x_i, y_i)_{i=1}^{m})\)</span>.</li>
<li>Update the weights: <span class="math inline">\(w \leftarrow w - \eta \nabla L(w; (x_i, y_i)_{i=1}^{m})\)</span>, where <span class="math inline">\(\eta\)</span> is the learning rate.</li>
</ol></li>
</ul></li>
</ol>
</section>
<section id="advantages-and-disadvantages-1" class="level4">
<h4 class="anchored" data-anchor-id="advantages-and-disadvantages-1">Advantages and Disadvantages</h4>
<ul>
<li><strong>Advantages:</strong>
<ul>
<li>Reduces the variance of the parameter updates.</li>
<li>Improves computational efficiency through vectorized operations.</li>
</ul></li>
<li><strong>Disadvantages:</strong>
<ul>
<li>Requires selection of mini-batch size.</li>
<li>Still needs careful tuning of the learning rate.</li>
</ul></li>
</ul>
</section>
</section>
<section id="momentum" class="level3">
<h3 class="anchored" data-anchor-id="momentum">15.5.3. Momentum</h3>
<p>Momentum is an optimization technique that helps accelerate SGD by considering the past gradients to smooth out the updates.</p>
<section id="methodology-2" class="level4">
<h4 class="anchored" data-anchor-id="methodology-2">Methodology</h4>
<ol type="1">
<li><strong>Initialize Weights and Velocity:</strong> Start with random values for the weights and initialize the velocity <span class="math inline">\(v = 0\)</span>.</li>
<li><strong>Iterate over Mini-batches:</strong>
<ul>
<li>For each mini-batch of training examples <span class="math inline">\((x_i, y_i)_{i=1}^{m}\)</span>:
<ol type="1">
<li>Compute the gradient of the loss function with respect to the weights: <span class="math inline">\(\nabla L(w; (x_i, y_i)_{i=1}^{m})\)</span>.</li>
<li>Update the velocity: <span class="math inline">\(v \leftarrow \beta v + \eta \nabla L(w; (x_i, y_i)_{i=1}^{m})\)</span>, where <span class="math inline">\(\beta\)</span> is the momentum term.</li>
<li>Update the weights: <span class="math inline">\(w \leftarrow w - v\)</span>.</li>
</ol></li>
</ul></li>
</ol>
</section>
<section id="advantages-and-disadvantages-2" class="level4">
<h4 class="anchored" data-anchor-id="advantages-and-disadvantages-2">Advantages and Disadvantages</h4>
<ul>
<li><strong>Advantages:</strong>
<ul>
<li>Helps accelerate convergence and reduces oscillations.</li>
<li>Smoothens the updates by considering the past gradients.</li>
</ul></li>
<li><strong>Disadvantages:</strong>
<ul>
<li>Requires tuning of the momentum term <span class="math inline">\(\beta\)</span>.</li>
</ul></li>
</ul>
</section>
</section>
<section id="rmsprop" class="level3">
<h3 class="anchored" data-anchor-id="rmsprop">15.5.4. RMSprop</h3>
<p>RMSprop (Root Mean Square Propagation) is an optimization algorithm designed to adapt the learning rate for each parameter individually, scaling it based on the moving average of the squared gradients.</p>
<section id="methodology-3" class="level4">
<h4 class="anchored" data-anchor-id="methodology-3">Methodology</h4>
<ol type="1">
<li><strong>Initialize Weights and Squared Gradient Accumulator:</strong> Start with random values for the weights and initialize <span class="math inline">\(E[g^2] = 0\)</span>.</li>
<li><strong>Iterate over Mini-batches:</strong>
<ul>
<li>For each mini-batch of training examples <span class="math inline">\((x_i, y_i)_{i=1}^{m}\)</span>:
<ol type="1">
<li>Compute the gradient of the loss function with respect to the weights: <span class="math inline">\(\nabla L(w; (x_i, y_i)_{i=1}^{m})\)</span>.</li>
<li>Update the squared gradient accumulator: <span class="math inline">\(E[g^2] \leftarrow \beta E[g^2] + (1 - \beta) (\nabla L(w; (x_i, y_i)_{i=1}^{m}))^2\)</span>, where <span class="math inline">\(\beta\)</span> is the decay rate.</li>
<li>Update the weights: <span class="math inline">\(w \leftarrow w - \frac{\eta}{\sqrt{E[g^2]} + \epsilon} \nabla L(w; (x_i, y_i)_{i=1}^{m})\)</span>, where <span class="math inline">\(\epsilon\)</span> is a small constant to prevent division by zero.</li>
</ol></li>
</ul></li>
</ol>
</section>
<section id="advantages-and-disadvantages-3" class="level4">
<h4 class="anchored" data-anchor-id="advantages-and-disadvantages-3">Advantages and Disadvantages</h4>
<ul>
<li><strong>Advantages:</strong>
<ul>
<li>Adapts learning rate for each parameter individually.</li>
<li>Prevents the learning rate from becoming too small.</li>
</ul></li>
<li><strong>Disadvantages:</strong>
<ul>
<li>Requires tuning of the decay rate <span class="math inline">\(\beta\)</span> and the learning rate <span class="math inline">\(\eta\)</span>.</li>
</ul></li>
</ul>
</section>
</section>
<section id="adam-optimizer" class="level3">
<h3 class="anchored" data-anchor-id="adam-optimizer">15.5.5. Adam Optimizer</h3>
<p>Adam (Adaptive Moment Estimation) combines the benefits of both RMSprop and Momentum by computing adaptive learning rates for each parameter. It also maintains moving averages of both the gradients and their squared values.</p>
<section id="methodology-4" class="level4">
<h4 class="anchored" data-anchor-id="methodology-4">Methodology</h4>
<ol type="1">
<li><strong>Initialize Weights, First Moment <span class="math inline">\(m\)</span>, and Second Moment <span class="math inline">\(v\)</span>:</strong>
<ul>
<li>Start with random values for the weights, initialize <span class="math inline">\(m = 0\)</span> and <span class="math inline">\(v = 0\)</span>.</li>
</ul></li>
<li><strong>Iterate over Mini-batches:</strong>
<ul>
<li>For each mini-batch of training examples <span class="math inline">\((x_i, y_i)_{i=1}^{m}\)</span>:
<ol type="1">
<li>Compute the gradient of the loss function with respect to the weights: <span class="math inline">\(\nabla L(w; (x_i, y_i)_{i=1}^{m})\)</span>.</li>
<li>Update the first moment estimate: <span class="math inline">\(m \leftarrow \beta_1 m + (1 - \beta_1) \nabla L(w; (x_i, y_i)_{i=1}^{m})\)</span>, where <span class="math inline">\(\beta_1\)</span> is the decay rate for the first moment.</li>
<li>Update the second moment estimate: <span class="math inline">\(v \leftarrow \beta_2 v + (1 - \beta_2) (\nabla L(w; (x_i, y_i)_{i=1}^{m}))^2\)</span>, where <span class="math inline">\(\beta_2\)</span> is the decay rate for the second moment.</li>
<li>Compute bias-corrected first and second moment estimates: <span class="math inline">\(\hat{m} = \frac{m}{1 - \beta_1^t}\)</span> and <span class="math inline">\(\hat{v} = \frac{v}{1 - \beta_2^t}\)</span>.</li>
<li>Update the weights: <span class="math inline">\(w \leftarrow w - \frac{\eta}{\sqrt{\hat{v}} + \epsilon} \hat{m}\)</span>, where <span class="math inline">\(\epsilon\)</span> is a small constant to prevent division by zero.</li>
</ol></li>
</ul></li>
</ol>
</section>
<section id="advantages-and-disadvantages-4" class="level4">
<h4 class="anchored" data-anchor-id="advantages-and-disadvantages-4">Advantages and Disadvantages</h4>
<ul>
<li><strong>Advantages:</strong>
<ul>
<li>Combines the benefits of both Momentum and RMSprop.</li>
<li>Adapts learning rates for each parameter.</li>
<li>Works well with sparse gradients and large datasets.</li>
</ul></li>
<li><strong>Disadvantages:</strong>
<ul>
<li>Requires tuning of multiple hyperparameters (<span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span>, <span class="math inline">\(\eta\)</span>, and <span class="math inline">\(\epsilon\)</span>).</li>
<li>May not always generalize as well as simpler methods on some problems.</li>
</ul></li>
</ul>
</section>
</section>
<section id="example-training-with-different-optimization-algorithms" class="level3">
<h3 class="anchored" data-anchor-id="example-training-with-different-optimization-algorithms">Example: Training with Different Optimization Algorithms</h3>
<p>Suppose we have a neural network for classifying images from the CIFAR-10 dataset. The network architecture includes convolutional layers, pooling layers, and fully connected layers. We will compare the performance of different optimization algorithms during training.</p>
<ul>
<li><strong>Dataset:</strong> CIFAR-10, with 60,000 32x32 color images in 10 classes.</li>
<li><strong>Network Architecture:</strong>
<ul>
<li>Convolutional Layer 1: 32 filters, 3x3 kernel, ReLU activation</li>
<li>Max Pooling Layer 1: 2x2 pool size</li>
<li>Convolutional Layer 2: 64 filters, 3x3 kernel, ReLU activation</li>
<li>Max Pooling Layer 2: 2x2 pool size</li>
<li>Fully Connected Layer: 512 neurons, ReLU activation</li>
<li>Output Layer: 10 neurons, softmax activation</li>
</ul></li>
<li><strong>Training Process:</strong>
<ul>
<li>Use cross-entropy loss for classification.</li>
<li>Train the network with different optimization algorithms: SGD, Mini-batch Gradient Descent, Momentum, RMSprop, and Adam.</li>
<li>Evaluate the training and validation accuracy and loss for each optimizer.</li>
</ul></li>
</ul>
<p>By understanding and applying different optimization algorithms, we can effectively train neural networks to achieve high performance on various tasks, selecting the most appropriate optimizer based on the specific problem and dataset characteristics.</p>
</section>
</section>
<section id="regularization-in-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="regularization-in-neural-networks">15.6. Regularization in Neural Networks</h2>
<p>Regularization techniques are essential for improving the generalization ability of neural networks by preventing overfitting. Overfitting occurs when a model learns the training data too well, including the noise, and performs poorly on unseen data. Regularization introduces constraints or modifications to the learning algorithm to ensure that the model generalizes better to new data.</p>
<section id="l1-and-l2-regularization" class="level3">
<h3 class="anchored" data-anchor-id="l1-and-l2-regularization">15.6.1. L1 and L2 Regularization</h3>
<p>L1 and L2 regularization are techniques that add a penalty to the loss function to constrain the magnitude of the model parameters.</p>
<section id="l1-regularization-lasso" class="level4">
<h4 class="anchored" data-anchor-id="l1-regularization-lasso">L1 Regularization (Lasso)</h4>
<p>L1 regularization adds the absolute value of the coefficients as a penalty term to the loss function. It encourages sparsity in the model parameters, meaning it can shrink some parameters to zero, effectively performing feature selection.</p>
<ul>
<li><p><strong>Mathematical Formulation:</strong> <span class="math display">\[
L = L_0 + \lambda \sum_{i=1}^{n} |w_i|
\]</span> where <span class="math inline">\(L_0\)</span> is the original loss (e.g., MSE or cross-entropy), <span class="math inline">\(w_i\)</span> are the model weights, and <span class="math inline">\(\lambda\)</span> is the regularization parameter controlling the strength of the penalty.</p></li>
<li><p><strong>Advantages:</strong></p>
<ul>
<li>Encourages sparsity, leading to simpler models.</li>
<li>Can perform feature selection.</li>
</ul></li>
<li><p><strong>Disadvantages:</strong></p>
<ul>
<li>May be less stable than L2 regularization.</li>
</ul></li>
</ul>
</section>
<section id="l2-regularization-ridge" class="level4">
<h4 class="anchored" data-anchor-id="l2-regularization-ridge">L2 Regularization (Ridge)</h4>
<p>L2 regularization adds the squared value of the coefficients as a penalty term to the loss function. It discourages large weights, promoting weight values to be small but not exactly zero.</p>
<ul>
<li><p><strong>Mathematical Formulation:</strong> <span class="math display">\[
L = L_0 + \lambda \sum_{i=1}^{n} w_i^2
\]</span></p></li>
<li><p><strong>Advantages:</strong></p>
<ul>
<li>Encourages smaller weights, leading to more stable models.</li>
<li>Does not eliminate features completely.</li>
</ul></li>
<li><p><strong>Disadvantages:</strong></p>
<ul>
<li>Does not perform feature selection.</li>
</ul></li>
</ul>
</section>
</section>
<section id="dropout" class="level3">
<h3 class="anchored" data-anchor-id="dropout">15.6.2. Dropout</h3>
<p>Dropout is a regularization technique that randomly drops a fraction of the neurons during training, forcing the network to learn redundant representations and preventing co-adaptation of neurons.</p>
<ul>
<li><strong>Methodology:</strong>
<ul>
<li>During each training iteration, each neuron is retained with a probability <span class="math inline">\(p\)</span> (e.g., <span class="math inline">\(p = 0.5\)</span>) and dropped with a probability <span class="math inline">\(1 - p\)</span>.</li>
<li>Dropped neurons do not contribute to the forward pass and do not receive weight updates during backpropagation.</li>
</ul></li>
<li><strong>Advantages:</strong>
<ul>
<li>Reduces overfitting by preventing co-adaptation.</li>
<li>Encourages the network to learn more robust features.</li>
</ul></li>
<li><strong>Disadvantages:</strong>
<ul>
<li>Increases training time.</li>
<li>Requires tuning of the dropout rate.</li>
</ul></li>
<li><strong>Example:</strong>
<ul>
<li>If a network has a hidden layer with 100 neurons and a dropout rate of 0.5, during each training iteration, approximately 50 neurons will be dropped out.</li>
</ul></li>
</ul>
</section>
<section id="batch-normalization" class="level3">
<h3 class="anchored" data-anchor-id="batch-normalization">15.6.3. Batch Normalization</h3>
<p>Batch normalization normalizes the inputs of each layer to have zero mean and unit variance within each mini-batch. This helps stabilize and accelerate training by reducing the internal covariate shift.</p>
<ul>
<li><strong>Methodology:</strong>
<ol type="1">
<li>Compute the mean and variance of the mini-batch.</li>
<li>Normalize the inputs: <span class="math inline">\(\hat{x} = \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}}\)</span>, where <span class="math inline">\(\mu\)</span> is the mini-batch mean, <span class="math inline">\(\sigma^2\)</span> is the mini-batch variance, and <span class="math inline">\(\epsilon\)</span> is a small constant for numerical stability.</li>
<li>Scale and shift the normalized inputs using learnable parameters <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\beta\)</span>: <span class="math inline">\(y = \gamma \hat{x} + \beta\)</span>.</li>
</ol></li>
<li><strong>Advantages:</strong>
<ul>
<li>Stabilizes and accelerates training.</li>
<li>Allows for higher learning rates.</li>
<li>Acts as a regularizer, reducing the need for other forms of regularization like dropout.</li>
</ul></li>
<li><strong>Disadvantages:</strong>
<ul>
<li>Adds complexity to the model.</li>
<li>Introduces additional parameters to learn.</li>
</ul></li>
</ul>
</section>
<section id="early-stopping" class="level3">
<h3 class="anchored" data-anchor-id="early-stopping">15.6.4. Early Stopping</h3>
<p>Early stopping is a regularization technique that monitors the model’s performance on a validation set and stops training when the performance starts to deteriorate, indicating potential overfitting.</p>
<ul>
<li><strong>Methodology:</strong>
<ol type="1">
<li>Split the data into training and validation sets.</li>
<li>During training, monitor the validation loss after each epoch.</li>
<li>Stop training when the validation loss stops improving for a specified number of epochs (patience).</li>
</ol></li>
<li><strong>Advantages:</strong>
<ul>
<li>Simple and effective way to prevent overfitting.</li>
<li>Does not require modifying the model architecture.</li>
</ul></li>
<li><strong>Disadvantages:</strong>
<ul>
<li>Requires a validation set, reducing the amount of data available for training.</li>
<li>The model may stop training too early, missing out on further improvements.</li>
</ul></li>
</ul>
</section>
<section id="example-applying-regularization-techniques" class="level3">
<h3 class="anchored" data-anchor-id="example-applying-regularization-techniques">Example: Applying Regularization Techniques</h3>
<p>Suppose we have a neural network for predicting house prices. The network architecture includes several hidden layers with ReLU activation.</p>
<ul>
<li><strong>Network Architecture:</strong>
<ul>
<li>Input Layer: Features like square footage, number of rooms, etc.</li>
<li>Hidden Layer 1: 128 neurons, ReLU activation</li>
<li>Hidden Layer 2: 64 neurons, ReLU activation</li>
<li>Output Layer: 1 neuron, linear activation</li>
</ul></li>
<li><strong>Regularization Techniques:</strong>
<ul>
<li><strong>L2 Regularization:</strong>
<ul>
<li>Add L2 penalty to the loss function.</li>
</ul></li>
<li><strong>Dropout:</strong>
<ul>
<li>Apply dropout with a rate of 0.5 after each hidden layer.</li>
</ul></li>
<li><strong>Batch Normalization:</strong>
<ul>
<li>Apply batch normalization after each hidden layer before the activation function.</li>
</ul></li>
<li><strong>Early Stopping:</strong>
<ul>
<li>Monitor validation loss and stop training if it does not improve for 10 consecutive epochs.</li>
</ul></li>
</ul></li>
</ul>
<p>By combining these regularization techniques, we can improve the generalization performance of the neural network, reducing the risk of overfitting and ensuring better performance on unseen data.</p>
</section>
</section>
<section id="weight-initialization-techniques" class="level2">
<h2 class="anchored" data-anchor-id="weight-initialization-techniques">15.7. Weight Initialization Techniques</h2>
<p>Proper weight initialization is crucial for training neural networks. Poor initialization can lead to slow convergence or getting stuck in local minima. The goal is to set the initial weights in a way that maintains the variance of activations and gradients across layers, ensuring efficient training.</p>
<section id="xavierglorot-initialization" class="level3">
<h3 class="anchored" data-anchor-id="xavierglorot-initialization">15.7.1. Xavier/Glorot Initialization</h3>
<p>Xavier initialization, also known as Glorot initialization, is designed to keep the scale of the gradients roughly the same across all layers. It works well with activation functions like sigmoid and tanh.</p>
<ul>
<li><p><strong>Mathematical Formulation:</strong> <span class="math display">\[
W \sim \mathcal{N}\left(0, \frac{2}{n_{\text{in}} + n_{\text{out}}}\right)
\]</span> where <span class="math inline">\(W\)</span> are the weights, <span class="math inline">\(\mathcal{N}(0, \sigma^2)\)</span> denotes a Gaussian distribution with mean 0 and variance <span class="math inline">\(\sigma^2\)</span>, <span class="math inline">\(n_{\text{in}}\)</span> is the number of input units, and <span class="math inline">\(n_{\text{out}}\)</span> is the number of output units.</p></li>
<li><p><strong>Advantages:</strong></p>
<ul>
<li>Balances the variance of activations across layers.</li>
<li>Helps in maintaining gradients’ variance, preventing the vanishing or exploding gradient problem.</li>
</ul></li>
<li><p><strong>Example:</strong></p>
<ul>
<li>For a layer with 256 input neurons and 128 output neurons, the weights would be initialized from a Gaussian distribution with mean 0 and variance <span class="math inline">\(\frac{2}{256 + 128} = \frac{2}{384} = \frac{1}{192}\)</span>.</li>
</ul></li>
</ul>
</section>
<section id="he-initialization" class="level3">
<h3 class="anchored" data-anchor-id="he-initialization">15.7.2. He Initialization</h3>
<p>He initialization, introduced by Kaiming He et al., is specifically designed for layers with ReLU activation functions. It scales the weights more aggressively than Xavier initialization to account for the properties of ReLU.</p>
<ul>
<li><p><strong>Mathematical Formulation:</strong> <span class="math display">\[
W \sim \mathcal{N}\left(0, \frac{2}{n_{\text{in}}}\right)
\]</span></p></li>
<li><p><strong>Advantages:</strong></p>
<ul>
<li>Provides a better initialization for ReLU and its variants (Leaky ReLU, PReLU).</li>
<li>Helps in maintaining a healthy variance in the forward pass, especially in deep networks.</li>
</ul></li>
<li><p><strong>Example:</strong></p>
<ul>
<li>For a layer with 256 input neurons, the weights would be initialized from a Gaussian distribution with mean 0 and variance <span class="math inline">\(\frac{2}{256} = \frac{1}{128}\)</span>.</li>
</ul></li>
</ul>
</section>
</section>
<section id="neural-network-architectures" class="level2">
<h2 class="anchored" data-anchor-id="neural-network-architectures">15.8. Neural Network Architectures</h2>
<p>Neural networks come in various architectures, each suited for different types of data and tasks. The three fundamental architectures are Feedforward Neural Networks (FNNs), Convolutional Neural Networks (CNNs), and Recurrent Neural Networks (RNNs).</p>
<section id="feedforward-neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="feedforward-neural-networks">15.8.1. Feedforward Neural Networks</h3>
<p>Feedforward Neural Networks (FNNs), also known as Multi-Layer Perceptrons (MLPs), are the simplest type of artificial neural networks. They consist of an input layer, one or more hidden layers, and an output layer, where connections between nodes do not form cycles.</p>
<section id="characteristics" class="level4">
<h4 class="anchored" data-anchor-id="characteristics">Characteristics</h4>
<ul>
<li><strong>Architecture:</strong>
<ul>
<li>Layers are fully connected.</li>
<li>Information moves in one direction: from input to output.</li>
</ul></li>
<li><strong>Activation Functions:</strong>
<ul>
<li>Typically use ReLU, sigmoid, or tanh.</li>
</ul></li>
<li><strong>Training:</strong>
<ul>
<li>Uses backpropagation for weight updates.</li>
<li>Optimized using gradient descent and its variants.</li>
</ul></li>
</ul>
</section>
<section id="applications" class="level4">
<h4 class="anchored" data-anchor-id="applications">Applications</h4>
<ul>
<li>Suitable for structured data like tabular datasets.</li>
<li>Commonly used in classification and regression tasks.</li>
</ul>
</section>
</section>
<section id="convolutional-neural-networks-basics" class="level3">
<h3 class="anchored" data-anchor-id="convolutional-neural-networks-basics">15.8.2. Convolutional Neural Networks (Basics)</h3>
<p>Convolutional Neural Networks (CNNs) are designed to process data with a grid-like topology, such as images. They leverage spatial hierarchies by applying convolutional layers that reduce the number of parameters and computational complexity.</p>
<section id="characteristics-1" class="level4">
<h4 class="anchored" data-anchor-id="characteristics-1">Characteristics</h4>
<ul>
<li><strong>Architecture:</strong>
<ul>
<li>Consists of convolutional layers, pooling layers, and fully connected layers.</li>
<li>Convolutional layers apply filters to extract features.</li>
<li>Pooling layers reduce dimensionality by down-sampling.</li>
<li>Fully connected layers make final predictions.</li>
</ul></li>
<li><strong>Activation Functions:</strong>
<ul>
<li>Typically use ReLU in convolutional layers.</li>
</ul></li>
<li><strong>Training:</strong>
<ul>
<li>Uses backpropagation.</li>
<li>Optimized using gradient descent and its variants.</li>
</ul></li>
</ul>
</section>
<section id="applications-1" class="level4">
<h4 class="anchored" data-anchor-id="applications-1">Applications</h4>
<ul>
<li>Image classification (e.g., MNIST, CIFAR-10).</li>
<li>Object detection and segmentation.</li>
<li>Image generation (e.g., GANs).</li>
</ul>
</section>
</section>
<section id="recurrent-neural-networks-basics" class="level3">
<h3 class="anchored" data-anchor-id="recurrent-neural-networks-basics">15.8.3. Recurrent Neural Networks (Basics)</h3>
<p>Recurrent Neural Networks (RNNs) are designed for sequential data. They maintain a hidden state that captures information from previous time steps, making them suitable for tasks where context is important.</p>
<section id="characteristics-2" class="level4">
<h4 class="anchored" data-anchor-id="characteristics-2">Characteristics</h4>
<ul>
<li><strong>Architecture:</strong>
<ul>
<li>Contains loops that allow information to persist.</li>
<li>Each neuron receives input from the current time step and the hidden state from the previous time step.</li>
</ul></li>
<li><strong>Activation Functions:</strong>
<ul>
<li>Typically use tanh or ReLU.</li>
</ul></li>
<li><strong>Training:</strong>
<ul>
<li>Uses backpropagation through time (BPTT) to handle sequences.</li>
<li>Optimized using gradient descent and its variants.</li>
</ul></li>
</ul>
</section>
<section id="variants" class="level4">
<h4 class="anchored" data-anchor-id="variants">Variants</h4>
<ul>
<li><strong>LSTM (Long Short-Term Memory):</strong>
<ul>
<li>Designed to combat the vanishing gradient problem by introducing gates that regulate the flow of information.</li>
</ul></li>
<li><strong>GRU (Gated Recurrent Unit):</strong>
<ul>
<li>Simplified version of LSTM with fewer parameters.</li>
</ul></li>
</ul>
</section>
<section id="applications-2" class="level4">
<h4 class="anchored" data-anchor-id="applications-2">Applications</h4>
<ul>
<li>Natural language processing (NLP) tasks (e.g., language modeling, translation).</li>
<li>Time series forecasting.</li>
<li>Speech recognition.</li>
</ul>
</section>
</section>
<section id="example-implementing-different-neural-network-architectures" class="level3">
<h3 class="anchored" data-anchor-id="example-implementing-different-neural-network-architectures">Example: Implementing Different Neural Network Architectures</h3>
<section id="feedforward-neural-network-fnn" class="level4">
<h4 class="anchored" data-anchor-id="feedforward-neural-network-fnn">Feedforward Neural Network (FNN)</h4>
<ul>
<li><strong>Dataset:</strong> Iris dataset for classification.</li>
<li><strong>Architecture:</strong>
<ul>
<li>Input Layer: 4 neurons (features)</li>
<li>Hidden Layer: 10 neurons, ReLU activation</li>
<li>Output Layer: 3 neurons, softmax activation</li>
</ul></li>
</ul>
</section>
<section id="convolutional-neural-network-cnn" class="level4">
<h4 class="anchored" data-anchor-id="convolutional-neural-network-cnn">Convolutional Neural Network (CNN)</h4>
<ul>
<li><strong>Dataset:</strong> CIFAR-10 for image classification.</li>
<li><strong>Architecture:</strong>
<ul>
<li>Convolutional Layer 1: 32 filters, 3x3 kernel, ReLU activation</li>
<li>Pooling Layer 1: 2x2 max pooling</li>
<li>Convolutional Layer 2: 64 filters, 3x3 kernel, ReLU activation</li>
<li>Pooling Layer 2: 2x2 max pooling</li>
<li>Fully Connected Layer: 128 neurons, ReLU activation</li>
<li>Output Layer: 10 neurons, softmax activation</li>
</ul></li>
</ul>
</section>
<section id="recurrent-neural-network-rnn" class="level4">
<h4 class="anchored" data-anchor-id="recurrent-neural-network-rnn">Recurrent Neural Network (RNN)</h4>
<ul>
<li><strong>Dataset:</strong> IMDB movie reviews for sentiment analysis.</li>
<li><strong>Architecture:</strong>
<ul>
<li>Input Layer: Word embeddings</li>
<li>RNN Layer: 50 units, tanh activation</li>
<li>Fully Connected Layer: 50 neurons, ReLU activation</li>
<li>Output Layer: 1 neuron, sigmoid activation</li>
</ul></li>
</ul>
<p>By understanding and implementing different weight initialization techniques and neural network architectures, we can build and train effective models for a wide range of machine learning tasks.</p>
</section>
</section>
</section>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>